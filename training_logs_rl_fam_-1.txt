Running experiments for the following parameters: DATASET_NAME: ['kinship_family'] MODEL_NAME: ['PPO'] SEED: [[0]]
Experiment number  0  out of  1  experiments.
Seed 0  in  [0]

Run vars: kinship_family-transe-mean-64-3-130-dynamic-True-True-1-True-False-False-True-True-True-True-False-20-True-0.1-0.2-python-1 
 Namespace(dataset_name='kinship_family', model_name='PPO', learn_embeddings=True, atom_embedder='transe', state_embedder='mean', atom_embedding_size=64, seed=[0], max_depth=20, timesteps_train=10000000, restore_best_val_model=True, memory_pruning=True, rule_depend_var=False, dynamic_consult=True, corruption_mode='dynamic', train_neg_pos_ratio=1, false_rules=False, end_proof_action=False, skip_unary_actions=True, ent_coef=0.1, clip_range=0.2, engine='python', train_depth=None, valid_depth=None, test_depth=None, truncate_atoms=True, truncate_states=True, padding_atoms=3, padding_states=130, non_provable_queries=True, non_provable_corruptions=True, corruption_scheme=['head', 'tail'], janus_file=None, data_path='./data/', train_file='train.txt', valid_file='valid.txt', test_file='test.txt', rules_file='rules.txt', facts_file='train.txt', state_embedding_size=64, constant_embedding_size=64, predicate_embedding_size=64, variable_no=500, device='cuda', load_model=False, save_model=True, models_path='models/kinship_family', n_eval_queries=None, n_test_queries=None, valid_negatives=None, test_negatives=-1, eval_freq=65536, n_envs=256, n_eval_envs=256, n_callback_envs=1, n_steps=256, n_epochs=10, batch_size=256, lr=0.0003, run_signature='kinship_family-transe-mean-64-3-130-dynamic-True-True-1-True-False-False-True-True-True-True-False-20-True-0.1-0.2-python-1', seed_run_i=0) 

kinship_family-transe-mean-64-3-130-dynamic-True-True-1-True-False-False-True-True-True-True-False-20-True-0.1-0.2-python-1
Device: cuda
CUDA available: True, Device count: 2
Using cuda device
Embedding dim in policy 64
Embedding dim in value 64
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
---------------evaluation started---------------
Eval num_timesteps=65536, episode_reward=0.75 +/- 0.43
Episode length: 1.08 +/- 0.44
New best mean reward!
---------------evaluation finished---------------  took 11.69 seconds
Epoch 1 completed in 83.81 seconds.
Improved rollout/ep_rew_mean to 0.3800
Time to collect_rollouts 83.94
Training model
Time to train 101.4
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 1.73      |
|    ep_rew_mean          | 0.38      |
| time/                   |           |
|    fps                  | 353       |
|    iterations           | 1         |
|    total_timesteps      | 65536     |
| train/                  |           |
|    approx_kl            | 3.7234225 |
|    clip_fraction        | 0.296     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.151    |
|    explained_variance   | -32.1     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.224     |
|    n_updates            | 10        |
|    policy_gradient_loss | 0.0846    |
|    value_loss           | 0.549     |
---------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
---------------evaluation started---------------
Eval num_timesteps=130816, episode_reward=0.75 +/- 0.43
Episode length: 1.08 +/- 0.44
New best mean reward!
---------------evaluation finished---------------  took 11.82 seconds
Collecting rollouts: 255/256 steps
Epoch 2 completed in 72.21 seconds.
Time to collect_rollouts 72.33
Training model
Time to train 103.65
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 1.54      |
|    ep_rew_mean          | 0.36      |
| time/                   |           |
|    fps                  | 362       |
|    iterations           | 2         |
|    total_timesteps      | 131072    |
| train/                  |           |
|    approx_kl            | 0.5329991 |
|    clip_fraction        | 0.39      |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.397    |
|    explained_variance   | 0.033     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0399   |
|    n_updates            | 20        |
|    policy_gradient_loss | 0.00659   |
|    value_loss           | 0.164     |
---------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
---------------evaluation started---------------
Eval num_timesteps=196096, episode_reward=0.76 +/- 0.43
Episode length: 1.08 +/- 0.43
New best mean reward!
---------------evaluation finished---------------  took 27.13 seconds
Collecting rollouts: 255/256 steps
Epoch 3 completed in 109.01 seconds.
Time to collect_rollouts 109.15
Training model
Time to train 114.73
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.92         |
|    ep_rew_mean          | 0.29         |
| time/                   |              |
|    fps                  | 335          |
|    iterations           | 3            |
|    total_timesteps      | 196608       |
| train/                  |              |
|    approx_kl            | 0.0025063818 |
|    clip_fraction        | 0.00961      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.976       |
|    explained_variance   | 0.0883       |
|    learning_rate        | 0.0003       |
|    loss                 | -0.014       |
|    n_updates            | 30           |
|    policy_gradient_loss | -0.000996    |
|    value_loss           | 0.157        |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
---------------evaluation started---------------
Eval num_timesteps=261376, episode_reward=0.76 +/- 0.43
Episode length: 1.08 +/- 0.44
---------------evaluation finished---------------  took 26.91 seconds
Collecting rollouts: 255/256 steps
Epoch 4 completed in 109.10 seconds.
Time to collect_rollouts 109.22
Training model
Time to train 119.91
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.77         |
|    ep_rew_mean          | 0.31         |
| time/                   |              |
|    fps                  | 321          |
|    iterations           | 4            |
|    total_timesteps      | 262144       |
| train/                  |              |
|    approx_kl            | 0.0026601553 |
|    clip_fraction        | 0.0083       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.972       |
|    explained_variance   | 0.131        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0332      |
|    n_updates            | 40           |
|    policy_gradient_loss | -0.00221     |
|    value_loss           | 0.152        |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
---------------evaluation started---------------
Eval num_timesteps=326656, episode_reward=0.76 +/- 0.43
Episode length: 1.07 +/- 0.43
---------------evaluation finished---------------  took 26.53 seconds
Collecting rollouts: 255/256 steps
Epoch 5 completed in 109.28 seconds.
Improved rollout/ep_rew_mean to 0.4300
Time to collect_rollouts 109.5
Training model
Time to train 118.86
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.55         |
|    ep_rew_mean          | 0.43         |
| time/                   |              |
|    fps                  | 314          |
|    iterations           | 5            |
|    total_timesteps      | 327680       |
| train/                  |              |
|    approx_kl            | 0.0019159631 |
|    clip_fraction        | 0.00778      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.981       |
|    explained_variance   | 0.167        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0411      |
|    n_updates            | 50           |
|    policy_gradient_loss | -0.00245     |
|    value_loss           | 0.145        |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
---------------evaluation started---------------
Eval num_timesteps=391936, episode_reward=0.76 +/- 0.43
Episode length: 1.07 +/- 0.44
---------------evaluation finished---------------  took 22.93 seconds
Collecting rollouts: 255/256 steps
Epoch 6 completed in 103.94 seconds.
Time to collect_rollouts 104.05
Training model
Time to train 123.94
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.62         |
|    ep_rew_mean          | 0.34         |
| time/                   |              |
|    fps                  | 309          |
|    iterations           | 6            |
|    total_timesteps      | 393216       |
| train/                  |              |
|    approx_kl            | 0.0018250362 |
|    clip_fraction        | 0.00585      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.969       |
|    explained_variance   | 0.206        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0388      |
|    n_updates            | 60           |
|    policy_gradient_loss | -0.00233     |
|    value_loss           | 0.139        |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
---------------evaluation started---------------
Eval num_timesteps=457216, episode_reward=0.76 +/- 0.43
Episode length: 1.08 +/- 0.45
---------------evaluation finished---------------  took 22.20 seconds
Collecting rollouts: 255/256 steps
Epoch 7 completed in 103.01 seconds.
Time to collect_rollouts 103.13
Training model
Time to train 131.41
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.66        |
|    ep_rew_mean          | 0.36        |
| time/                   |             |
|    fps                  | 304         |
|    iterations           | 7           |
|    total_timesteps      | 458752      |
| train/                  |             |
|    approx_kl            | 0.001821601 |
|    clip_fraction        | 0.00668     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.978      |
|    explained_variance   | 0.245       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0465     |
|    n_updates            | 70          |
|    policy_gradient_loss | -0.00253    |
|    value_loss           | 0.134       |
-----------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
---------------evaluation started---------------
Eval num_timesteps=522496, episode_reward=0.76 +/- 0.43
Episode length: 1.07 +/- 0.39
---------------evaluation finished---------------  took 20.47 seconds
Collecting rollouts: 255/256 steps
Epoch 8 completed in 101.29 seconds.
Time to collect_rollouts 101.41
Training model
Time to train 121.78
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.75         |
|    ep_rew_mean          | 0.39         |
| time/                   |              |
|    fps                  | 303          |
|    iterations           | 8            |
|    total_timesteps      | 524288       |
| train/                  |              |
|    approx_kl            | 0.0017932372 |
|    clip_fraction        | 0.0036       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.978       |
|    explained_variance   | 0.284        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0423      |
|    n_updates            | 80           |
|    policy_gradient_loss | -0.00237     |
|    value_loss           | 0.128        |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
---------------evaluation started---------------
Eval num_timesteps=587776, episode_reward=0.76 +/- 0.43
Episode length: 1.07 +/- 0.39
---------------evaluation finished---------------  took 19.59 seconds
Collecting rollouts: 255/256 steps
Epoch 9 completed in 100.38 seconds.
Improved rollout/ep_rew_mean to 0.4600
Time to collect_rollouts 100.6
Training model
Time to train 119.58
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.58         |
|    ep_rew_mean          | 0.46         |
| time/                   |              |
|    fps                  | 302          |
|    iterations           | 9            |
|    total_timesteps      | 589824       |
| train/                  |              |
|    approx_kl            | 0.0022483892 |
|    clip_fraction        | 0.00681      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.987       |
|    explained_variance   | 0.317        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0413      |
|    n_updates            | 90           |
|    policy_gradient_loss | -0.00237     |
|    value_loss           | 0.123        |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
---------------evaluation started---------------
Eval num_timesteps=653056, episode_reward=0.76 +/- 0.43
Episode length: 1.08 +/- 0.43
---------------evaluation finished---------------  took 17.07 seconds
Collecting rollouts: 255/256 steps
Epoch 10 completed in 97.86 seconds.
Time to collect_rollouts 97.97
Training model
Time to train 117.72
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.41         |
|    ep_rew_mean          | 0.33         |
| time/                   |              |
|    fps                  | 302          |
|    iterations           | 10           |
|    total_timesteps      | 655360       |
| train/                  |              |
|    approx_kl            | 0.0020342912 |
|    clip_fraction        | 0.00656      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.972       |
|    explained_variance   | 0.357        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0336      |
|    n_updates            | 100          |
|    policy_gradient_loss | -0.00234     |
|    value_loss           | 0.119        |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
---------------evaluation started---------------
Eval num_timesteps=718336, episode_reward=0.76 +/- 0.43
Episode length: 1.08 +/- 0.41
---------------evaluation finished---------------  took 16.52 seconds
Collecting rollouts: 255/256 steps
Epoch 11 completed in 96.92 seconds.
Time to collect_rollouts 97.04
Training model
Time to train 129.86
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.52         |
|    ep_rew_mean          | 0.34         |
| time/                   |              |
|    fps                  | 301          |
|    iterations           | 11           |
|    total_timesteps      | 720896       |
| train/                  |              |
|    approx_kl            | 0.0019111235 |
|    clip_fraction        | 0.00454      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.972       |
|    explained_variance   | 0.396        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0511      |
|    n_updates            | 110          |
|    policy_gradient_loss | -0.0022      |
|    value_loss           | 0.113        |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
---------------evaluation started---------------
Eval num_timesteps=783616, episode_reward=0.76 +/- 0.43
Episode length: 1.09 +/- 0.46
---------------evaluation finished---------------  took 12.92 seconds
Collecting rollouts: 255/256 steps
Epoch 12 completed in 77.78 seconds.
Improved rollout/ep_rew_mean to 0.4700
Time to collect_rollouts 78.0
Training model
Time to train 78.69
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.75        |
|    ep_rew_mean          | 0.47        |
| time/                   |             |
|    fps                  | 308         |
|    iterations           | 12          |
|    total_timesteps      | 786432      |
| train/                  |             |
|    approx_kl            | 0.001971336 |
|    clip_fraction        | 0.00582     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.972      |
|    explained_variance   | 0.427       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0587     |
|    n_updates            | 120         |
|    policy_gradient_loss | -0.00265    |
|    value_loss           | 0.107       |
-----------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
---------------evaluation started---------------
Eval num_timesteps=848896, episode_reward=0.76 +/- 0.43
Episode length: 1.08 +/- 0.44
---------------evaluation finished---------------  took 23.16 seconds
Collecting rollouts: 255/256 steps
Epoch 13 completed in 89.03 seconds.
Time to collect_rollouts 89.14
Training model
Time to train 101.67
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.98         |
|    ep_rew_mean          | 0.32         |
| time/                   |              |
|    fps                  | 311          |
|    iterations           | 13           |
|    total_timesteps      | 851968       |
| train/                  |              |
|    approx_kl            | 0.0021261459 |
|    clip_fraction        | 0.00591      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.974       |
|    explained_variance   | 0.471        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0541      |
|    n_updates            | 130          |
|    policy_gradient_loss | -0.00278     |
|    value_loss           | 0.1          |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
---------------evaluation started---------------
Eval num_timesteps=914176, episode_reward=0.76 +/- 0.43
Episode length: 1.08 +/- 0.43
---------------evaluation finished---------------  took 23.99 seconds
Collecting rollouts: 255/256 steps
Epoch 14 completed in 89.94 seconds.
Time to collect_rollouts 90.06
Training model
Time to train 86.39
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.54         |
|    ep_rew_mean          | 0.4          |
| time/                   |              |
|    fps                  | 314          |
|    iterations           | 14           |
|    total_timesteps      | 917504       |
| train/                  |              |
|    approx_kl            | 0.0021861303 |
|    clip_fraction        | 0.00779      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.971       |
|    explained_variance   | 0.502        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0771      |
|    n_updates            | 140          |
|    policy_gradient_loss | -0.00265     |
|    value_loss           | 0.0952       |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
---------------evaluation started---------------
Eval num_timesteps=979456, episode_reward=0.76 +/- 0.43
Episode length: 1.08 +/- 0.45
---------------evaluation finished---------------  took 16.20 seconds
Collecting rollouts: 255/256 steps
Epoch 15 completed in 81.42 seconds.
Time to collect_rollouts 82.84
Training model
Time to train 98.69
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.03        |
|    ep_rew_mean          | 0.34        |
| time/                   |             |
|    fps                  | 317         |
|    iterations           | 15          |
|    total_timesteps      | 983040      |
| train/                  |             |
|    approx_kl            | 0.002251694 |
|    clip_fraction        | 0.00801     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.978      |
|    explained_variance   | 0.531       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.066      |
|    n_updates            | 150         |
|    policy_gradient_loss | -0.00247    |
|    value_loss           | 0.0902      |
-----------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
---------------evaluation started---------------
Eval num_timesteps=1044736, episode_reward=0.76 +/- 0.43
Episode length: 1.08 +/- 0.42
---------------evaluation finished---------------  took 12.89 seconds
Collecting rollouts: 255/256 steps
Epoch 16 completed in 78.22 seconds.
Improved rollout/ep_rew_mean to 0.5000
Time to collect_rollouts 78.45
Training model
Time to train 52.51
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.34         |
|    ep_rew_mean          | 0.5          |
| time/                   |              |
|    fps                  | 324          |
|    iterations           | 16           |
|    total_timesteps      | 1048576      |
| train/                  |              |
|    approx_kl            | 0.0022998727 |
|    clip_fraction        | 0.00888      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.966       |
|    explained_variance   | 0.566        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0698      |
|    n_updates            | 160          |
|    policy_gradient_loss | -0.00276     |
|    value_loss           | 0.0845       |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
---------------evaluation started---------------
Eval num_timesteps=1110016, episode_reward=0.76 +/- 0.43
Episode length: 1.09 +/- 0.46
---------------evaluation finished---------------  took 21.56 seconds
Collecting rollouts: 255/256 steps
Epoch 17 completed in 87.46 seconds.
Time to collect_rollouts 87.57
Training model
Time to train 101.41
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.77         |
|    ep_rew_mean          | 0.27         |
| time/                   |              |
|    fps                  | 326          |
|    iterations           | 17           |
|    total_timesteps      | 1114112      |
| train/                  |              |
|    approx_kl            | 0.0020887305 |
|    clip_fraction        | 0.00667      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.976       |
|    explained_variance   | 0.6          |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0745      |
|    n_updates            | 170          |
|    policy_gradient_loss | -0.00268     |
|    value_loss           | 0.0768       |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
---------------evaluation started---------------
Eval num_timesteps=1175296, episode_reward=0.76 +/- 0.43
Episode length: 1.09 +/- 0.49
---------------evaluation finished---------------  took 21.39 seconds
Collecting rollouts: 255/256 steps
Epoch 18 completed in 86.58 seconds.
Time to collect_rollouts 86.7
Training model
Time to train 130.42
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.53         |
|    ep_rew_mean          | 0.36         |
| time/                   |              |
|    fps                  | 324          |
|    iterations           | 18           |
|    total_timesteps      | 1179648      |
| train/                  |              |
|    approx_kl            | 0.0021295138 |
|    clip_fraction        | 0.00654      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.985       |
|    explained_variance   | 0.631        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0826      |
|    n_updates            | 180          |
|    policy_gradient_loss | -0.00251     |
|    value_loss           | 0.0707       |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
---------------evaluation started---------------
Eval num_timesteps=1240576, episode_reward=0.76 +/- 0.43
Episode length: 1.08 +/- 0.43
---------------evaluation finished---------------  took 15.59 seconds
Collecting rollouts: 255/256 steps
Epoch 19 completed in 80.63 seconds.
Time to collect_rollouts 80.74
Training model
Time to train 137.43
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.62         |
|    ep_rew_mean          | 0.32         |
| time/                   |              |
|    fps                  | 323          |
|    iterations           | 19           |
|    total_timesteps      | 1245184      |
| train/                  |              |
|    approx_kl            | 0.0020576785 |
|    clip_fraction        | 0.00642      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.975       |
|    explained_variance   | 0.656        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0685      |
|    n_updates            | 190          |
|    policy_gradient_loss | -0.00257     |
|    value_loss           | 0.0657       |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
---------------evaluation started---------------
Eval num_timesteps=1305856, episode_reward=0.76 +/- 0.43
Episode length: 1.08 +/- 0.46
---------------evaluation finished---------------  took 13.05 seconds
Collecting rollouts: 255/256 steps
Epoch 20 completed in 78.02 seconds.
Time to collect_rollouts 78.12
Training model
Time to train 132.17
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.73        |
|    ep_rew_mean          | 0.37        |
| time/                   |             |
|    fps                  | 322         |
|    iterations           | 20          |
|    total_timesteps      | 1310720     |
| train/                  |             |
|    approx_kl            | 0.002181979 |
|    clip_fraction        | 0.00853     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.97       |
|    explained_variance   | 0.68        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0699     |
|    n_updates            | 200         |
|    policy_gradient_loss | -0.00288    |
|    value_loss           | 0.062       |
-----------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
---------------evaluation started---------------
Eval num_timesteps=1371136, episode_reward=0.76 +/- 0.43
Episode length: 1.08 +/- 0.45
---------------evaluation finished---------------  took 12.97 seconds
Collecting rollouts: 255/256 steps
Epoch 21 completed in 77.75 seconds.
Time to collect_rollouts 77.86
Training model
Time to train 121.43
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.68         |
|    ep_rew_mean          | 0.32         |
| time/                   |              |
|    fps                  | 322          |
|    iterations           | 21           |
|    total_timesteps      | 1376256      |
| train/                  |              |
|    approx_kl            | 0.0021585054 |
|    clip_fraction        | 0.00931      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.972       |
|    explained_variance   | 0.714        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0711      |
|    n_updates            | 210          |
|    policy_gradient_loss | -0.00255     |
|    value_loss           | 0.0553       |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
---------------evaluation started---------------
Eval num_timesteps=1436416, episode_reward=0.76 +/- 0.43
Episode length: 1.08 +/- 0.44
---------------evaluation finished---------------  took 16.25 seconds
Collecting rollouts: 255/256 steps
Epoch 22 completed in 81.90 seconds.
Time to collect_rollouts 82.0
Training model
Time to train 115.41
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.72         |
|    ep_rew_mean          | 0.33         |
| time/                   |              |
|    fps                  | 323          |
|    iterations           | 22           |
|    total_timesteps      | 1441792      |
| train/                  |              |
|    approx_kl            | 0.0019780472 |
|    clip_fraction        | 0.00872      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.977       |
|    explained_variance   | 0.733        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0924      |
|    n_updates            | 220          |
|    policy_gradient_loss | -0.00257     |
|    value_loss           | 0.0512       |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
---------------evaluation started---------------
Eval num_timesteps=1501696, episode_reward=0.76 +/- 0.43
Episode length: 1.09 +/- 0.47
---------------evaluation finished---------------  took 19.80 seconds
Collecting rollouts: 255/256 steps
Epoch 23 completed in 85.82 seconds.
Time to collect_rollouts 85.92
Training model
Time to train 115.59
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.56         |
|    ep_rew_mean          | 0.39         |
| time/                   |              |
|    fps                  | 323          |
|    iterations           | 23           |
|    total_timesteps      | 1507328      |
| train/                  |              |
|    approx_kl            | 0.0022077963 |
|    clip_fraction        | 0.0099       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.966       |
|    explained_variance   | 0.755        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0773      |
|    n_updates            | 230          |
|    policy_gradient_loss | -0.00275     |
|    value_loss           | 0.0468       |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
---------------evaluation started---------------
Eval num_timesteps=1566976, episode_reward=0.76 +/- 0.43
Episode length: 1.09 +/- 0.50
---------------evaluation finished---------------  took 24.18 seconds
Collecting rollouts: 255/256 steps
Epoch 24 completed in 89.67 seconds.
Time to collect_rollouts 89.78
Training model
Time to train 107.64
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.43        |
|    ep_rew_mean          | 0.43        |
| time/                   |             |
|    fps                  | 323         |
|    iterations           | 24          |
|    total_timesteps      | 1572864     |
| train/                  |             |
|    approx_kl            | 0.002359096 |
|    clip_fraction        | 0.00716     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.97       |
|    explained_variance   | 0.774       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0795     |
|    n_updates            | 240         |
|    policy_gradient_loss | -0.00271    |
|    value_loss           | 0.0437      |
-----------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
---------------evaluation started---------------
Eval num_timesteps=1632256, episode_reward=0.76 +/- 0.43
Episode length: 1.09 +/- 0.49
---------------evaluation finished---------------  took 21.45 seconds
Collecting rollouts: 255/256 steps
Epoch 25 completed in 86.54 seconds.
Time to collect_rollouts 86.65
Training model
Time to train 98.17
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.15         |
|    ep_rew_mean          | 0.41         |
| time/                   |              |
|    fps                  | 324          |
|    iterations           | 25           |
|    total_timesteps      | 1638400      |
| train/                  |              |
|    approx_kl            | 0.0022594363 |
|    clip_fraction        | 0.00974      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.969       |
|    explained_variance   | 0.78         |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0857      |
|    n_updates            | 250          |
|    policy_gradient_loss | -0.00278     |
|    value_loss           | 0.0419       |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
---------------evaluation started---------------
Eval num_timesteps=1697536, episode_reward=0.76 +/- 0.43
Episode length: 1.10 +/- 0.53
---------------evaluation finished---------------  took 13.34 seconds
Collecting rollouts: 255/256 steps
Epoch 26 completed in 78.30 seconds.
Time to collect_rollouts 78.41
Training model
Time to train 75.08
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.82         |
|    ep_rew_mean          | 0.36         |
| time/                   |              |
|    fps                  | 327          |
|    iterations           | 26           |
|    total_timesteps      | 1703936      |
| train/                  |              |
|    approx_kl            | 0.0020995536 |
|    clip_fraction        | 0.00708      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.962       |
|    explained_variance   | 0.798        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0924      |
|    n_updates            | 260          |
|    policy_gradient_loss | -0.00248     |
|    value_loss           | 0.0386       |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
---------------evaluation started---------------
Eval num_timesteps=1762816, episode_reward=0.76 +/- 0.43
Episode length: 1.08 +/- 0.46
---------------evaluation finished---------------  took 20.30 seconds
Collecting rollouts: 255/256 steps
Epoch 27 completed in 85.93 seconds.
Time to collect_rollouts 86.04
Training model
Time to train 68.8
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.45         |
|    ep_rew_mean          | 0.35         |
| time/                   |              |
|    fps                  | 330          |
|    iterations           | 27           |
|    total_timesteps      | 1769472      |
| train/                  |              |
|    approx_kl            | 0.0021266113 |
|    clip_fraction        | 0.00824      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.968       |
|    explained_variance   | 0.811        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0815      |
|    n_updates            | 270          |
|    policy_gradient_loss | -0.00243     |
|    value_loss           | 0.0363       |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
---------------evaluation started---------------
Eval num_timesteps=1828096, episode_reward=0.76 +/- 0.43
Episode length: 1.09 +/- 0.48
---------------evaluation finished---------------  took 22.27 seconds
Collecting rollouts: 255/256 steps
Epoch 28 completed in 87.13 seconds.
Time to collect_rollouts 87.24
Training model
Time to train 126.21
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.87         |
|    ep_rew_mean          | 0.42         |
| time/                   |              |
|    fps                  | 329          |
|    iterations           | 28           |
|    total_timesteps      | 1835008      |
| train/                  |              |
|    approx_kl            | 0.0025687339 |
|    clip_fraction        | 0.0118       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.966       |
|    explained_variance   | 0.814        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0951      |
|    n_updates            | 280          |
|    policy_gradient_loss | -0.00261     |
|    value_loss           | 0.0344       |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
---------------evaluation started---------------
Eval num_timesteps=1893376, episode_reward=0.76 +/- 0.43
Episode length: 1.10 +/- 0.57
---------------evaluation finished---------------  took 13.64 seconds
Collecting rollouts: 255/256 steps
Epoch 29 completed in 78.47 seconds.
Time to collect_rollouts 78.59
Training model
Time to train 125.36
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.69         |
|    ep_rew_mean          | 0.31         |
| time/                   |              |
|    fps                  | 329          |
|    iterations           | 29           |
|    total_timesteps      | 1900544      |
| train/                  |              |
|    approx_kl            | 0.0021043238 |
|    clip_fraction        | 0.00623      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.974       |
|    explained_variance   | 0.828        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.087       |
|    n_updates            | 290          |
|    policy_gradient_loss | -0.00245     |
|    value_loss           | 0.0322       |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
---------------evaluation started---------------
Eval num_timesteps=1958656, episode_reward=0.76 +/- 0.43
Episode length: 1.10 +/- 0.56
---------------evaluation finished---------------  took 13.12 seconds
Collecting rollouts: 255/256 steps
Epoch 30 completed in 79.31 seconds.
Time to collect_rollouts 79.42
Training model
Time to train 109.16
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.53         |
|    ep_rew_mean          | 0.38         |
| time/                   |              |
|    fps                  | 330          |
|    iterations           | 30           |
|    total_timesteps      | 1966080      |
| train/                  |              |
|    approx_kl            | 0.0020072001 |
|    clip_fraction        | 0.00605      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.977       |
|    explained_variance   | 0.833        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0917      |
|    n_updates            | 300          |
|    policy_gradient_loss | -0.00251     |
|    value_loss           | 0.0302       |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
---------------evaluation started---------------
Eval num_timesteps=2023936, episode_reward=0.76 +/- 0.43
Episode length: 1.11 +/- 0.58
---------------evaluation finished---------------  took 20.46 seconds
Collecting rollouts: 255/256 steps
Epoch 31 completed in 85.89 seconds.
Time to collect_rollouts 86.0
Training model
Time to train 102.35
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.45         |
|    ep_rew_mean          | 0.38         |
| time/                   |              |
|    fps                  | 330          |
|    iterations           | 31           |
|    total_timesteps      | 2031616      |
| train/                  |              |
|    approx_kl            | 0.0023889826 |
|    clip_fraction        | 0.00933      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.965       |
|    explained_variance   | 0.842        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.1         |
|    n_updates            | 310          |
|    policy_gradient_loss | -0.00248     |
|    value_loss           | 0.029        |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
---------------evaluation started---------------
Eval num_timesteps=2089216, episode_reward=0.76 +/- 0.43
Episode length: 1.11 +/- 0.56
---------------evaluation finished---------------  took 23.51 seconds
Collecting rollouts: 255/256 steps
Epoch 32 completed in 88.88 seconds.
Time to collect_rollouts 88.99
Training model
Time to train 109.92
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.59         |
|    ep_rew_mean          | 0.39         |
| time/                   |              |
|    fps                  | 330          |
|    iterations           | 32           |
|    total_timesteps      | 2097152      |
| train/                  |              |
|    approx_kl            | 0.0021912814 |
|    clip_fraction        | 0.00776      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.973       |
|    explained_variance   | 0.846        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0783      |
|    n_updates            | 320          |
|    policy_gradient_loss | -0.00265     |
|    value_loss           | 0.0275       |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
---------------evaluation started---------------
Eval num_timesteps=2154496, episode_reward=0.76 +/- 0.43
Episode length: 1.09 +/- 0.46
---------------evaluation finished---------------  took 20.20 seconds
Collecting rollouts: 255/256 steps
Epoch 33 completed in 85.45 seconds.
Time to collect_rollouts 85.56
Training model
Time to train 116.41
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.47         |
|    ep_rew_mean          | 0.42         |
| time/                   |              |
|    fps                  | 330          |
|    iterations           | 33           |
|    total_timesteps      | 2162688      |
| train/                  |              |
|    approx_kl            | 0.0016116565 |
|    clip_fraction        | 0.0062       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.962       |
|    explained_variance   | 0.857        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0725      |
|    n_updates            | 330          |
|    policy_gradient_loss | -0.00245     |
|    value_loss           | 0.0261       |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
---------------evaluation started---------------
Eval num_timesteps=2219776, episode_reward=0.76 +/- 0.43
Episode length: 1.08 +/- 0.46
---------------evaluation finished---------------  took 12.89 seconds
Collecting rollouts: 255/256 steps
Epoch 34 completed in 77.69 seconds.
Time to collect_rollouts 77.8
Training model
Time to train 121.26
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.6         |
|    ep_rew_mean          | 0.38        |
| time/                   |             |
|    fps                  | 330         |
|    iterations           | 34          |
|    total_timesteps      | 2228224     |
| train/                  |             |
|    approx_kl            | 0.002532084 |
|    clip_fraction        | 0.0106      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.977      |
|    explained_variance   | 0.854       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.101      |
|    n_updates            | 340         |
|    policy_gradient_loss | -0.00284    |
|    value_loss           | 0.0258      |
-----------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
---------------evaluation started---------------
Eval num_timesteps=2285056, episode_reward=0.76 +/- 0.43
Episode length: 1.08 +/- 0.47
---------------evaluation finished---------------  took 12.28 seconds
Collecting rollouts: 255/256 steps
Epoch 35 completed in 77.35 seconds.
Time to collect_rollouts 77.47
Training model
Time to train 112.02
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.78         |
|    ep_rew_mean          | 0.35         |
| time/                   |              |
|    fps                  | 330          |
|    iterations           | 35           |
|    total_timesteps      | 2293760      |
| train/                  |              |
|    approx_kl            | 0.0022638324 |
|    clip_fraction        | 0.00914      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.978       |
|    explained_variance   | 0.869        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0836      |
|    n_updates            | 350          |
|    policy_gradient_loss | -0.00275     |
|    value_loss           | 0.0237       |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
---------------evaluation started---------------
Eval num_timesteps=2350336, episode_reward=0.76 +/- 0.43
Episode length: 1.09 +/- 0.47
---------------evaluation finished---------------  took 17.47 seconds
Collecting rollouts: 255/256 steps
Epoch 36 completed in 82.81 seconds.
Time to collect_rollouts 82.92
Training model
Time to train 105.33
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.8          |
|    ep_rew_mean          | 0.45         |
| time/                   |              |
|    fps                  | 331          |
|    iterations           | 36           |
|    total_timesteps      | 2359296      |
| train/                  |              |
|    approx_kl            | 0.0020615463 |
|    clip_fraction        | 0.00588      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.975       |
|    explained_variance   | 0.87         |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0873      |
|    n_updates            | 360          |
|    policy_gradient_loss | -0.00255     |
|    value_loss           | 0.0231       |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
---------------evaluation started---------------
Eval num_timesteps=2415616, episode_reward=0.76 +/- 0.43
Episode length: 1.08 +/- 0.43
---------------evaluation finished---------------  took 21.81 seconds
Collecting rollouts: 255/256 steps
Epoch 37 completed in 87.23 seconds.
Time to collect_rollouts 87.34
Training model
Time to train 101.55
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.93         |
|    ep_rew_mean          | 0.32         |
| time/                   |              |
|    fps                  | 331          |
|    iterations           | 37           |
|    total_timesteps      | 2424832      |
| train/                  |              |
|    approx_kl            | 0.0035965557 |
|    clip_fraction        | 0.0095       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.975       |
|    explained_variance   | 0.875        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0996      |
|    n_updates            | 370          |
|    policy_gradient_loss | -0.00291     |
|    value_loss           | 0.0225       |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
---------------evaluation started---------------
Eval num_timesteps=2480896, episode_reward=0.76 +/- 0.43
Episode length: 1.08 +/- 0.43
---------------evaluation finished---------------  took 18.64 seconds
Collecting rollouts: 255/256 steps
Epoch 38 completed in 83.89 seconds.
Time to collect_rollouts 84.0
Training model
Time to train 114.0
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.72         |
|    ep_rew_mean          | 0.39         |
| time/                   |              |
|    fps                  | 331          |
|    iterations           | 38           |
|    total_timesteps      | 2490368      |
| train/                  |              |
|    approx_kl            | 0.0021747933 |
|    clip_fraction        | 0.00844      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.972       |
|    explained_variance   | 0.88         |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0942      |
|    n_updates            | 380          |
|    policy_gradient_loss | -0.00264     |
|    value_loss           | 0.021        |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
---------------evaluation started---------------
Eval num_timesteps=2546176, episode_reward=0.76 +/- 0.43
Episode length: 1.07 +/- 0.41
---------------evaluation finished---------------  took 14.09 seconds
Collecting rollouts: 255/256 steps
Epoch 39 completed in 79.68 seconds.
Time to collect_rollouts 79.79
Training model
Time to train 123.07
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.32         |
|    ep_rew_mean          | 0.39         |
| time/                   |              |
|    fps                  | 331          |
|    iterations           | 39           |
|    total_timesteps      | 2555904      |
| train/                  |              |
|    approx_kl            | 0.0023386069 |
|    clip_fraction        | 0.00897      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.971       |
|    explained_variance   | 0.882        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0774      |
|    n_updates            | 390          |
|    policy_gradient_loss | -0.00302     |
|    value_loss           | 0.0211       |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
---------------evaluation started---------------
Eval num_timesteps=2611456, episode_reward=0.76 +/- 0.43
Episode length: 1.08 +/- 0.45
---------------evaluation finished---------------  took 10.78 seconds
Collecting rollouts: 255/256 steps
Epoch 40 completed in 76.24 seconds.
Time to collect_rollouts 76.36
Training model
Time to train 122.52
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.64         |
|    ep_rew_mean          | 0.43         |
| time/                   |              |
|    fps                  | 331          |
|    iterations           | 40           |
|    total_timesteps      | 2621440      |
| train/                  |              |
|    approx_kl            | 0.0021291943 |
|    clip_fraction        | 0.00696      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.971       |
|    explained_variance   | 0.885        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0804      |
|    n_updates            | 400          |
|    policy_gradient_loss | -0.00257     |
|    value_loss           | 0.0207       |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
---------------evaluation started---------------
Eval num_timesteps=2676736, episode_reward=0.76 +/- 0.43
Episode length: 1.08 +/- 0.45
---------------evaluation finished---------------  took 10.68 seconds
Collecting rollouts: 255/256 steps
Epoch 41 completed in 76.50 seconds.
Time to collect_rollouts 76.62
Training model
Time to train 110.19
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.51         |
|    ep_rew_mean          | 0.35         |
| time/                   |              |
|    fps                  | 331          |
|    iterations           | 41           |
|    total_timesteps      | 2686976      |
| train/                  |              |
|    approx_kl            | 0.0024126167 |
|    clip_fraction        | 0.00925      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.976       |
|    explained_variance   | 0.89         |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0901      |
|    n_updates            | 410          |
|    policy_gradient_loss | -0.00309     |
|    value_loss           | 0.0193       |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
---------------evaluation started---------------
Eval num_timesteps=2742016, episode_reward=0.76 +/- 0.43
Episode length: 1.08 +/- 0.46
---------------evaluation finished---------------  took 14.06 seconds
Collecting rollouts: 255/256 steps
Epoch 42 completed in 79.97 seconds.
Time to collect_rollouts 80.08
Training model
Time to train 105.34
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.77         |
|    ep_rew_mean          | 0.35         |
| time/                   |              |
|    fps                  | 332          |
|    iterations           | 42           |
|    total_timesteps      | 2752512      |
| train/                  |              |
|    approx_kl            | 0.0019433058 |
|    clip_fraction        | 0.00729      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.972       |
|    explained_variance   | 0.892        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.101       |
|    n_updates            | 420          |
|    policy_gradient_loss | -0.00283     |
|    value_loss           | 0.0185       |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
---------------evaluation started---------------
Eval num_timesteps=2807296, episode_reward=0.76 +/- 0.43
Episode length: 1.08 +/- 0.44
---------------evaluation finished---------------  took 18.48 seconds
Collecting rollouts: 255/256 steps
Epoch 43 completed in 84.29 seconds.
Time to collect_rollouts 84.4
Training model
Time to train 104.9
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.77         |
|    ep_rew_mean          | 0.41         |
| time/                   |              |
|    fps                  | 332          |
|    iterations           | 43           |
|    total_timesteps      | 2818048      |
| train/                  |              |
|    approx_kl            | 0.0022357479 |
|    clip_fraction        | 0.00793      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.97        |
|    explained_variance   | 0.892        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0919      |
|    n_updates            | 430          |
|    policy_gradient_loss | -0.00286     |
|    value_loss           | 0.0186       |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
---------------evaluation started---------------
Eval num_timesteps=2872576, episode_reward=0.76 +/- 0.43
Episode length: 1.09 +/- 0.51
---------------evaluation finished---------------  took 14.48 seconds
Collecting rollouts: 255/256 steps
Epoch 44 completed in 80.34 seconds.
Time to collect_rollouts 80.44
Training model
Time to train 117.81
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.66         |
|    ep_rew_mean          | 0.37         |
| time/                   |              |
|    fps                  | 332          |
|    iterations           | 44           |
|    total_timesteps      | 2883584      |
| train/                  |              |
|    approx_kl            | 0.0023449257 |
|    clip_fraction        | 0.00725      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.979       |
|    explained_variance   | 0.9          |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0816      |
|    n_updates            | 440          |
|    policy_gradient_loss | -0.00279     |
|    value_loss           | 0.0172       |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
---------------evaluation started---------------
Eval num_timesteps=2937856, episode_reward=0.76 +/- 0.43
Episode length: 1.09 +/- 0.55
---------------evaluation finished---------------  took 13.92 seconds
Collecting rollouts: 255/256 steps
Epoch 45 completed in 79.28 seconds.
Time to collect_rollouts 79.4
Training model
Time to train 122.47
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.55        |
|    ep_rew_mean          | 0.34        |
| time/                   |             |
|    fps                  | 332         |
|    iterations           | 45          |
|    total_timesteps      | 2949120     |
| train/                  |             |
|    approx_kl            | 0.002096935 |
|    clip_fraction        | 0.00575     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.972      |
|    explained_variance   | 0.906       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0907     |
|    n_updates            | 450         |
|    policy_gradient_loss | -0.00274    |
|    value_loss           | 0.0167      |
-----------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
---------------evaluation started---------------
Eval num_timesteps=3003136, episode_reward=0.76 +/- 0.43
Episode length: 1.09 +/- 0.54
---------------evaluation finished---------------  took 10.70 seconds
Collecting rollouts: 255/256 steps
Epoch 46 completed in 76.02 seconds.
Time to collect_rollouts 76.13
Training model
Time to train 112.07
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.82         |
|    ep_rew_mean          | 0.45         |
| time/                   |              |
|    fps                  | 332          |
|    iterations           | 46           |
|    total_timesteps      | 3014656      |
| train/                  |              |
|    approx_kl            | 0.0020963263 |
|    clip_fraction        | 0.00689      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.976       |
|    explained_variance   | 0.899        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.095       |
|    n_updates            | 460          |
|    policy_gradient_loss | -0.00267     |
|    value_loss           | 0.0175       |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
---------------evaluation started---------------
Eval num_timesteps=3068416, episode_reward=0.76 +/- 0.43
Episode length: 1.08 +/- 0.49
---------------evaluation finished---------------  took 14.22 seconds
Collecting rollouts: 255/256 steps
Epoch 47 completed in 81.13 seconds.
Time to collect_rollouts 81.25
Training model
Time to train 110.29
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.32        |
|    ep_rew_mean          | 0.41        |
| time/                   |             |
|    fps                  | 332         |
|    iterations           | 47          |
|    total_timesteps      | 3080192     |
| train/                  |             |
|    approx_kl            | 0.002086236 |
|    clip_fraction        | 0.00707     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.967      |
|    explained_variance   | 0.909       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.09       |
|    n_updates            | 470         |
|    policy_gradient_loss | -0.00285    |
|    value_loss           | 0.0161      |
-----------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
---------------evaluation started---------------
Eval num_timesteps=3133696, episode_reward=0.76 +/- 0.43
Episode length: 1.06 +/- 0.39
---------------evaluation finished---------------  took 13.85 seconds
Collecting rollouts: 255/256 steps
Epoch 48 completed in 80.16 seconds.
Time to collect_rollouts 80.27
Training model
Time to train 107.99
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.53        |
|    ep_rew_mean          | 0.4         |
| time/                   |             |
|    fps                  | 333         |
|    iterations           | 48          |
|    total_timesteps      | 3145728     |
| train/                  |             |
|    approx_kl            | 0.002130723 |
|    clip_fraction        | 0.00973     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.965      |
|    explained_variance   | 0.9         |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0909     |
|    n_updates            | 480         |
|    policy_gradient_loss | -0.00353    |
|    value_loss           | 0.0166      |
-----------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
---------------evaluation started---------------
Eval num_timesteps=3198976, episode_reward=0.76 +/- 0.43
Episode length: 1.07 +/- 0.38
---------------evaluation finished---------------  took 18.55 seconds
Collecting rollouts: 255/256 steps
Epoch 49 completed in 84.47 seconds.
Time to collect_rollouts 84.58
Training model
Time to train 107.28
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.75         |
|    ep_rew_mean          | 0.29         |
| time/                   |              |
|    fps                  | 333          |
|    iterations           | 49           |
|    total_timesteps      | 3211264      |
| train/                  |              |
|    approx_kl            | 0.0022740304 |
|    clip_fraction        | 0.00935      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.965       |
|    explained_variance   | 0.908        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.1         |
|    n_updates            | 490          |
|    policy_gradient_loss | -0.00315     |
|    value_loss           | 0.0158       |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
---------------evaluation started---------------
Eval num_timesteps=3264256, episode_reward=0.76 +/- 0.43
Episode length: 1.07 +/- 0.40
---------------evaluation finished---------------  took 20.55 seconds
Collecting rollouts: 255/256 steps
Epoch 50 completed in 86.30 seconds.
Time to collect_rollouts 86.41
Training model
Time to train 110.72
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.77         |
|    ep_rew_mean          | 0.3          |
| time/                   |              |
|    fps                  | 333          |
|    iterations           | 50           |
|    total_timesteps      | 3276800      |
| train/                  |              |
|    approx_kl            | 0.0023390823 |
|    clip_fraction        | 0.00875      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.968       |
|    explained_variance   | 0.911        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.106       |
|    n_updates            | 500          |
|    policy_gradient_loss | -0.00299     |
|    value_loss           | 0.0157       |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
---------------evaluation started---------------
Eval num_timesteps=3329536, episode_reward=0.76 +/- 0.43
Episode length: 1.07 +/- 0.38
---------------evaluation finished---------------  took 17.46 seconds
Collecting rollouts: 255/256 steps
Epoch 51 completed in 83.05 seconds.
Time to collect_rollouts 83.16
Training model
Time to train 109.12
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.45         |
|    ep_rew_mean          | 0.38         |
| time/                   |              |
|    fps                  | 333          |
|    iterations           | 51           |
|    total_timesteps      | 3342336      |
| train/                  |              |
|    approx_kl            | 0.0020992074 |
|    clip_fraction        | 0.00707      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.964       |
|    explained_variance   | 0.912        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0856      |
|    n_updates            | 510          |
|    policy_gradient_loss | -0.00292     |
|    value_loss           | 0.0153       |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
---------------evaluation started---------------
Eval num_timesteps=3394816, episode_reward=0.76 +/- 0.43
Episode length: 1.06 +/- 0.35
---------------evaluation finished---------------  took 17.16 seconds
Collecting rollouts: 255/256 steps
Epoch 52 completed in 82.78 seconds.
Time to collect_rollouts 82.9
Training model
Time to train 109.56
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.38        |
|    ep_rew_mean          | 0.33        |
| time/                   |             |
|    fps                  | 333         |
|    iterations           | 52          |
|    total_timesteps      | 3407872     |
| train/                  |             |
|    approx_kl            | 0.002314425 |
|    clip_fraction        | 0.0107      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.966      |
|    explained_variance   | 0.911       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0671     |
|    n_updates            | 520         |
|    policy_gradient_loss | -0.00319    |
|    value_loss           | 0.0154      |
-----------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
---------------evaluation started---------------
Eval num_timesteps=3460096, episode_reward=0.76 +/- 0.43
Episode length: 1.08 +/- 0.42
---------------evaluation finished---------------  took 15.69 seconds
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 53 completed in 81.12 seconds.
Time to collect_rollouts 81.23
Training model
Time to train 103.41
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.73         |
|    ep_rew_mean          | 0.34         |
| time/                   |              |
|    fps                  | 333          |
|    iterations           | 53           |
|    total_timesteps      | 3473408      |
| train/                  |              |
|    approx_kl            | 0.0027537434 |
|    clip_fraction        | 0.012        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.96        |
|    explained_variance   | 0.913        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0879      |
|    n_updates            | 530          |
|    policy_gradient_loss | -0.00323     |
|    value_loss           | 0.0151       |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
---------------evaluation started---------------
Eval num_timesteps=3525376, episode_reward=0.76 +/- 0.43
Episode length: 1.07 +/- 0.43
---------------evaluation finished---------------  took 17.87 seconds
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 54 completed in 83.78 seconds.
Time to collect_rollouts 83.89
Training model
Time to train 107.25
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.74        |
|    ep_rew_mean          | 0.37        |
| time/                   |             |
|    fps                  | 334         |
|    iterations           | 54          |
|    total_timesteps      | 3538944     |
| train/                  |             |
|    approx_kl            | 0.002138991 |
|    clip_fraction        | 0.00893     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.959      |
|    explained_variance   | 0.921       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0975     |
|    n_updates            | 540         |
|    policy_gradient_loss | -0.00316    |
|    value_loss           | 0.0141      |
-----------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
---------------evaluation started---------------
Eval num_timesteps=3590656, episode_reward=0.76 +/- 0.43
Episode length: 1.07 +/- 0.44
---------------evaluation finished---------------  took 17.28 seconds
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 55 completed in 82.57 seconds.
Time to collect_rollouts 82.68
Training model
Time to train 108.86
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.77         |
|    ep_rew_mean          | 0.33         |
| time/                   |              |
|    fps                  | 334          |
|    iterations           | 55           |
|    total_timesteps      | 3604480      |
| train/                  |              |
|    approx_kl            | 0.0028739553 |
|    clip_fraction        | 0.0131       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.966       |
|    explained_variance   | 0.917        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0931      |
|    n_updates            | 550          |
|    policy_gradient_loss | -0.00316     |
|    value_loss           | 0.0138       |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
---------------evaluation started---------------
Eval num_timesteps=3655936, episode_reward=0.76 +/- 0.43
Episode length: 1.08 +/- 0.48
---------------evaluation finished---------------  took 13.54 seconds
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 56 completed in 78.96 seconds.
Time to collect_rollouts 79.07
Training model
Time to train 113.18
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.54         |
|    ep_rew_mean          | 0.34         |
| time/                   |              |
|    fps                  | 334          |
|    iterations           | 56           |
|    total_timesteps      | 3670016      |
| train/                  |              |
|    approx_kl            | 0.0023648166 |
|    clip_fraction        | 0.0102       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.971       |
|    explained_variance   | 0.925        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0987      |
|    n_updates            | 560          |
|    policy_gradient_loss | -0.00308     |
|    value_loss           | 0.0132       |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
---------------evaluation started---------------
Eval num_timesteps=3721216, episode_reward=0.76 +/- 0.43
Episode length: 1.08 +/- 0.46
---------------evaluation finished---------------  took 17.45 seconds
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 57 completed in 82.61 seconds.
Time to collect_rollouts 82.73
Training model
Time to train 105.67
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.67         |
|    ep_rew_mean          | 0.44         |
| time/                   |              |
|    fps                  | 334          |
|    iterations           | 57           |
|    total_timesteps      | 3735552      |
| train/                  |              |
|    approx_kl            | 0.0023465874 |
|    clip_fraction        | 0.00941      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.969       |
|    explained_variance   | 0.92         |
|    learning_rate        | 0.0003       |
|    loss                 | -0.102       |
|    n_updates            | 570          |
|    policy_gradient_loss | -0.00287     |
|    value_loss           | 0.0136       |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
---------------evaluation started---------------
Eval num_timesteps=3786496, episode_reward=0.76 +/- 0.43
Episode length: 1.07 +/- 0.41
---------------evaluation finished---------------  took 22.38 seconds
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 58 completed in 89.46 seconds.
Time to collect_rollouts 89.55
Training model
Time to train 104.44
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.52        |
|    ep_rew_mean          | 0.36        |
| time/                   |             |
|    fps                  | 334         |
|    iterations           | 58          |
|    total_timesteps      | 3801088     |
| train/                  |             |
|    approx_kl            | 0.002079865 |
|    clip_fraction        | 0.0071      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.968      |
|    explained_variance   | 0.924       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0867     |
|    n_updates            | 580         |
|    policy_gradient_loss | -0.00291    |
|    value_loss           | 0.0131      |
-----------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
---------------evaluation started---------------
Eval num_timesteps=3851776, episode_reward=0.76 +/- 0.43
Episode length: 1.06 +/- 0.40
---------------evaluation finished---------------  took 18.32 seconds
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 59 completed in 83.89 seconds.
Time to collect_rollouts 84.0
Training model
Time to train 110.68
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.32         |
|    ep_rew_mean          | 0.43         |
| time/                   |              |
|    fps                  | 334          |
|    iterations           | 59           |
|    total_timesteps      | 3866624      |
| train/                  |              |
|    approx_kl            | 0.0019366624 |
|    clip_fraction        | 0.00665      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.968       |
|    explained_variance   | 0.922        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.102       |
|    n_updates            | 590          |
|    policy_gradient_loss | -0.00276     |
|    value_loss           | 0.0132       |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
---------------evaluation started---------------
Eval num_timesteps=3917056, episode_reward=0.76 +/- 0.43
Episode length: 1.07 +/- 0.42
---------------evaluation finished---------------  took 15.58 seconds
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 60 completed in 81.12 seconds.
Time to collect_rollouts 81.23
Training model
Time to train 114.72
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.88         |
|    ep_rew_mean          | 0.41         |
| time/                   |              |
|    fps                  | 334          |
|    iterations           | 60           |
|    total_timesteps      | 3932160      |
| train/                  |              |
|    approx_kl            | 0.0023958473 |
|    clip_fraction        | 0.00906      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.965       |
|    explained_variance   | 0.923        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0904      |
|    n_updates            | 600          |
|    policy_gradient_loss | -0.0033      |
|    value_loss           | 0.0132       |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
---------------evaluation started---------------
Eval num_timesteps=3982336, episode_reward=0.76 +/- 0.43
Episode length: 1.07 +/- 0.40
---------------evaluation finished---------------  took 12.97 seconds
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 61 completed in 78.08 seconds.
Time to collect_rollouts 78.18
Training model
Time to train 115.78
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.66         |
|    ep_rew_mean          | 0.33         |
| time/                   |              |
|    fps                  | 334          |
|    iterations           | 61           |
|    total_timesteps      | 3997696      |
| train/                  |              |
|    approx_kl            | 0.0022221874 |
|    clip_fraction        | 0.00708      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.967       |
|    explained_variance   | 0.922        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0948      |
|    n_updates            | 610          |
|    policy_gradient_loss | -0.00301     |
|    value_loss           | 0.0129       |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
---------------evaluation started---------------
Eval num_timesteps=4047616, episode_reward=0.76 +/- 0.43
Episode length: 1.07 +/- 0.41
---------------evaluation finished---------------  took 14.56 seconds
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 62 completed in 79.83 seconds.
Time to collect_rollouts 79.95
Training model
Time to train 112.61
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.68        |
|    ep_rew_mean          | 0.45        |
| time/                   |             |
|    fps                  | 334         |
|    iterations           | 62          |
|    total_timesteps      | 4063232     |
| train/                  |             |
|    approx_kl            | 0.002127356 |
|    clip_fraction        | 0.00776     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.972      |
|    explained_variance   | 0.926       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0879     |
|    n_updates            | 620         |
|    policy_gradient_loss | -0.00314    |
|    value_loss           | 0.0124      |
-----------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
---------------evaluation started---------------
Eval num_timesteps=4112896, episode_reward=0.76 +/- 0.43
Episode length: 1.07 +/- 0.40
---------------evaluation finished---------------  took 13.61 seconds
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 63 completed in 78.36 seconds.
Time to collect_rollouts 78.47
Training model
Time to train 110.97
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.68         |
|    ep_rew_mean          | 0.38         |
| time/                   |              |
|    fps                  | 335          |
|    iterations           | 63           |
|    total_timesteps      | 4128768      |
| train/                  |              |
|    approx_kl            | 0.0021311734 |
|    clip_fraction        | 0.0082       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.976       |
|    explained_variance   | 0.927        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.101       |
|    n_updates            | 630          |
|    policy_gradient_loss | -0.00279     |
|    value_loss           | 0.0122       |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
---------------evaluation started---------------
Eval num_timesteps=4178176, episode_reward=0.76 +/- 0.43
Episode length: 1.07 +/- 0.44
---------------evaluation finished---------------  took 13.99 seconds
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 64 completed in 79.30 seconds.
Time to collect_rollouts 79.41
Training model
Time to train 109.83
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.98         |
|    ep_rew_mean          | 0.34         |
| time/                   |              |
|    fps                  | 335          |
|    iterations           | 64           |
|    total_timesteps      | 4194304      |
| train/                  |              |
|    approx_kl            | 0.0023562023 |
|    clip_fraction        | 0.00831      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.978       |
|    explained_variance   | 0.929        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0848      |
|    n_updates            | 640          |
|    policy_gradient_loss | -0.00311     |
|    value_loss           | 0.0122       |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
---------------evaluation started---------------
Eval num_timesteps=4243456, episode_reward=0.76 +/- 0.43
Episode length: 1.08 +/- 0.44
---------------evaluation finished---------------  took 13.70 seconds
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 65 completed in 79.12 seconds.
Time to collect_rollouts 79.23
Training model
Time to train 115.74
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.54         |
|    ep_rew_mean          | 0.38         |
| time/                   |              |
|    fps                  | 335          |
|    iterations           | 65           |
|    total_timesteps      | 4259840      |
| train/                  |              |
|    approx_kl            | 0.0018767206 |
|    clip_fraction        | 0.00462      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.98        |
|    explained_variance   | 0.926        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0981      |
|    n_updates            | 650          |
|    policy_gradient_loss | -0.00305     |
|    value_loss           | 0.0123       |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
---------------evaluation started---------------
Eval num_timesteps=4308736, episode_reward=0.76 +/- 0.43
Episode length: 1.07 +/- 0.42
---------------evaluation finished---------------  took 13.85 seconds
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 66 completed in 79.36 seconds.
Time to collect_rollouts 79.48
Training model
Time to train 118.86
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.39         |
|    ep_rew_mean          | 0.35         |
| time/                   |              |
|    fps                  | 335          |
|    iterations           | 66           |
|    total_timesteps      | 4325376      |
| train/                  |              |
|    approx_kl            | 0.0023011444 |
|    clip_fraction        | 0.0088       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.971       |
|    explained_variance   | 0.925        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0975      |
|    n_updates            | 660          |
|    policy_gradient_loss | -0.00347     |
|    value_loss           | 0.0122       |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
---------------evaluation started---------------
Eval num_timesteps=4374016, episode_reward=0.76 +/- 0.43
Episode length: 1.08 +/- 0.44
---------------evaluation finished---------------  took 11.96 seconds
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 67 completed in 78.46 seconds.
Time to collect_rollouts 78.57
Training model
Time to train 108.12
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.63        |
|    ep_rew_mean          | 0.32        |
| time/                   |             |
|    fps                  | 335         |
|    iterations           | 67          |
|    total_timesteps      | 4390912     |
| train/                  |             |
|    approx_kl            | 0.002331012 |
|    clip_fraction        | 0.0103      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.971      |
|    explained_variance   | 0.927       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.1        |
|    n_updates            | 670         |
|    policy_gradient_loss | -0.00309    |
|    value_loss           | 0.0119      |
-----------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
---------------evaluation started---------------
Eval num_timesteps=4439296, episode_reward=0.76 +/- 0.43
Episode length: 1.08 +/- 0.44
---------------evaluation finished---------------  took 15.02 seconds
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 68 completed in 80.22 seconds.
Time to collect_rollouts 80.33
Training model
Time to train 109.54
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.49         |
|    ep_rew_mean          | 0.36         |
| time/                   |              |
|    fps                  | 335          |
|    iterations           | 68           |
|    total_timesteps      | 4456448      |
| train/                  |              |
|    approx_kl            | 0.0024109713 |
|    clip_fraction        | 0.0104       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.972       |
|    explained_variance   | 0.929        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.086       |
|    n_updates            | 680          |
|    policy_gradient_loss | -0.00332     |
|    value_loss           | 0.0121       |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
---------------evaluation started---------------
Eval num_timesteps=4504576, episode_reward=0.76 +/- 0.43
Episode length: 1.07 +/- 0.44
---------------evaluation finished---------------  took 14.28 seconds
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 69 completed in 79.82 seconds.
Time to collect_rollouts 79.94
Training model
Time to train 106.72
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.73         |
|    ep_rew_mean          | 0.37         |
| time/                   |              |
|    fps                  | 335          |
|    iterations           | 69           |
|    total_timesteps      | 4521984      |
| train/                  |              |
|    approx_kl            | 0.0028440456 |
|    clip_fraction        | 0.0161       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.969       |
|    explained_variance   | 0.932        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0838      |
|    n_updates            | 690          |
|    policy_gradient_loss | -0.00343     |
|    value_loss           | 0.0111       |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
---------------evaluation started---------------
Eval num_timesteps=4569856, episode_reward=0.76 +/- 0.43
Episode length: 1.08 +/- 0.49
---------------evaluation finished---------------  took 21.05 seconds
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 70 completed in 86.56 seconds.
Time to collect_rollouts 86.68
Training model
Time to train 109.56
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.64       |
|    ep_rew_mean          | 0.38       |
| time/                   |            |
|    fps                  | 335        |
|    iterations           | 70         |
|    total_timesteps      | 4587520    |
| train/                  |            |
|    approx_kl            | 0.00200467 |
|    clip_fraction        | 0.00775    |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.962     |
|    explained_variance   | 0.933      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.103     |
|    n_updates            | 700        |
|    policy_gradient_loss | -0.00319   |
|    value_loss           | 0.011      |
----------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
---------------evaluation started---------------
Eval num_timesteps=4635136, episode_reward=0.76 +/- 0.43
Episode length: 1.07 +/- 0.44
---------------evaluation finished---------------  took 16.51 seconds
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 71 completed in 81.83 seconds.
Time to collect_rollouts 81.94
Training model
Time to train 125.34
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.29         |
|    ep_rew_mean          | 0.45         |
| time/                   |              |
|    fps                  | 335          |
|    iterations           | 71           |
|    total_timesteps      | 4653056      |
| train/                  |              |
|    approx_kl            | 0.0021472087 |
|    clip_fraction        | 0.0069       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.962       |
|    explained_variance   | 0.935        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0873      |
|    n_updates            | 710          |
|    policy_gradient_loss | -0.00327     |
|    value_loss           | 0.0109       |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
---------------evaluation started---------------
Eval num_timesteps=4700416, episode_reward=0.76 +/- 0.43
Episode length: 1.08 +/- 0.45
---------------evaluation finished---------------  took 12.79 seconds
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 72 completed in 77.68 seconds.
Time to collect_rollouts 77.79
Training model
Time to train 127.53
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.94         |
|    ep_rew_mean          | 0.35         |
| time/                   |              |
|    fps                  | 335          |
|    iterations           | 72           |
|    total_timesteps      | 4718592      |
| train/                  |              |
|    approx_kl            | 0.0025448904 |
|    clip_fraction        | 0.0101       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.975       |
|    explained_variance   | 0.928        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.109       |
|    n_updates            | 720          |
|    policy_gradient_loss | -0.00327     |
|    value_loss           | 0.0115       |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
---------------evaluation started---------------
Eval num_timesteps=4765696, episode_reward=0.76 +/- 0.43
Episode length: 1.07 +/- 0.42
---------------evaluation finished---------------  took 12.64 seconds
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 73 completed in 77.99 seconds.
Time to collect_rollouts 78.1
Training model
Time to train 108.71
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.37       |
|    ep_rew_mean          | 0.38       |
| time/                   |            |
|    fps                  | 335        |
|    iterations           | 73         |
|    total_timesteps      | 4784128    |
| train/                  |            |
|    approx_kl            | 0.00231022 |
|    clip_fraction        | 0.00805    |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.966     |
|    explained_variance   | 0.934      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.105     |
|    n_updates            | 730        |
|    policy_gradient_loss | -0.00323   |
|    value_loss           | 0.0112     |
----------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
---------------evaluation started---------------
Eval num_timesteps=4830976, episode_reward=0.76 +/- 0.43
Episode length: 1.08 +/- 0.44
---------------evaluation finished---------------  took 17.58 seconds
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 74 completed in 83.52 seconds.
Improved rollout/ep_rew_mean to 0.5200
Time to collect_rollouts 83.73
Training model
Time to train 101.5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.61         |
|    ep_rew_mean          | 0.52         |
| time/                   |              |
|    fps                  | 335          |
|    iterations           | 74           |
|    total_timesteps      | 4849664      |
| train/                  |              |
|    approx_kl            | 0.0020746915 |
|    clip_fraction        | 0.00645      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.953       |
|    explained_variance   | 0.936        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0935      |
|    n_updates            | 740          |
|    policy_gradient_loss | -0.00327     |
|    value_loss           | 0.0106       |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
---------------evaluation started---------------
Eval num_timesteps=4896256, episode_reward=0.76 +/- 0.43
Episode length: 1.07 +/- 0.42
---------------evaluation finished---------------  took 18.04 seconds
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 75 completed in 84.09 seconds.
Time to collect_rollouts 84.21
Training model
Time to train 106.81
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.84         |
|    ep_rew_mean          | 0.42         |
| time/                   |              |
|    fps                  | 335          |
|    iterations           | 75           |
|    total_timesteps      | 4915200      |
| train/                  |              |
|    approx_kl            | 0.0027112747 |
|    clip_fraction        | 0.0108       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.962       |
|    explained_variance   | 0.936        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.097       |
|    n_updates            | 750          |
|    policy_gradient_loss | -0.00345     |
|    value_loss           | 0.0107       |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
---------------evaluation started---------------
Eval num_timesteps=4961536, episode_reward=0.76 +/- 0.43
Episode length: 1.08 +/- 0.46
---------------evaluation finished---------------  took 23.33 seconds
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 76 completed in 89.04 seconds.
Time to collect_rollouts 89.15
Training model
Time to train 107.89
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.45         |
|    ep_rew_mean          | 0.38         |
| time/                   |              |
|    fps                  | 335          |
|    iterations           | 76           |
|    total_timesteps      | 4980736      |
| train/                  |              |
|    approx_kl            | 0.0027471334 |
|    clip_fraction        | 0.0131       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.972       |
|    explained_variance   | 0.937        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.105       |
|    n_updates            | 760          |
|    policy_gradient_loss | -0.00351     |
|    value_loss           | 0.0103       |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
---------------evaluation started---------------
Eval num_timesteps=5026816, episode_reward=0.76 +/- 0.43
Episode length: 1.07 +/- 0.42
---------------evaluation finished---------------  took 17.48 seconds
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 77 completed in 82.87 seconds.
Time to collect_rollouts 82.99
Training model
Time to train 116.94
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.51         |
|    ep_rew_mean          | 0.41         |
| time/                   |              |
|    fps                  | 335          |
|    iterations           | 77           |
|    total_timesteps      | 5046272      |
| train/                  |              |
|    approx_kl            | 0.0024454773 |
|    clip_fraction        | 0.00925      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.97        |
|    explained_variance   | 0.939        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.101       |
|    n_updates            | 770          |
|    policy_gradient_loss | -0.00341     |
|    value_loss           | 0.0104       |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
---------------evaluation started---------------
Eval num_timesteps=5092096, episode_reward=0.76 +/- 0.43
Episode length: 1.07 +/- 0.40
---------------evaluation finished---------------  took 16.79 seconds
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 78 completed in 82.14 seconds.
Time to collect_rollouts 82.25
Training model
Time to train 114.9
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.66        |
|    ep_rew_mean          | 0.31        |
| time/                   |             |
|    fps                  | 335         |
|    iterations           | 78          |
|    total_timesteps      | 5111808     |
| train/                  |             |
|    approx_kl            | 0.002517536 |
|    clip_fraction        | 0.0113      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.96       |
|    explained_variance   | 0.942       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.101      |
|    n_updates            | 780         |
|    policy_gradient_loss | -0.00347    |
|    value_loss           | 0.00954     |
-----------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
---------------evaluation started---------------
Eval num_timesteps=5157376, episode_reward=0.76 +/- 0.43
Episode length: 1.07 +/- 0.40
---------------evaluation finished---------------  took 12.86 seconds
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 79 completed in 77.93 seconds.
Time to collect_rollouts 79.6
Training model
Time to train 115.62
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.65         |
|    ep_rew_mean          | 0.36         |
| time/                   |              |
|    fps                  | 335          |
|    iterations           | 79           |
|    total_timesteps      | 5177344      |
| train/                  |              |
|    approx_kl            | 0.0027365058 |
|    clip_fraction        | 0.0117       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.973       |
|    explained_variance   | 0.935        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.106       |
|    n_updates            | 790          |
|    policy_gradient_loss | -0.00364     |
|    value_loss           | 0.0107       |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
---------------evaluation started---------------
Eval num_timesteps=5222656, episode_reward=0.76 +/- 0.43
Episode length: 1.07 +/- 0.36
---------------evaluation finished---------------  took 17.21 seconds
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 80 completed in 81.01 seconds.
Time to collect_rollouts 81.12
Training model
Time to train 106.18
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.53         |
|    ep_rew_mean          | 0.31         |
| time/                   |              |
|    fps                  | 335          |
|    iterations           | 80           |
|    total_timesteps      | 5242880      |
| train/                  |              |
|    approx_kl            | 0.0025936991 |
|    clip_fraction        | 0.0113       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.966       |
|    explained_variance   | 0.938        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0986      |
|    n_updates            | 800          |
|    policy_gradient_loss | -0.00379     |
|    value_loss           | 0.00997      |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
---------------evaluation started---------------
Eval num_timesteps=5287936, episode_reward=0.76 +/- 0.43
Episode length: 1.08 +/- 0.43
---------------evaluation finished---------------  took 17.36 seconds
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 81 completed in 84.87 seconds.
Time to collect_rollouts 84.98
Training model
Time to train 106.82
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.76         |
|    ep_rew_mean          | 0.4          |
| time/                   |              |
|    fps                  | 335          |
|    iterations           | 81           |
|    total_timesteps      | 5308416      |
| train/                  |              |
|    approx_kl            | 0.0023856487 |
|    clip_fraction        | 0.0102       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.955       |
|    explained_variance   | 0.933        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.101       |
|    n_updates            | 810          |
|    policy_gradient_loss | -0.00394     |
|    value_loss           | 0.0107       |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
---------------evaluation started---------------
Eval num_timesteps=5353216, episode_reward=0.76 +/- 0.43
Episode length: 1.08 +/- 0.40
---------------evaluation finished---------------  took 23.28 seconds
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 82 completed in 88.98 seconds.
Time to collect_rollouts 89.09
Training model
Time to train 104.56
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.99         |
|    ep_rew_mean          | 0.33         |
| time/                   |              |
|    fps                  | 335          |
|    iterations           | 82           |
|    total_timesteps      | 5373952      |
| train/                  |              |
|    approx_kl            | 0.0023674285 |
|    clip_fraction        | 0.00815      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.96        |
|    explained_variance   | 0.941        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0825      |
|    n_updates            | 820          |
|    policy_gradient_loss | -0.00315     |
|    value_loss           | 0.00991      |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
---------------evaluation started---------------
Eval num_timesteps=5418496, episode_reward=0.76 +/- 0.43
Episode length: 1.07 +/- 0.41
---------------evaluation finished---------------  took 17.29 seconds
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 83 completed in 82.65 seconds.
Time to collect_rollouts 82.77
Training model
Time to train 114.93
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.63         |
|    ep_rew_mean          | 0.39         |
| time/                   |              |
|    fps                  | 335          |
|    iterations           | 83           |
|    total_timesteps      | 5439488      |
| train/                  |              |
|    approx_kl            | 0.0026068417 |
|    clip_fraction        | 0.0103       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.973       |
|    explained_variance   | 0.94         |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0978      |
|    n_updates            | 830          |
|    policy_gradient_loss | -0.00362     |
|    value_loss           | 0.00993      |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
---------------evaluation started---------------
Eval num_timesteps=5483776, episode_reward=0.76 +/- 0.43
Episode length: 1.07 +/- 0.37
New best mean reward!
---------------evaluation finished---------------  took 15.65 seconds
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 84 completed in 81.14 seconds.
Time to collect_rollouts 81.25
Training model
Time to train 119.61
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.43        |
|    ep_rew_mean          | 0.43        |
| time/                   |             |
|    fps                  | 335         |
|    iterations           | 84          |
|    total_timesteps      | 5505024     |
| train/                  |             |
|    approx_kl            | 0.002708099 |
|    clip_fraction        | 0.0115      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.967      |
|    explained_variance   | 0.935       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0973     |
|    n_updates            | 840         |
|    policy_gradient_loss | -0.00356    |
|    value_loss           | 0.0108      |
-----------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
---------------evaluation started---------------
Eval num_timesteps=5549056, episode_reward=0.76 +/- 0.43
Episode length: 1.08 +/- 0.41
---------------evaluation finished---------------  took 10.42 seconds
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 85 completed in 75.73 seconds.
Time to collect_rollouts 75.83
Training model
Time to train 118.74
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.72        |
|    ep_rew_mean          | 0.32        |
| time/                   |             |
|    fps                  | 335         |
|    iterations           | 85          |
|    total_timesteps      | 5570560     |
| train/                  |             |
|    approx_kl            | 0.002350598 |
|    clip_fraction        | 0.00839     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.968      |
|    explained_variance   | 0.946       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0794     |
|    n_updates            | 850         |
|    policy_gradient_loss | -0.00341    |
|    value_loss           | 0.00897     |
-----------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
---------------evaluation started---------------
Eval num_timesteps=5614336, episode_reward=0.76 +/- 0.43
Episode length: 1.08 +/- 0.43
---------------evaluation finished---------------  took 14.60 seconds
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 86 completed in 79.82 seconds.
Time to collect_rollouts 79.93
Training model
Time to train 113.49
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.87         |
|    ep_rew_mean          | 0.33         |
| time/                   |              |
|    fps                  | 335          |
|    iterations           | 86           |
|    total_timesteps      | 5636096      |
| train/                  |              |
|    approx_kl            | 0.0027756304 |
|    clip_fraction        | 0.0131       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.963       |
|    explained_variance   | 0.942        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0832      |
|    n_updates            | 860          |
|    policy_gradient_loss | -0.00308     |
|    value_loss           | 0.00985      |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
---------------evaluation started---------------
Eval num_timesteps=5679616, episode_reward=0.76 +/- 0.43
Episode length: 1.08 +/- 0.48
---------------evaluation finished---------------  took 14.16 seconds
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 87 completed in 80.00 seconds.
Time to collect_rollouts 80.12
Training model
Time to train 110.07
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.3          |
|    ep_rew_mean          | 0.33         |
| time/                   |              |
|    fps                  | 335          |
|    iterations           | 87           |
|    total_timesteps      | 5701632      |
| train/                  |              |
|    approx_kl            | 0.0026420099 |
|    clip_fraction        | 0.011        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.97        |
|    explained_variance   | 0.942        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0963      |
|    n_updates            | 870          |
|    policy_gradient_loss | -0.00356     |
|    value_loss           | 0.00976      |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
---------------evaluation started---------------
Eval num_timesteps=5744896, episode_reward=0.76 +/- 0.43
Episode length: 1.08 +/- 0.44
---------------evaluation finished---------------  took 17.02 seconds
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 88 completed in 82.91 seconds.
Time to collect_rollouts 83.02
Training model
Time to train 107.39
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.05        |
|    ep_rew_mean          | 0.36        |
| time/                   |             |
|    fps                  | 335         |
|    iterations           | 88          |
|    total_timesteps      | 5767168     |
| train/                  |             |
|    approx_kl            | 0.002632502 |
|    clip_fraction        | 0.0121      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.959      |
|    explained_variance   | 0.94        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0983     |
|    n_updates            | 880         |
|    policy_gradient_loss | -0.00368    |
|    value_loss           | 0.00975     |
-----------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
---------------evaluation started---------------
Eval num_timesteps=5810176, episode_reward=0.76 +/- 0.43
Episode length: 1.08 +/- 0.41
---------------evaluation finished---------------  took 15.44 seconds
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 89 completed in 87.48 seconds.
Time to collect_rollouts 87.6
Training model
Time to train 114.66
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.53         |
|    ep_rew_mean          | 0.41         |
| time/                   |              |
|    fps                  | 335          |
|    iterations           | 89           |
|    total_timesteps      | 5832704      |
| train/                  |              |
|    approx_kl            | 0.0024191737 |
|    clip_fraction        | 0.0088       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.955       |
|    explained_variance   | 0.944        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0941      |
|    n_updates            | 890          |
|    policy_gradient_loss | -0.00343     |
|    value_loss           | 0.00933      |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
---------------evaluation started---------------
Eval num_timesteps=5875456, episode_reward=0.76 +/- 0.43
Episode length: 1.09 +/- 0.51
---------------evaluation finished---------------  took 15.72 seconds
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 90 completed in 80.95 seconds.
Time to collect_rollouts 82.63
Training model
Time to train 114.06
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.74         |
|    ep_rew_mean          | 0.31         |
| time/                   |              |
|    fps                  | 335          |
|    iterations           | 90           |
|    total_timesteps      | 5898240      |
| train/                  |              |
|    approx_kl            | 0.0026915274 |
|    clip_fraction        | 0.0123       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.959       |
|    explained_variance   | 0.938        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0983      |
|    n_updates            | 900          |
|    policy_gradient_loss | -0.00341     |
|    value_loss           | 0.0103       |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
---------------evaluation started---------------
Eval num_timesteps=5940736, episode_reward=0.76 +/- 0.43
Episode length: 1.08 +/- 0.40
---------------evaluation finished---------------  took 15.12 seconds
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 91 completed in 80.18 seconds.
Time to collect_rollouts 80.29
Training model
Time to train 113.15
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.75         |
|    ep_rew_mean          | 0.43         |
| time/                   |              |
|    fps                  | 335          |
|    iterations           | 91           |
|    total_timesteps      | 5963776      |
| train/                  |              |
|    approx_kl            | 0.0025178308 |
|    clip_fraction        | 0.0107       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.957       |
|    explained_variance   | 0.942        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0984      |
|    n_updates            | 910          |
|    policy_gradient_loss | -0.00342     |
|    value_loss           | 0.0094       |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
---------------evaluation started---------------
Eval num_timesteps=6006016, episode_reward=0.76 +/- 0.43
Episode length: 1.07 +/- 0.39
---------------evaluation finished---------------  took 15.44 seconds
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 92 completed in 80.74 seconds.
Time to collect_rollouts 80.85
Training model
Time to train 111.0
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.49         |
|    ep_rew_mean          | 0.36         |
| time/                   |              |
|    fps                  | 335          |
|    iterations           | 92           |
|    total_timesteps      | 6029312      |
| train/                  |              |
|    approx_kl            | 0.0022795694 |
|    clip_fraction        | 0.00724      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.968       |
|    explained_variance   | 0.941        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0879      |
|    n_updates            | 920          |
|    policy_gradient_loss | -0.00339     |
|    value_loss           | 0.0102       |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
---------------evaluation started---------------
Eval num_timesteps=6071296, episode_reward=0.76 +/- 0.43
Episode length: 1.07 +/- 0.41
---------------evaluation finished---------------  took 15.11 seconds
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 93 completed in 80.84 seconds.
Time to collect_rollouts 80.96
Training model
Time to train 111.88
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.48        |
|    ep_rew_mean          | 0.38        |
| time/                   |             |
|    fps                  | 335         |
|    iterations           | 93          |
|    total_timesteps      | 6094848     |
| train/                  |             |
|    approx_kl            | 0.002386217 |
|    clip_fraction        | 0.00945     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.963      |
|    explained_variance   | 0.942       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0939     |
|    n_updates            | 930         |
|    policy_gradient_loss | -0.00399    |
|    value_loss           | 0.00958     |
-----------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
---------------evaluation started---------------
Eval num_timesteps=6136576, episode_reward=0.76 +/- 0.43
Episode length: 1.07 +/- 0.36
---------------evaluation finished---------------  took 14.00 seconds
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 94 completed in 79.82 seconds.
Time to collect_rollouts 79.94
Training model
Time to train 111.46
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.7        |
|    ep_rew_mean          | 0.43       |
| time/                   |            |
|    fps                  | 335        |
|    iterations           | 94         |
|    total_timesteps      | 6160384    |
| train/                  |            |
|    approx_kl            | 0.00263041 |
|    clip_fraction        | 0.0117     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.967     |
|    explained_variance   | 0.946      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0903    |
|    n_updates            | 940        |
|    policy_gradient_loss | -0.00396   |
|    value_loss           | 0.00912    |
----------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
---------------evaluation started---------------
Eval num_timesteps=6201856, episode_reward=0.76 +/- 0.43
Episode length: 1.07 +/- 0.42
---------------evaluation finished---------------  took 18.70 seconds
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 95 completed in 84.14 seconds.
Time to collect_rollouts 84.23
Training model
Time to train 107.39
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.51         |
|    ep_rew_mean          | 0.36         |
| time/                   |              |
|    fps                  | 335          |
|    iterations           | 95           |
|    total_timesteps      | 6225920      |
| train/                  |              |
|    approx_kl            | 0.0026335795 |
|    clip_fraction        | 0.0141       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.969       |
|    explained_variance   | 0.948        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.104       |
|    n_updates            | 950          |
|    policy_gradient_loss | -0.00406     |
|    value_loss           | 0.0089       |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
---------------evaluation started---------------
Eval num_timesteps=6267136, episode_reward=0.76 +/- 0.43
Episode length: 1.07 +/- 0.39
---------------evaluation finished---------------  took 17.17 seconds
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 96 completed in 82.58 seconds.
Time to collect_rollouts 82.69
Training model
Time to train 113.45
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.71         |
|    ep_rew_mean          | 0.34         |
| time/                   |              |
|    fps                  | 335          |
|    iterations           | 96           |
|    total_timesteps      | 6291456      |
| train/                  |              |
|    approx_kl            | 0.0025913138 |
|    clip_fraction        | 0.00987      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.963       |
|    explained_variance   | 0.945        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.106       |
|    n_updates            | 960          |
|    policy_gradient_loss | -0.00394     |
|    value_loss           | 0.00899      |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
---------------evaluation started---------------
Eval num_timesteps=6332416, episode_reward=0.76 +/- 0.43
Episode length: 1.09 +/- 0.51
---------------evaluation finished---------------  took 17.52 seconds
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 97 completed in 83.41 seconds.
Time to collect_rollouts 83.52
Training model
Time to train 112.56
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.81         |
|    ep_rew_mean          | 0.44         |
| time/                   |              |
|    fps                  | 335          |
|    iterations           | 97           |
|    total_timesteps      | 6356992      |
| train/                  |              |
|    approx_kl            | 0.0027012895 |
|    clip_fraction        | 0.0116       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.963       |
|    explained_variance   | 0.949        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.118       |
|    n_updates            | 970          |
|    policy_gradient_loss | -0.00377     |
|    value_loss           | 0.00875      |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
---------------evaluation started---------------
Eval num_timesteps=6397696, episode_reward=0.76 +/- 0.43
Episode length: 1.09 +/- 0.46
---------------evaluation finished---------------  took 16.93 seconds
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 98 completed in 82.37 seconds.
Time to collect_rollouts 82.48
Training model
Time to train 83.68
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.3         |
|    ep_rew_mean          | 0.44        |
| time/                   |             |
|    fps                  | 336         |
|    iterations           | 98          |
|    total_timesteps      | 6422528     |
| train/                  |             |
|    approx_kl            | 0.003037901 |
|    clip_fraction        | 0.0156      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.959      |
|    explained_variance   | 0.944       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0858     |
|    n_updates            | 980         |
|    policy_gradient_loss | -0.00421    |
|    value_loss           | 0.00906     |
-----------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
---------------evaluation started---------------
Eval num_timesteps=6462976, episode_reward=0.76 +/- 0.43
Episode length: 1.08 +/- 0.43
---------------evaluation finished---------------  took 16.69 seconds
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 99 completed in 81.87 seconds.
Time to collect_rollouts 81.99
Training model
Time to train 70.09
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.51        |
|    ep_rew_mean          | 0.35        |
| time/                   |             |
|    fps                  | 337         |
|    iterations           | 99          |
|    total_timesteps      | 6488064     |
| train/                  |             |
|    approx_kl            | 0.002781238 |
|    clip_fraction        | 0.0124      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.964      |
|    explained_variance   | 0.948       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.106      |
|    n_updates            | 990         |
|    policy_gradient_loss | -0.00385    |
|    value_loss           | 0.00847     |
-----------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
---------------evaluation started---------------
Eval num_timesteps=6528256, episode_reward=0.76 +/- 0.43
Episode length: 1.07 +/- 0.41
---------------evaluation finished---------------  took 14.66 seconds
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 100 completed in 79.77 seconds.
Time to collect_rollouts 79.88
Training model
Time to train 94.46
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.89         |
|    ep_rew_mean          | 0.35         |
| time/                   |              |
|    fps                  | 337          |
|    iterations           | 100          |
|    total_timesteps      | 6553600      |
| train/                  |              |
|    approx_kl            | 0.0029294975 |
|    clip_fraction        | 0.0138       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.959       |
|    explained_variance   | 0.947        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0988      |
|    n_updates            | 1000         |
|    policy_gradient_loss | -0.00401     |
|    value_loss           | 0.00892      |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
---------------evaluation started---------------
Eval num_timesteps=6593536, episode_reward=0.76 +/- 0.43
Episode length: 1.08 +/- 0.45
---------------evaluation finished---------------  took 14.19 seconds
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 101 completed in 79.64 seconds.
Time to collect_rollouts 79.74
Training model
Time to train 119.03
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.68        |
|    ep_rew_mean          | 0.43        |
| time/                   |             |
|    fps                  | 337         |
|    iterations           | 101         |
|    total_timesteps      | 6619136     |
| train/                  |             |
|    approx_kl            | 0.002988682 |
|    clip_fraction        | 0.012       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.962      |
|    explained_variance   | 0.948       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0971     |
|    n_updates            | 1010        |
|    policy_gradient_loss | -0.00416    |
|    value_loss           | 0.00842     |
-----------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
---------------evaluation started---------------
Eval num_timesteps=6658816, episode_reward=0.76 +/- 0.43
Episode length: 1.07 +/- 0.41
---------------evaluation finished---------------  took 12.13 seconds
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 102 completed in 79.01 seconds.
Time to collect_rollouts 79.12
Training model
Time to train 117.86
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.65         |
|    ep_rew_mean          | 0.35         |
| time/                   |              |
|    fps                  | 337          |
|    iterations           | 102          |
|    total_timesteps      | 6684672      |
| train/                  |              |
|    approx_kl            | 0.0027779466 |
|    clip_fraction        | 0.0114       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.957       |
|    explained_variance   | 0.948        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.103       |
|    n_updates            | 1020         |
|    policy_gradient_loss | -0.00372     |
|    value_loss           | 0.00869      |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
Collecting rollouts: 153/256 steps
---------------evaluation started---------------
Eval num_timesteps=6724096, episode_reward=0.76 +/- 0.43
Episode length: 1.07 +/- 0.43
---------------evaluation finished---------------  took 15.52 seconds
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 103 completed in 80.79 seconds.
Time to collect_rollouts 80.91
Training model
Time to train 114.95
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.57         |
|    ep_rew_mean          | 0.4          |
| time/                   |              |
|    fps                  | 337          |
|    iterations           | 103          |
|    total_timesteps      | 6750208      |
| train/                  |              |
|    approx_kl            | 0.0032806078 |
|    clip_fraction        | 0.0169       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.966       |
|    explained_variance   | 0.945        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.11        |
|    n_updates            | 1030         |
|    policy_gradient_loss | -0.00409     |
|    value_loss           | 0.00874      |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
---------------evaluation started---------------
Eval num_timesteps=6789376, episode_reward=0.76 +/- 0.43
Episode length: 1.07 +/- 0.39
---------------evaluation finished---------------  took 14.19 seconds
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 104 completed in 79.70 seconds.
Time to collect_rollouts 79.81
Training model
Time to train 110.11
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.61         |
|    ep_rew_mean          | 0.35         |
| time/                   |              |
|    fps                  | 337          |
|    iterations           | 104          |
|    total_timesteps      | 6815744      |
| train/                  |              |
|    approx_kl            | 0.0026477743 |
|    clip_fraction        | 0.0105       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.96        |
|    explained_variance   | 0.945        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0986      |
|    n_updates            | 1040         |
|    policy_gradient_loss | -0.00368     |
|    value_loss           | 0.00884      |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
---------------evaluation started---------------
Eval num_timesteps=6854656, episode_reward=0.76 +/- 0.43
Episode length: 1.08 +/- 0.43
---------------evaluation finished---------------  took 16.10 seconds
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 105 completed in 81.81 seconds.
Time to collect_rollouts 81.93
Training model
Time to train 109.42
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.59        |
|    ep_rew_mean          | 0.3         |
| time/                   |             |
|    fps                  | 337         |
|    iterations           | 105         |
|    total_timesteps      | 6881280     |
| train/                  |             |
|    approx_kl            | 0.003091163 |
|    clip_fraction        | 0.0153      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.959      |
|    explained_variance   | 0.949       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.107      |
|    n_updates            | 1050        |
|    policy_gradient_loss | -0.00446    |
|    value_loss           | 0.00821     |
-----------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
---------------evaluation started---------------
Eval num_timesteps=6919936, episode_reward=0.76 +/- 0.43
Episode length: 1.08 +/- 0.44
---------------evaluation finished---------------  took 14.39 seconds
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 106 completed in 79.47 seconds.
Time to collect_rollouts 79.59
Training model
Time to train 116.15
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.61         |
|    ep_rew_mean          | 0.38         |
| time/                   |              |
|    fps                  | 337          |
|    iterations           | 106          |
|    total_timesteps      | 6946816      |
| train/                  |              |
|    approx_kl            | 0.0026620966 |
|    clip_fraction        | 0.0104       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.965       |
|    explained_variance   | 0.947        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.107       |
|    n_updates            | 1060         |
|    policy_gradient_loss | -0.00394     |
|    value_loss           | 0.00846      |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
---------------evaluation started---------------
Eval num_timesteps=6985216, episode_reward=0.76 +/- 0.43
Episode length: 1.07 +/- 0.43
---------------evaluation finished---------------  took 14.96 seconds
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 107 completed in 80.57 seconds.
Time to collect_rollouts 80.68
Training model
Time to train 109.11
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.36         |
|    ep_rew_mean          | 0.43         |
| time/                   |              |
|    fps                  | 337          |
|    iterations           | 107          |
|    total_timesteps      | 7012352      |
| train/                  |              |
|    approx_kl            | 0.0027773585 |
|    clip_fraction        | 0.0122       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.956       |
|    explained_variance   | 0.945        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.107       |
|    n_updates            | 1070         |
|    policy_gradient_loss | -0.00391     |
|    value_loss           | 0.00886      |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
---------------evaluation started---------------
Eval num_timesteps=7050496, episode_reward=0.76 +/- 0.43
Episode length: 1.08 +/- 0.45
---------------evaluation finished---------------  took 16.26 seconds
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 108 completed in 82.34 seconds.
Time to collect_rollouts 82.46
Training model
Time to train 83.87
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.89         |
|    ep_rew_mean          | 0.42         |
| time/                   |              |
|    fps                  | 338          |
|    iterations           | 108          |
|    total_timesteps      | 7077888      |
| train/                  |              |
|    approx_kl            | 0.0029036975 |
|    clip_fraction        | 0.0134       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.954       |
|    explained_variance   | 0.948        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.09        |
|    n_updates            | 1080         |
|    policy_gradient_loss | -0.0043      |
|    value_loss           | 0.00824      |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
---------------evaluation started---------------
Eval num_timesteps=7115776, episode_reward=0.76 +/- 0.43
Episode length: 1.08 +/- 0.45
New best mean reward!
---------------evaluation finished---------------  took 14.10 seconds
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 109 completed in 79.38 seconds.
Time to collect_rollouts 79.49
Training model
Time to train 117.44
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.72         |
|    ep_rew_mean          | 0.35         |
| time/                   |              |
|    fps                  | 337          |
|    iterations           | 109          |
|    total_timesteps      | 7143424      |
| train/                  |              |
|    approx_kl            | 0.0031502964 |
|    clip_fraction        | 0.0165       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.962       |
|    explained_variance   | 0.952        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0967      |
|    n_updates            | 1090         |
|    policy_gradient_loss | -0.00378     |
|    value_loss           | 0.00813      |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
---------------evaluation started---------------
Eval num_timesteps=7181056, episode_reward=0.76 +/- 0.43
Episode length: 1.09 +/- 0.47
---------------evaluation finished---------------  took 14.29 seconds
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 110 completed in 79.73 seconds.
Time to collect_rollouts 79.85
Training model
Time to train 120.62
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.66        |
|    ep_rew_mean          | 0.37        |
| time/                   |             |
|    fps                  | 337         |
|    iterations           | 110         |
|    total_timesteps      | 7208960     |
| train/                  |             |
|    approx_kl            | 0.002832952 |
|    clip_fraction        | 0.0122      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.962      |
|    explained_variance   | 0.949       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.108      |
|    n_updates            | 1100        |
|    policy_gradient_loss | -0.00433    |
|    value_loss           | 0.00821     |
-----------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
---------------evaluation started---------------
Eval num_timesteps=7246336, episode_reward=0.76 +/- 0.43
Episode length: 1.08 +/- 0.45
---------------evaluation finished---------------  took 10.78 seconds
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 111 completed in 76.29 seconds.
Time to collect_rollouts 76.41
Training model
Time to train 119.5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.52        |
|    ep_rew_mean          | 0.33        |
| time/                   |             |
|    fps                  | 337         |
|    iterations           | 111         |
|    total_timesteps      | 7274496     |
| train/                  |             |
|    approx_kl            | 0.003046937 |
|    clip_fraction        | 0.0146      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.965      |
|    explained_variance   | 0.946       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.107      |
|    n_updates            | 1110        |
|    policy_gradient_loss | -0.0041     |
|    value_loss           | 0.00876     |
-----------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
---------------evaluation started---------------
Eval num_timesteps=7311616, episode_reward=0.76 +/- 0.43
Episode length: 1.08 +/- 0.47
---------------evaluation finished---------------  took 16.64 seconds
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 112 completed in 82.19 seconds.
Time to collect_rollouts 82.31
Training model
Time to train 110.92
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.31         |
|    ep_rew_mean          | 0.4          |
| time/                   |              |
|    fps                  | 337          |
|    iterations           | 112          |
|    total_timesteps      | 7340032      |
| train/                  |              |
|    approx_kl            | 0.0029175177 |
|    clip_fraction        | 0.0133       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.957       |
|    explained_variance   | 0.95         |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0862      |
|    n_updates            | 1120         |
|    policy_gradient_loss | -0.0039      |
|    value_loss           | 0.00819      |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
---------------evaluation started---------------
Eval num_timesteps=7376896, episode_reward=0.76 +/- 0.43
Episode length: 1.07 +/- 0.42
---------------evaluation finished---------------  took 17.42 seconds
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 113 completed in 82.95 seconds.
Time to collect_rollouts 83.06
Training model
Time to train 107.62
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.58         |
|    ep_rew_mean          | 0.29         |
| time/                   |              |
|    fps                  | 337          |
|    iterations           | 113          |
|    total_timesteps      | 7405568      |
| train/                  |              |
|    approx_kl            | 0.0031595433 |
|    clip_fraction        | 0.0147       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.96        |
|    explained_variance   | 0.946        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0998      |
|    n_updates            | 1130         |
|    policy_gradient_loss | -0.00414     |
|    value_loss           | 0.00876      |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
---------------evaluation started---------------
Eval num_timesteps=7442176, episode_reward=0.76 +/- 0.43
Episode length: 1.08 +/- 0.43
---------------evaluation finished---------------  took 23.75 seconds
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 114 completed in 89.48 seconds.
Time to collect_rollouts 89.6
Training model
Time to train 108.44
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.6         |
|    ep_rew_mean          | 0.31        |
| time/                   |             |
|    fps                  | 337         |
|    iterations           | 114         |
|    total_timesteps      | 7471104     |
| train/                  |             |
|    approx_kl            | 0.002899975 |
|    clip_fraction        | 0.0113      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.951      |
|    explained_variance   | 0.949       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0811     |
|    n_updates            | 1140        |
|    policy_gradient_loss | -0.0042     |
|    value_loss           | 0.00854     |
-----------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
---------------evaluation started---------------
Eval num_timesteps=7507456, episode_reward=0.76 +/- 0.43
Episode length: 1.08 +/- 0.44
---------------evaluation finished---------------  took 17.61 seconds
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 115 completed in 83.24 seconds.
Time to collect_rollouts 83.35
Training model
Time to train 102.05
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.4          |
|    ep_rew_mean          | 0.44         |
| time/                   |              |
|    fps                  | 337          |
|    iterations           | 115          |
|    total_timesteps      | 7536640      |
| train/                  |              |
|    approx_kl            | 0.0032189928 |
|    clip_fraction        | 0.017        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.954       |
|    explained_variance   | 0.949        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.104       |
|    n_updates            | 1150         |
|    policy_gradient_loss | -0.00484     |
|    value_loss           | 0.00839      |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
---------------evaluation started---------------
Eval num_timesteps=7572736, episode_reward=0.76 +/- 0.43
Episode length: 1.08 +/- 0.41
---------------evaluation finished---------------  took 17.64 seconds
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 116 completed in 83.23 seconds.
Time to collect_rollouts 83.34
Training model
Time to train 97.75
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.52         |
|    ep_rew_mean          | 0.31         |
| time/                   |              |
|    fps                  | 338          |
|    iterations           | 116          |
|    total_timesteps      | 7602176      |
| train/                  |              |
|    approx_kl            | 0.0030928538 |
|    clip_fraction        | 0.0159       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.96        |
|    explained_variance   | 0.95         |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0997      |
|    n_updates            | 1160         |
|    policy_gradient_loss | -0.00417     |
|    value_loss           | 0.00797      |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
---------------evaluation started---------------
Eval num_timesteps=7638016, episode_reward=0.76 +/- 0.43
Episode length: 1.07 +/- 0.43
---------------evaluation finished---------------  took 17.41 seconds
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 117 completed in 84.64 seconds.
Time to collect_rollouts 84.75
Training model
Time to train 114.14
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.62       |
|    ep_rew_mean          | 0.39       |
| time/                   |            |
|    fps                  | 338        |
|    iterations           | 117        |
|    total_timesteps      | 7667712    |
| train/                  |            |
|    approx_kl            | 0.00312462 |
|    clip_fraction        | 0.0137     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.972     |
|    explained_variance   | 0.954      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.104     |
|    n_updates            | 1170       |
|    policy_gradient_loss | -0.00373   |
|    value_loss           | 0.00751    |
----------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
---------------evaluation started---------------
Eval num_timesteps=7703296, episode_reward=0.76 +/- 0.43
Episode length: 1.08 +/- 0.42
---------------evaluation finished---------------  took 16.90 seconds
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 118 completed in 82.65 seconds.
Time to collect_rollouts 82.76
Training model
Time to train 107.67
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.47        |
|    ep_rew_mean          | 0.35        |
| time/                   |             |
|    fps                  | 338         |
|    iterations           | 118         |
|    total_timesteps      | 7733248     |
| train/                  |             |
|    approx_kl            | 0.002780692 |
|    clip_fraction        | 0.0115      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.95       |
|    explained_variance   | 0.955       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.118      |
|    n_updates            | 1180        |
|    policy_gradient_loss | -0.0039     |
|    value_loss           | 0.00767     |
-----------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
---------------evaluation started---------------
Eval num_timesteps=7768576, episode_reward=0.76 +/- 0.43
Episode length: 1.09 +/- 0.48
---------------evaluation finished---------------  took 19.79 seconds
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 119 completed in 85.97 seconds.
Time to collect_rollouts 86.09
Training model
Time to train 107.88
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.67         |
|    ep_rew_mean          | 0.44         |
| time/                   |              |
|    fps                  | 338          |
|    iterations           | 119          |
|    total_timesteps      | 7798784      |
| train/                  |              |
|    approx_kl            | 0.0035226606 |
|    clip_fraction        | 0.0172       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.962       |
|    explained_variance   | 0.954        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.102       |
|    n_updates            | 1190         |
|    policy_gradient_loss | -0.0048      |
|    value_loss           | 0.00723      |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
---------------evaluation started---------------
Eval num_timesteps=7833856, episode_reward=0.76 +/- 0.43
Episode length: 1.08 +/- 0.42
---------------evaluation finished---------------  took 14.03 seconds
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 120 completed in 79.58 seconds.
Time to collect_rollouts 79.67
Training model
Time to train 109.17
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.61        |
|    ep_rew_mean          | 0.37        |
| time/                   |             |
|    fps                  | 338         |
|    iterations           | 120         |
|    total_timesteps      | 7864320     |
| train/                  |             |
|    approx_kl            | 0.002741674 |
|    clip_fraction        | 0.0108      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.955      |
|    explained_variance   | 0.953       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.117      |
|    n_updates            | 1200        |
|    policy_gradient_loss | -0.00379    |
|    value_loss           | 0.00764     |
-----------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
---------------evaluation started---------------
Eval num_timesteps=7899136, episode_reward=0.76 +/- 0.43
Episode length: 1.08 +/- 0.43
---------------evaluation finished---------------  took 18.08 seconds
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 121 completed in 84.07 seconds.
Time to collect_rollouts 84.18
Training model
Time to train 107.45
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.73         |
|    ep_rew_mean          | 0.32         |
| time/                   |              |
|    fps                  | 338          |
|    iterations           | 121          |
|    total_timesteps      | 7929856      |
| train/                  |              |
|    approx_kl            | 0.0033275643 |
|    clip_fraction        | 0.0178       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.953       |
|    explained_variance   | 0.952        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0943      |
|    n_updates            | 1210         |
|    policy_gradient_loss | -0.0044      |
|    value_loss           | 0.00765      |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
---------------evaluation started---------------
Eval num_timesteps=7964416, episode_reward=0.76 +/- 0.43
Episode length: 1.08 +/- 0.44
---------------evaluation finished---------------  took 19.15 seconds
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 122 completed in 84.95 seconds.
Time to collect_rollouts 85.07
Training model
Time to train 107.16
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.67        |
|    ep_rew_mean          | 0.34        |
| time/                   |             |
|    fps                  | 338         |
|    iterations           | 122         |
|    total_timesteps      | 7995392     |
| train/                  |             |
|    approx_kl            | 0.002983515 |
|    clip_fraction        | 0.0141      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.963      |
|    explained_variance   | 0.956       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.092      |
|    n_updates            | 1220        |
|    policy_gradient_loss | -0.00421    |
|    value_loss           | 0.0076      |
-----------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
---------------evaluation started---------------
Eval num_timesteps=8029696, episode_reward=0.76 +/- 0.43
Episode length: 1.08 +/- 0.43
---------------evaluation finished---------------  took 17.09 seconds
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 123 completed in 82.76 seconds.
Time to collect_rollouts 82.87
Training model
Time to train 112.51
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.48         |
|    ep_rew_mean          | 0.3          |
| time/                   |              |
|    fps                  | 338          |
|    iterations           | 123          |
|    total_timesteps      | 8060928      |
| train/                  |              |
|    approx_kl            | 0.0030224326 |
|    clip_fraction        | 0.013        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.965       |
|    explained_variance   | 0.953        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0867      |
|    n_updates            | 1230         |
|    policy_gradient_loss | -0.00447     |
|    value_loss           | 0.00778      |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
---------------evaluation started---------------
Eval num_timesteps=8094976, episode_reward=0.76 +/- 0.43
Episode length: 1.08 +/- 0.46
---------------evaluation finished---------------  took 17.04 seconds
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 124 completed in 82.61 seconds.
Time to collect_rollouts 82.71
Training model
Time to train 117.22
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.73         |
|    ep_rew_mean          | 0.39         |
| time/                   |              |
|    fps                  | 338          |
|    iterations           | 124          |
|    total_timesteps      | 8126464      |
| train/                  |              |
|    approx_kl            | 0.0032958013 |
|    clip_fraction        | 0.0188       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.958       |
|    explained_variance   | 0.952        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0899      |
|    n_updates            | 1240         |
|    policy_gradient_loss | -0.00437     |
|    value_loss           | 0.00769      |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
---------------evaluation started---------------
Eval num_timesteps=8160256, episode_reward=0.76 +/- 0.43
Episode length: 1.09 +/- 0.48
---------------evaluation finished---------------  took 11.95 seconds
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 125 completed in 77.42 seconds.
Time to collect_rollouts 77.53
Training model
Time to train 117.74
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.95        |
|    ep_rew_mean          | 0.3         |
| time/                   |             |
|    fps                  | 338         |
|    iterations           | 125         |
|    total_timesteps      | 8192000     |
| train/                  |             |
|    approx_kl            | 0.003096027 |
|    clip_fraction        | 0.0135      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.959      |
|    explained_variance   | 0.954       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0873     |
|    n_updates            | 1250        |
|    policy_gradient_loss | -0.00435    |
|    value_loss           | 0.00743     |
-----------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
---------------evaluation started---------------
Eval num_timesteps=8225536, episode_reward=0.76 +/- 0.43
Episode length: 1.08 +/- 0.42
---------------evaluation finished---------------  took 16.05 seconds
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 126 completed in 81.29 seconds.
Time to collect_rollouts 81.4
Training model
Time to train 111.78
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.57         |
|    ep_rew_mean          | 0.39         |
| time/                   |              |
|    fps                  | 338          |
|    iterations           | 126          |
|    total_timesteps      | 8257536      |
| train/                  |              |
|    approx_kl            | 0.0032377136 |
|    clip_fraction        | 0.015        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.957       |
|    explained_variance   | 0.954        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0981      |
|    n_updates            | 1260         |
|    policy_gradient_loss | -0.00412     |
|    value_loss           | 0.00742      |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
---------------evaluation started---------------
Eval num_timesteps=8290816, episode_reward=0.76 +/- 0.43
Episode length: 1.08 +/- 0.43
---------------evaluation finished---------------  took 14.18 seconds
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 127 completed in 79.90 seconds.
Time to collect_rollouts 79.99
Training model
Time to train 106.89
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.85         |
|    ep_rew_mean          | 0.35         |
| time/                   |              |
|    fps                  | 338          |
|    iterations           | 127          |
|    total_timesteps      | 8323072      |
| train/                  |              |
|    approx_kl            | 0.0034474384 |
|    clip_fraction        | 0.0196       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.972       |
|    explained_variance   | 0.956        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.115       |
|    n_updates            | 1270         |
|    policy_gradient_loss | -0.00448     |
|    value_loss           | 0.00719      |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
---------------evaluation started---------------
Eval num_timesteps=8356096, episode_reward=0.76 +/- 0.43
Episode length: 1.07 +/- 0.40
---------------evaluation finished---------------  took 15.27 seconds
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 128 completed in 80.79 seconds.
Time to collect_rollouts 80.9
Training model
Time to train 73.28
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.74         |
|    ep_rew_mean          | 0.26         |
| time/                   |              |
|    fps                  | 338          |
|    iterations           | 128          |
|    total_timesteps      | 8388608      |
| train/                  |              |
|    approx_kl            | 0.0032017415 |
|    clip_fraction        | 0.0159       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.955       |
|    explained_variance   | 0.953        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0955      |
|    n_updates            | 1280         |
|    policy_gradient_loss | -0.0045      |
|    value_loss           | 0.00719      |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
---------------evaluation started---------------
Eval num_timesteps=8421376, episode_reward=0.76 +/- 0.43
Episode length: 1.07 +/- 0.37
---------------evaluation finished---------------  took 15.33 seconds
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 129 completed in 80.66 seconds.
Time to collect_rollouts 80.76
Training model
Time to train 118.9
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.47         |
|    ep_rew_mean          | 0.35         |
| time/                   |              |
|    fps                  | 338          |
|    iterations           | 129          |
|    total_timesteps      | 8454144      |
| train/                  |              |
|    approx_kl            | 0.0031968264 |
|    clip_fraction        | 0.0163       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.963       |
|    explained_variance   | 0.956        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.108       |
|    n_updates            | 1290         |
|    policy_gradient_loss | -0.00432     |
|    value_loss           | 0.00745      |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
---------------evaluation started---------------
Eval num_timesteps=8486656, episode_reward=0.76 +/- 0.43
Episode length: 1.07 +/- 0.38
---------------evaluation finished---------------  took 12.95 seconds
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 130 completed in 78.26 seconds.
Time to collect_rollouts 80.11
Training model
Time to train 120.25
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.64         |
|    ep_rew_mean          | 0.45         |
| time/                   |              |
|    fps                  | 338          |
|    iterations           | 130          |
|    total_timesteps      | 8519680      |
| train/                  |              |
|    approx_kl            | 0.0032379858 |
|    clip_fraction        | 0.0158       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.959       |
|    explained_variance   | 0.955        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0967      |
|    n_updates            | 1300         |
|    policy_gradient_loss | -0.00408     |
|    value_loss           | 0.00767      |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
---------------evaluation started---------------
Eval num_timesteps=8551936, episode_reward=0.76 +/- 0.43
Episode length: 1.06 +/- 0.36
---------------evaluation finished---------------  took 17.02 seconds
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 131 completed in 82.71 seconds.
Time to collect_rollouts 82.8
Training model
Time to train 111.54
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.83         |
|    ep_rew_mean          | 0.39         |
| time/                   |              |
|    fps                  | 338          |
|    iterations           | 131          |
|    total_timesteps      | 8585216      |
| train/                  |              |
|    approx_kl            | 0.0035460389 |
|    clip_fraction        | 0.019        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.969       |
|    explained_variance   | 0.951        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.095       |
|    n_updates            | 1310         |
|    policy_gradient_loss | -0.00483     |
|    value_loss           | 0.00755      |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
---------------evaluation started---------------
Eval num_timesteps=8617216, episode_reward=0.76 +/- 0.43
Episode length: 1.07 +/- 0.42
---------------evaluation finished---------------  took 15.79 seconds
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 132 completed in 81.86 seconds.
Time to collect_rollouts 81.98
Training model
Time to train 108.84
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.93         |
|    ep_rew_mean          | 0.31         |
| time/                   |              |
|    fps                  | 338          |
|    iterations           | 132          |
|    total_timesteps      | 8650752      |
| train/                  |              |
|    approx_kl            | 0.0037601122 |
|    clip_fraction        | 0.0195       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.969       |
|    explained_variance   | 0.953        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.101       |
|    n_updates            | 1320         |
|    policy_gradient_loss | -0.00466     |
|    value_loss           | 0.00733      |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
---------------evaluation started---------------
Eval num_timesteps=8682496, episode_reward=0.76 +/- 0.43
Episode length: 1.07 +/- 0.44
---------------evaluation finished---------------  took 15.13 seconds
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 133 completed in 81.10 seconds.
Time to collect_rollouts 81.18
Training model
Time to train 108.85
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.39         |
|    ep_rew_mean          | 0.47         |
| time/                   |              |
|    fps                  | 338          |
|    iterations           | 133          |
|    total_timesteps      | 8716288      |
| train/                  |              |
|    approx_kl            | 0.0032567936 |
|    clip_fraction        | 0.0158       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.962       |
|    explained_variance   | 0.956        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.086       |
|    n_updates            | 1330         |
|    policy_gradient_loss | -0.00388     |
|    value_loss           | 0.00713      |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
---------------evaluation started---------------
Eval num_timesteps=8747776, episode_reward=0.76 +/- 0.43
Episode length: 1.07 +/- 0.38
---------------evaluation finished---------------  took 14.48 seconds
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 134 completed in 80.41 seconds.
Time to collect_rollouts 80.52
Training model
Time to train 118.59
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.65         |
|    ep_rew_mean          | 0.45         |
| time/                   |              |
|    fps                  | 338          |
|    iterations           | 134          |
|    total_timesteps      | 8781824      |
| train/                  |              |
|    approx_kl            | 0.0035968586 |
|    clip_fraction        | 0.0202       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.959       |
|    explained_variance   | 0.956        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0932      |
|    n_updates            | 1340         |
|    policy_gradient_loss | -0.0046      |
|    value_loss           | 0.00699      |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
---------------evaluation started---------------
Eval num_timesteps=8813056, episode_reward=0.76 +/- 0.43
Episode length: 1.07 +/- 0.39
---------------evaluation finished---------------  took 13.63 seconds
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 135 completed in 79.02 seconds.
Time to collect_rollouts 79.13
Training model
Time to train 119.23
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.69         |
|    ep_rew_mean          | 0.35         |
| time/                   |              |
|    fps                  | 338          |
|    iterations           | 135          |
|    total_timesteps      | 8847360      |
| train/                  |              |
|    approx_kl            | 0.0032613385 |
|    clip_fraction        | 0.016        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.96        |
|    explained_variance   | 0.953        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.099       |
|    n_updates            | 1350         |
|    policy_gradient_loss | -0.00444     |
|    value_loss           | 0.00747      |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
---------------evaluation started---------------
Eval num_timesteps=8878336, episode_reward=0.76 +/- 0.43
Episode length: 1.06 +/- 0.35
---------------evaluation finished---------------  took 11.79 seconds
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 136 completed in 77.20 seconds.
Time to collect_rollouts 77.31
Training model
Time to train 121.65
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.47        |
|    ep_rew_mean          | 0.37        |
| time/                   |             |
|    fps                  | 338         |
|    iterations           | 136         |
|    total_timesteps      | 8912896     |
| train/                  |             |
|    approx_kl            | 0.003401733 |
|    clip_fraction        | 0.0169      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.958      |
|    explained_variance   | 0.956       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0982     |
|    n_updates            | 1360        |
|    policy_gradient_loss | -0.00415    |
|    value_loss           | 0.00699     |
-----------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
---------------evaluation started---------------
Eval num_timesteps=8943616, episode_reward=0.76 +/- 0.43
Episode length: 1.06 +/- 0.35
---------------evaluation finished---------------  took 15.59 seconds
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 137 completed in 81.32 seconds.
Time to collect_rollouts 81.43
Training model
Time to train 118.65
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 1.63     |
|    ep_rew_mean          | 0.34     |
| time/                   |          |
|    fps                  | 338      |
|    iterations           | 137      |
|    total_timesteps      | 8978432  |
| train/                  |          |
|    approx_kl            | 0.003271 |
|    clip_fraction        | 0.0161   |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.963   |
|    explained_variance   | 0.958    |
|    learning_rate        | 0.0003   |
|    loss                 | -0.108   |
|    n_updates            | 1370     |
|    policy_gradient_loss | -0.00443 |
|    value_loss           | 0.00672  |
--------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
---------------evaluation started---------------
Eval num_timesteps=9008896, episode_reward=0.76 +/- 0.43
Episode length: 1.07 +/- 0.39
---------------evaluation finished---------------  took 16.55 seconds
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 138 completed in 99.13 seconds.
Time to collect_rollouts 99.25
Training model
Time to train 103.36
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.52         |
|    ep_rew_mean          | 0.32         |
| time/                   |              |
|    fps                  | 338          |
|    iterations           | 138          |
|    total_timesteps      | 9043968      |
| train/                  |              |
|    approx_kl            | 0.0035727825 |
|    clip_fraction        | 0.0187       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.973       |
|    explained_variance   | 0.955        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.113       |
|    n_updates            | 1380         |
|    policy_gradient_loss | -0.00443     |
|    value_loss           | 0.00719      |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
---------------evaluation started---------------
Eval num_timesteps=9074176, episode_reward=0.76 +/- 0.43
Episode length: 1.08 +/- 0.42
---------------evaluation finished---------------  took 16.36 seconds
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 139 completed in 97.28 seconds.
Time to collect_rollouts 97.38
Training model
Time to train 102.73
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.72        |
|    ep_rew_mean          | 0.35        |
| time/                   |             |
|    fps                  | 338         |
|    iterations           | 139         |
|    total_timesteps      | 9109504     |
| train/                  |             |
|    approx_kl            | 0.003391052 |
|    clip_fraction        | 0.0166      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.966      |
|    explained_variance   | 0.956       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.104      |
|    n_updates            | 1390        |
|    policy_gradient_loss | -0.00427    |
|    value_loss           | 0.00718     |
-----------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
---------------evaluation started---------------
Eval num_timesteps=9139456, episode_reward=0.76 +/- 0.43
Episode length: 1.07 +/- 0.39
---------------evaluation finished---------------  took 13.57 seconds
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 140 completed in 75.72 seconds.
Time to collect_rollouts 75.82
Training model
Time to train 79.19
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.54         |
|    ep_rew_mean          | 0.33         |
| time/                   |              |
|    fps                  | 338          |
|    iterations           | 140          |
|    total_timesteps      | 9175040      |
| train/                  |              |
|    approx_kl            | 0.0038002622 |
|    clip_fraction        | 0.021        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.964       |
|    explained_variance   | 0.951        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0908      |
|    n_updates            | 1400         |
|    policy_gradient_loss | -0.00511     |
|    value_loss           | 0.0076       |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
---------------evaluation started---------------
Eval num_timesteps=9204736, episode_reward=0.76 +/- 0.43
Episode length: 1.08 +/- 0.42
---------------evaluation finished---------------  took 13.49 seconds
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 141 completed in 76.96 seconds.
Time to collect_rollouts 77.07
Training model
Time to train 102.6
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.43        |
|    ep_rew_mean          | 0.37        |
| time/                   |             |
|    fps                  | 338         |
|    iterations           | 141         |
|    total_timesteps      | 9240576     |
| train/                  |             |
|    approx_kl            | 0.003775976 |
|    clip_fraction        | 0.0218      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.96       |
|    explained_variance   | 0.956       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.112      |
|    n_updates            | 1410        |
|    policy_gradient_loss | -0.00507    |
|    value_loss           | 0.00702     |
-----------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
---------------evaluation started---------------
Eval num_timesteps=9270016, episode_reward=0.76 +/- 0.43
Episode length: 1.07 +/- 0.41
---------------evaluation finished---------------  took 9.69 seconds
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 142 completed in 73.50 seconds.
Time to collect_rollouts 73.58
Training model
Time to train 95.42
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.65         |
|    ep_rew_mean          | 0.32         |
| time/                   |              |
|    fps                  | 339          |
|    iterations           | 142          |
|    total_timesteps      | 9306112      |
| train/                  |              |
|    approx_kl            | 0.0031785509 |
|    clip_fraction        | 0.0169       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.954       |
|    explained_variance   | 0.956        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.105       |
|    n_updates            | 1420         |
|    policy_gradient_loss | -0.00437     |
|    value_loss           | 0.00739      |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
---------------evaluation started---------------
Eval num_timesteps=9335296, episode_reward=0.76 +/- 0.43
Episode length: 1.08 +/- 0.45
---------------evaluation finished---------------  took 14.03 seconds
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 143 completed in 77.54 seconds.
Time to collect_rollouts 77.64
Training model
Time to train 103.89
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.62         |
|    ep_rew_mean          | 0.36         |
| time/                   |              |
|    fps                  | 339          |
|    iterations           | 143          |
|    total_timesteps      | 9371648      |
| train/                  |              |
|    approx_kl            | 0.0037879886 |
|    clip_fraction        | 0.0193       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.958       |
|    explained_variance   | 0.958        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0997      |
|    n_updates            | 1430         |
|    policy_gradient_loss | -0.00521     |
|    value_loss           | 0.0067       |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
---------------evaluation started---------------
Eval num_timesteps=9400576, episode_reward=0.76 +/- 0.43
Episode length: 1.08 +/- 0.43
---------------evaluation finished---------------  took 13.96 seconds
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 144 completed in 77.83 seconds.
Time to collect_rollouts 77.95
Training model
Time to train 92.47
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.61        |
|    ep_rew_mean          | 0.39        |
| time/                   |             |
|    fps                  | 339         |
|    iterations           | 144         |
|    total_timesteps      | 9437184     |
| train/                  |             |
|    approx_kl            | 0.003510552 |
|    clip_fraction        | 0.0169      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.951      |
|    explained_variance   | 0.958       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0956     |
|    n_updates            | 1440        |
|    policy_gradient_loss | -0.0043     |
|    value_loss           | 0.00674     |
-----------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
---------------evaluation started---------------
Eval num_timesteps=9465856, episode_reward=0.76 +/- 0.43
Episode length: 1.08 +/- 0.43
New best mean reward!
---------------evaluation finished---------------  took 14.98 seconds
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 145 completed in 87.08 seconds.
Time to collect_rollouts 87.19
Training model
Time to train 107.09
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.26         |
|    ep_rew_mean          | 0.39         |
| time/                   |              |
|    fps                  | 339          |
|    iterations           | 145          |
|    total_timesteps      | 9502720      |
| train/                  |              |
|    approx_kl            | 0.0038311877 |
|    clip_fraction        | 0.0209       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.959       |
|    explained_variance   | 0.958        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0896      |
|    n_updates            | 1450         |
|    policy_gradient_loss | -0.00522     |
|    value_loss           | 0.00699      |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
---------------evaluation started---------------
Eval num_timesteps=9531136, episode_reward=0.76 +/- 0.43
Episode length: 1.09 +/- 0.49
---------------evaluation finished---------------  took 15.13 seconds
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 146 completed in 79.81 seconds.
Time to collect_rollouts 79.92
Training model
Time to train 98.5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.56         |
|    ep_rew_mean          | 0.43         |
| time/                   |              |
|    fps                  | 339          |
|    iterations           | 146          |
|    total_timesteps      | 9568256      |
| train/                  |              |
|    approx_kl            | 0.0040781936 |
|    clip_fraction        | 0.0237       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.961       |
|    explained_variance   | 0.956        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.104       |
|    n_updates            | 1460         |
|    policy_gradient_loss | -0.00488     |
|    value_loss           | 0.0071       |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
---------------evaluation started---------------
Eval num_timesteps=9596416, episode_reward=0.76 +/- 0.43
Episode length: 1.08 +/- 0.43
---------------evaluation finished---------------  took 10.37 seconds
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 147 completed in 74.68 seconds.
Time to collect_rollouts 74.79
Training model
Time to train 54.91
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.52         |
|    ep_rew_mean          | 0.41         |
| time/                   |              |
|    fps                  | 340          |
|    iterations           | 147          |
|    total_timesteps      | 9633792      |
| train/                  |              |
|    approx_kl            | 0.0038219453 |
|    clip_fraction        | 0.0211       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.972       |
|    explained_variance   | 0.957        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0825      |
|    n_updates            | 1470         |
|    policy_gradient_loss | -0.00477     |
|    value_loss           | 0.00687      |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
---------------evaluation started---------------
Eval num_timesteps=9661696, episode_reward=0.76 +/- 0.43
Episode length: 1.09 +/- 0.45
---------------evaluation finished---------------  took 15.98 seconds
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 148 completed in 79.90 seconds.
Time to collect_rollouts 80.02
Training model
Time to train 68.33
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.43         |
|    ep_rew_mean          | 0.38         |
| time/                   |              |
|    fps                  | 341          |
|    iterations           | 148          |
|    total_timesteps      | 9699328      |
| train/                  |              |
|    approx_kl            | 0.0038691554 |
|    clip_fraction        | 0.022        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.967       |
|    explained_variance   | 0.957        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0903      |
|    n_updates            | 1480         |
|    policy_gradient_loss | -0.00523     |
|    value_loss           | 0.00695      |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
---------------evaluation started---------------
Eval num_timesteps=9726976, episode_reward=0.76 +/- 0.43
Episode length: 1.09 +/- 0.48
---------------evaluation finished---------------  took 13.88 seconds
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 149 completed in 77.23 seconds.
Time to collect_rollouts 77.35
Training model
Time to train 69.93
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.4          |
|    ep_rew_mean          | 0.4          |
| time/                   |              |
|    fps                  | 341          |
|    iterations           | 149          |
|    total_timesteps      | 9764864      |
| train/                  |              |
|    approx_kl            | 0.0036982656 |
|    clip_fraction        | 0.0218       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.954       |
|    explained_variance   | 0.955        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.106       |
|    n_updates            | 1490         |
|    policy_gradient_loss | -0.00446     |
|    value_loss           | 0.00707      |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
---------------evaluation started---------------
Eval num_timesteps=9792256, episode_reward=0.76 +/- 0.43
Episode length: 1.08 +/- 0.47
---------------evaluation finished---------------  took 12.97 seconds
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 150 completed in 76.10 seconds.
Time to collect_rollouts 76.21
Training model
Time to train 55.27
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.61         |
|    ep_rew_mean          | 0.41         |
| time/                   |              |
|    fps                  | 342          |
|    iterations           | 150          |
|    total_timesteps      | 9830400      |
| train/                  |              |
|    approx_kl            | 0.0039058987 |
|    clip_fraction        | 0.0223       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.964       |
|    explained_variance   | 0.963        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.104       |
|    n_updates            | 1500         |
|    policy_gradient_loss | -0.00446     |
|    value_loss           | 0.00646      |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
---------------evaluation started---------------
Eval num_timesteps=9857536, episode_reward=0.76 +/- 0.43
Episode length: 1.07 +/- 0.41
---------------evaluation finished---------------  took 14.16 seconds
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 151 completed in 78.19 seconds.
Time to collect_rollouts 78.31
Training model
Time to train 104.31
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.74         |
|    ep_rew_mean          | 0.4          |
| time/                   |              |
|    fps                  | 342          |
|    iterations           | 151          |
|    total_timesteps      | 9895936      |
| train/                  |              |
|    approx_kl            | 0.0037237485 |
|    clip_fraction        | 0.022        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.959       |
|    explained_variance   | 0.957        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0932      |
|    n_updates            | 1510         |
|    policy_gradient_loss | -0.00499     |
|    value_loss           | 0.007        |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
---------------evaluation started---------------
Eval num_timesteps=9922816, episode_reward=0.76 +/- 0.43
Episode length: 1.07 +/- 0.40
---------------evaluation finished---------------  took 13.66 seconds
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 152 completed in 80.08 seconds.
Time to collect_rollouts 80.19
Training model
Time to train 104.68
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.59         |
|    ep_rew_mean          | 0.4          |
| time/                   |              |
|    fps                  | 342          |
|    iterations           | 152          |
|    total_timesteps      | 9961472      |
| train/                  |              |
|    approx_kl            | 0.0038540969 |
|    clip_fraction        | 0.0217       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.957       |
|    explained_variance   | 0.96         |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0996      |
|    n_updates            | 1520         |
|    policy_gradient_loss | -0.00482     |
|    value_loss           | 0.00663      |
------------------------------------------
Collecting rollouts
Collecting rollouts: 0/256 steps
Collecting rollouts: 51/256 steps
Collecting rollouts: 102/256 steps
---------------evaluation started---------------
Eval num_timesteps=9988096, episode_reward=0.76 +/- 0.43
Episode length: 1.07 +/- 0.41
---------------evaluation finished---------------  took 14.55 seconds
Collecting rollouts: 153/256 steps
Collecting rollouts: 204/256 steps
Collecting rollouts: 255/256 steps
Epoch 153 completed in 78.80 seconds.
/media/users/castellanoontiv/miniconda3/envs/rl_gpu/lib/python3.12/site-packages/stable_baselines3/common/save_util.py:284: UserWarning: Path 'models/kinship_family/kinship_family-transe-mean-64-3-130-dynamic-True-True-1-True-False-False-True-True-True-True-False-20-True-0.1-0.2-python-1/kinship_family-transe-mean-64-3-130-dynamic-True-True-1-True-False-False-True-True-True-True-False-20-True-0.1-0.2-python-1-seed_0' does not exist. Will create it.
  warnings.warn(f"Path '{path.parent}' does not exist. Will create it.")
Time to collect_rollouts 78.89
Training model
Time to train 103.3
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.45         |
|    ep_rew_mean          | 0.42         |
| time/                   |              |
|    fps                  | 342          |
|    iterations           | 153          |
|    total_timesteps      | 10027008     |
| train/                  |              |
|    approx_kl            | 0.0037873548 |
|    clip_fraction        | 0.0208       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.98        |
|    explained_variance   | 0.96         |
|    learning_rate        | 0.0003       |
|    loss                 | -0.102       |
|    n_updates            | 1530         |
|    policy_gradient_loss | -0.00462     |
|    value_loss           | 0.00671      |
------------------------------------------

Training completed!
Total training time: 12685.94 seconds.
Average epoch time: 82.91 seconds.
Traceback (most recent call last):
  File "/media/users/castellanoontiv/Neural-guided-Grounding/runner.py", line 316, in <module>
    for args in all_args:
        ^^^^^^^^^^^^^^^^^^
  File "/media/users/castellanoontiv/Neural-guided-Grounding/runner.py", line 294, in main_wrapper
    log_filename_tmp = None
                            
  File "/media/users/castellanoontiv/Neural-guided-Grounding/train.py", line 323, in main
    if use_WB:
        ^^^^^^^
  File "/media/users/castellanoontiv/Neural-guided-Grounding/my_callbacks.py", line 225, in restore_best_ckpt
    print(f'No best model found for {self.name}.')
                                                  ^
IndexError: list index out of range
