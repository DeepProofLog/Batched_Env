Profile  Learn Results
Date: 2026-01-06 09:08:27
Device: cuda
Dataset: family

Configuration:
  Total timesteps (profiled): 1
  Batch size env: 128
  N steps per rollout: 128
  N epochs: 5
  Minibatch size: 1024
  Compile mode: reduce-overhead
  Fullgraph: True


Setting up components...
[EnvOptimal] Compiled with mode=reduce-overhead, fullgraph=True
[PPO] Compiled ranking_step with mode=default
Initialization time: 3.69s

Running warmup (compilation + first rollout)...
[EnvOptimal] Compiled with mode=reduce-overhead, fullgraph=True
Warmup: Running learn() iteration to compile all graphs...
[PPO] Rollout collected in 5.21s. FPS: 3143.69
Epoch 1/5. 
Losses: total 1.05174, value 3.06076, policy 0.00516, entropy -0.03065, approx_kl 0.01709 clip_fraction 0.02777. 
Epoch 2/5. 
Losses: total 0.80183, value 2.43626, policy 0.00461, entropy -0.03038, approx_kl 0.05406 clip_fraction 0.03815. 
Epoch 3/5. 
Losses: total 0.61360, value 2.04953, policy 0.00416, entropy -0.03064, approx_kl 0.08379 clip_fraction 0.04466. 
Epoch 4/5. 
Losses: total 0.45314, value 1.77922, policy 0.00326, entropy -0.03100, approx_kl 0.10437 clip_fraction 0.04916. 
Epoch 5/5. 
Losses: total 0.35478, value 1.57713, policy 0.00242, entropy -0.03138, approx_kl 0.12078 clip_fraction 0.05227. 
[PPO] Training completed in 12.33s
Warmup time: 19.92s

Profiling training for 1 timesteps...
[PPO] Rollout collected in 2.52s. FPS: 6509.84
Epoch 1/5. 
Losses: total 0.45221, value 0.98103, policy 0.00218, entropy -0.03244, approx_kl 0.00897 clip_fraction 0.02130. 
Epoch 2/5. 
Losses: total 0.37699, value 0.89528, policy -0.00037, entropy -0.03147, approx_kl 0.03168 clip_fraction 0.03000. 
Epoch 3/5. 
Losses: total 0.29465, value 0.81345, policy -0.00107, entropy -0.03157, approx_kl 0.05521 clip_fraction 0.03674. 
Epoch 4/5. 
Losses: total 0.22982, value 0.74280, policy -0.00173, entropy -0.03178, approx_kl 0.07663 clip_fraction 0.04105. 
Epoch 5/5. 
Losses: total 0.21162, value 0.68188, policy -0.00218, entropy -0.03211, approx_kl 0.09440 clip_fraction 0.04429. 
[PPO] Training completed in 11.37s

================================================================================
TIMING SUMMARY
================================================================================
Init time:         3.6893s
Warmup time:       19.9202s
Runtime:           13.9025s
Total time:        33.8226s
Steps/second:      1178.5
Total timesteps:   32768 (Warmup: 16384, Profiled: 16384)

Target: Runtime ≤ 16s
Status: PASS ✓

Last training metrics:
  policy_loss: -0.0022
  value_loss: 0.6819
  entropy: 0.0321
  clip_fraction: 0.0443
  approx_kl: 0.1655
  explained_var: -7.0193

================================================================================
PROFILING RESULTS - Top by Cumulative Time
================================================================================
         521811 function calls (500477 primitive calls) in 13.847 seconds

   Ordered by: cumulative time
   List reduced from 739 to 40 due to restriction <40>

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
       36    4.981    0.138    4.981    0.138 {method 'item' of 'torch._C.TensorBase' objects}
       80    0.000    0.000    3.183    0.040 __init__.py:243(backward)
       80    0.001    0.000    3.183    0.040 graph.py:832(_engine_run_backward)
       80    3.111    0.039    3.178    0.040 {method 'run_backward' of 'torch._C._EngineBase' objects}
   240/80    0.005    0.000    3.013    0.038 clip_grad.py:41(_no_grad_wrapper)
       80    0.003    0.000    3.010    0.038 clip_grad.py:185(clip_grad_norm_)
       80    0.003    0.000    2.966    0.037 clip_grad.py:49(_get_total_norm)
       80    2.949    0.037    2.949    0.037 {built-in method torch._foreach_norm}
      128    1.936    0.015    1.936    0.015 {built-in method torch.nonzero}
      947    0.006    0.000    0.286    0.000 eval_frame.py:1039(_fn)
 4159/596    0.006    0.000    0.255    0.000 module.py:1771(_wrapped_call_impl)
 4159/596    0.007    0.000    0.254    0.000 module.py:1779(_call_impl)
  369/289    0.004    0.000    0.234    0.001 utils.py:119(call_func_at_runtime_with_args)
      289    0.003    0.000    0.208    0.001 output_code.py:590(__call__)
      209    0.001    0.000    0.196    0.001 aot_autograd.py:1126(forward)
      209    0.001    0.000    0.195    0.001 runtime_wrappers.py:310(runtime_wrapper)
      129    0.001    0.000    0.187    0.001 policy.py:276(predict_values)
      289    0.002    0.000    0.172    0.001 compile_fx.py:1767(run)
      289    0.000    0.000    0.170    0.001 cudagraph_trees.py:378(deferred_cudagraphify)
      289    0.001    0.000    0.170    0.001 utils.py:3013(run)
      209    0.001    0.000    0.169    0.001 runtime_wrappers.py:512(wrapper)
  496/289    0.004    0.000    0.166    0.001 cudagraph_trees.py:2008(run)
  496/289    0.001    0.000    0.160    0.001 cudagraph_trees.py:2073(_run)
      128    0.018    0.000    0.151    0.001 ppo.py:257(fused_step)
      288    0.002    0.000    0.139    0.000 cudagraph_trees.py:2241(execute_node)
      129    0.001    0.000    0.123    0.001 policy.py:184(forward_critic)
      288    0.002    0.000    0.112    0.000 cudagraph_trees.py:1105(run)
      128    0.001    0.000    0.111    0.001 ctd4in2vwdnc2zhrswdrwq5msalyrv6clfmufuhcn22vs2xackdx.py:13085(call)
      129    0.000    0.000    0.107    0.001 policy.py:137(_get_shared_features)
      129    0.014    0.000    0.106    0.001 policy.py:94(forward)
      288    0.001    0.000    0.095    0.000 cudagraph_trees.py:1219(run_graph)
     1161    0.004    0.000    0.087    0.000 kernels.py:43(forward)
      289    0.006    0.000    0.076    0.000 cudagraph_trees.py:1057(_copy_inputs_and_remove_from_src)
      129    0.001    0.000    0.069    0.001 base.py:12480(clone)
      129    0.000    0.000    0.069    0.001 _td.py:3261(_clone)
      129    0.004    0.000    0.068    0.001 base.py:10716(_clone_recurse)
  290/289    0.068    0.000    0.068    0.000 {built-in method torch._foreach_copy_}
       80    0.007    0.000    0.067    0.001 ppo.py:61(forward)
       80    0.016    0.000    0.067    0.001 function.py:300(apply)
      129    0.001    0.000    0.062    0.000 policy.py:54(forward)




================================================================================
PROFILING RESULTS - Top by Total Time
================================================================================
         521811 function calls (500477 primitive calls) in 13.847 seconds

   Ordered by: internal time
   List reduced from 739 to 40 due to restriction <40>

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
       36    4.981    0.138    4.981    0.138 {method 'item' of 'torch._C.TensorBase' objects}
       80    3.111    0.039    3.178    0.040 {method 'run_backward' of 'torch._C._EngineBase' objects}
       80    2.949    0.037    2.949    0.037 {built-in method torch._foreach_norm}
      128    1.936    0.015    1.936    0.015 {built-in method torch.nonzero}
  290/289    0.068    0.000    0.068    0.000 {built-in method torch._foreach_copy_}
     1419    0.052    0.000    0.052    0.000 {built-in method torch._C._nn.linear}
      508    0.050    0.000    0.050    0.000 {method 'cpu' of 'torch._C.TensorBase' objects}
      129    0.041    0.000    0.041    0.000 {built-in method torch._foreach_add}
      516    0.023    0.000    0.023    0.000 {built-in method torch.embedding}
     1161    0.022    0.000    0.022    0.000 {built-in method torch.layer_norm}
     1172    0.022    0.000    0.022    0.000 {method 'clone' of 'torch._C.TensorBase' objects}
      289    0.022    0.000    0.028    0.000 graphs.py:139(replay)
      128    0.018    0.000    0.151    0.001 ppo.py:257(fused_step)
       80    0.016    0.000    0.067    0.001 function.py:300(apply)
     1290    0.015    0.000    0.015    0.000 {built-in method torch.relu_}
      129    0.014    0.000    0.106    0.001 policy.py:94(forward)
      128    0.013    0.000    0.015    0.000 rollout.py:202(add)
      258    0.012    0.000    0.015    0.000 embeddings.py:771(forward)
        1    0.012    0.012    0.014    0.014 rollout.py:242(compute_returns_and_advantage)
      890    0.011    0.000    0.011    0.000 {method 'copy_' of 'torch._C.TensorBase' objects}
      450    0.011    0.000    0.011    0.000 {built-in method torch._ops.profiler._record_function_enter_new}
      640    0.010    0.000    0.010    0.000 {built-in method torch.index_select}
      368    0.010    0.000    0.010    0.000 {method 'mean' of 'torch._C.TensorBase' objects}
      288    0.008    0.000    0.011    0.000 cudagraph_trees.py:1126(reconstruct_outputs)
       80    0.008    0.000    0.012    0.000 adam.py:138(_init_group)
      254    0.007    0.000    0.007    0.000 {method 'masked_fill_' of 'torch._C.TensorBase' objects}
63931/63811    0.007    0.000    0.008    0.000 {built-in method builtins.isinstance}
 4159/596    0.007    0.000    0.254    0.000 module.py:1779(_call_impl)
       80    0.007    0.000    0.067    0.001 ppo.py:61(forward)
       80    0.006    0.000    0.017    0.000 clip_grad.py:120(_clip_grads_with_norm_)
      947    0.006    0.000    0.286    0.000 eval_frame.py:1039(_fn)
       82    0.006    0.000    0.006    0.000 {built-in method torch.stack}
 4159/596    0.006    0.000    0.255    0.000 module.py:1771(_wrapped_call_impl)
      258    0.006    0.000    0.061    0.000 embeddings.py:1256(get_embeddings_batch)
     8258    0.006    0.000    0.011    0.000 cudagraph_trees.py:534(expired)
       80    0.006    0.000    0.014    0.000 optimizer.py:997(zero_grad)
       80    0.006    0.000    0.046    0.001 runtime_wrappers.py:2083(forward)
      289    0.006    0.000    0.076    0.000 cudagraph_trees.py:1057(_copy_inputs_and_remove_from_src)
      254    0.005    0.000    0.005    0.000 {method 'bool' of 'torch._C.TensorBase' objects}
    51578    0.005    0.000    0.005    0.000 {method 'append' of 'list' objects}




Results saved to /home/castellanoontiv/Batched_env/kge_experiments/tests/profile_learn.txt
