Profile  Learn Results
Date: 2026-01-12 18:04:42
Device: cuda
Dataset: family

Configuration:
  Total timesteps (profiled): 1
  Batch size env: 128
  N steps per rollout: 128
  N epochs: 5
  Minibatch size: 1024
  Compile mode: reduce-overhead
  Fullgraph: True


Setting up components...
/home/castellanoontiv/miniconda3/envs/rl/lib/python3.13/site-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)
  _C._set_float32_matmul_precision(precision)
[EnvOptimal] skip_unary_actions enabled - skipping torch.compile for compatibility
[PPO] Compiled ranking_step (double-buffered) with mode=default
Initialization time: 2.63s

Running warmup (compilation + first rollout)...
[EnvOptimal] Compiled with mode=reduce-overhead, fullgraph=True
Warmup: Running learn() iteration to compile all graphs...
[PPO] Rollout collected in 11.68s. FPS: 1403.08
Epoch 1/5. 
Losses: total 1.18252, value 2.96933, policy 0.00480, entropy -0.03842, approx_kl 0.02662 clip_fraction 0.03601. 
Epoch 2/5. 
Losses: total 0.73051, value 2.35745, policy 0.00580, entropy -0.03846, approx_kl 0.07597 clip_fraction 0.04691. 
Epoch 3/5. 
Losses: total 0.61681, value 1.98114, policy 0.00548, entropy -0.03901, approx_kl 0.11318 clip_fraction 0.05400. 
Epoch 4/5. 
Losses: total 0.42437, value 1.72081, policy 0.00473, entropy -0.03959, approx_kl 0.13733 clip_fraction 0.05777. 
Epoch 5/5. 
Losses: total 0.36156, value 1.52573, policy 0.00373, entropy -0.04014, approx_kl 0.15526 clip_fraction 0.06051. 
[PPO] Training completed in 9.18s
Warmup time: 27.21s

Profiling training for 1 timesteps...
[PPO] Rollout collected in 3.35s. FPS: 4890.52
Epoch 1/5. 
Losses: total 0.43605, value 0.99574, policy 0.00394, entropy -0.04142, approx_kl 0.00598 clip_fraction 0.02484. 
Epoch 2/5. 
Losses: total 0.36827, value 0.90803, policy 0.00059, entropy -0.04149, approx_kl 0.03291 clip_fraction 0.03568. 
Epoch 3/5. 
Losses: total 0.27921, value 0.82135, policy -0.00045, entropy -0.04171, approx_kl 0.06198 clip_fraction 0.04342. 
Epoch 4/5. 
Losses: total 0.22822, value 0.74691, policy -0.00159, entropy -0.04241, approx_kl 0.08203 clip_fraction 0.04918. 
Epoch 5/5. 
Losses: total 0.18230, value 0.68314, policy -0.00263, entropy -0.04340, approx_kl 0.09838 clip_fraction 0.05376. 
[PPO] Training completed in 8.51s

================================================================================
TIMING SUMMARY
================================================================================
Init time:         2.6293s
Warmup time:       27.2137s
Runtime:           11.8846s
Total time:        39.0983s
Steps/second:      1378.6
Total timesteps:   32768 (Warmup: 16384, Profiled: 16384)

Target: Runtime ≤ 16s
Status: PASS ✓

Last training metrics:
  policy_loss: -0.0026
  value_loss: 0.6831
  entropy: 0.0434
  clip_fraction: 0.0538
  approx_kl: 0.1638
  explained_var: -7.8787

================================================================================
PROFILING RESULTS - Top by Cumulative Time
================================================================================
         514995 function calls (493693 primitive calls) in 11.842 seconds

   Ordered by: cumulative time
   List reduced from 738 to 40 due to restriction <40>

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
       36    4.794    0.133    4.794    0.133 {method 'item' of 'torch._C.TensorBase' objects}
   240/80    0.007    0.000    3.000    0.038 clip_grad.py:41(_no_grad_wrapper)
       80    0.054    0.001    2.996    0.037 clip_grad.py:185(clip_grad_norm_)
      128    2.936    0.023    2.936    0.023 {built-in method torch.nonzero}
       80    0.004    0.000    2.865    0.036 clip_grad.py:49(_get_total_norm)
       82    2.828    0.034    2.828    0.034 {built-in method torch.stack}
       80    0.000    0.000    0.407    0.005 __init__.py:243(backward)
       80    0.001    0.000    0.407    0.005 graph.py:832(_engine_run_backward)
       80    0.265    0.003    0.401    0.005 {method 'run_backward' of 'torch._C._EngineBase' objects}
      947    0.006    0.000    0.363    0.000 eval_frame.py:1039(_fn)
  369/289    0.005    0.000    0.271    0.001 utils.py:119(call_func_at_runtime_with_args)
 4159/596    0.006    0.000    0.254    0.000 module.py:1771(_wrapped_call_impl)
 4159/596    0.006    0.000    0.253    0.000 module.py:1779(_call_impl)
      289    0.003    0.000    0.222    0.001 output_code.py:590(__call__)
      209    0.001    0.000    0.184    0.001 aot_autograd.py:1126(forward)
      209    0.001    0.000    0.183    0.001 runtime_wrappers.py:310(runtime_wrapper)
      289    0.002    0.000    0.178    0.001 compile_fx.py:1767(run)
      289    0.000    0.000    0.176    0.001 cudagraph_trees.py:378(deferred_cudagraphify)
      289    0.001    0.000    0.176    0.001 utils.py:2958(run)
  496/289    0.004    0.000    0.171    0.001 cudagraph_trees.py:2008(run)
  496/289    0.001    0.000    0.165    0.001 cudagraph_trees.py:2073(_run)
      209    0.001    0.000    0.137    0.001 runtime_wrappers.py:512(wrapper)
       80    0.025    0.000    0.135    0.002 function.py:300(apply)
      288    0.003    0.000    0.135    0.000 cudagraph_trees.py:2241(execute_node)
      129    0.001    0.000    0.135    0.001 policy.py:324(predict_values)
       80    0.007    0.000    0.117    0.001 ppo.py:70(forward)
       80    0.001    0.000    0.111    0.001 runtime_wrappers.py:2239(backward)
       80    0.003    0.000    0.110    0.001 runtime_wrappers.py:2288(impl_fn)
      508    0.106    0.000    0.106    0.000 {method 'cpu' of 'torch._C.TensorBase' objects}
       80    0.001    0.000    0.100    0.001 utils.py:102(g)
       80    0.000    0.000    0.099    0.001 function.py:565(apply)
       80    0.006    0.000    0.099    0.001 {built-in method apply}
       80    0.000    0.000    0.091    0.001 runtime_wrappers.py:2330(_backward_impl)
      129    0.001    0.000    0.090    0.001 policy.py:229(forward_critic)
       80    0.009    0.000    0.084    0.001 runtime_wrappers.py:2083(forward)
      129    0.000    0.000    0.079    0.001 policy.py:182(_get_shared_features)
      129    0.010    0.000    0.078    0.001 policy.py:112(forward)
       80    0.001    0.000    0.078    0.001 cylq7jrtkt4rpcmbxkq5i7latb5qexej7jg6f6zvk4p2x5ktka6j.py:6160(call)
      288    0.002    0.000    0.073    0.000 cudagraph_trees.py:1105(run)
      128    0.011    0.000    0.072    0.001 ppo.py:297(fused_step)




================================================================================
PROFILING RESULTS - Top by Total Time
================================================================================
         514995 function calls (493693 primitive calls) in 11.842 seconds

   Ordered by: internal time
   List reduced from 738 to 40 due to restriction <40>

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
       36    4.794    0.133    4.794    0.133 {method 'item' of 'torch._C.TensorBase' objects}
      128    2.936    0.023    2.936    0.023 {built-in method torch.nonzero}
       82    2.828    0.034    2.828    0.034 {built-in method torch.stack}
       80    0.265    0.003    0.401    0.005 {method 'run_backward' of 'torch._C._EngineBase' objects}
      508    0.106    0.000    0.106    0.000 {method 'cpu' of 'torch._C.TensorBase' objects}
       80    0.054    0.001    2.996    0.037 clip_grad.py:185(clip_grad_norm_)
     1419    0.037    0.000    0.037    0.000 {built-in method torch._C._nn.linear}
  290/289    0.028    0.000    0.028    0.000 {built-in method torch._foreach_copy_}
       80    0.025    0.000    0.135    0.002 function.py:300(apply)
       80    0.019    0.000    0.019    0.000 {built-in method torch._foreach_norm}
       80    0.018    0.000    0.029    0.000 adam.py:138(_init_group)
       80    0.016    0.000    0.031    0.000 optimizer.py:997(zero_grad)
      288    0.015    0.000    0.022    0.000 cudagraph_trees.py:1126(reconstruct_outputs)
     1161    0.015    0.000    0.015    0.000 {built-in method torch.layer_norm}
      129    0.015    0.000    0.015    0.000 {built-in method torch._foreach_add}
13280/2400    0.015    0.000    0.018    0.000 module.py:2823(named_modules)
     1172    0.015    0.000    0.015    0.000 {method 'clone' of 'torch._C.TensorBase' objects}
     8252    0.015    0.000    0.032    0.000 cudagraph_trees.py:534(expired)
      516    0.014    0.000    0.014    0.000 {built-in method torch.embedding}
      640    0.014    0.000    0.014    0.000 {built-in method torch.index_select}
61239/61119    0.013    0.000    0.015    0.000 {built-in method builtins.isinstance}
    48747    0.013    0.000    0.013    0.000 {method 'append' of 'list' objects}
      890    0.012    0.000    0.012    0.000 {method 'copy_' of 'torch._C.TensorBase' objects}
     4080    0.012    0.000    0.044    0.000 module.py:2636(_named_members)
      128    0.011    0.000    0.072    0.001 ppo.py:297(fused_step)
      129    0.010    0.000    0.078    0.001 policy.py:112(forward)
     1290    0.010    0.000    0.010    0.000 {built-in method torch.relu_}
      450    0.010    0.000    0.010    0.000 {built-in method torch._ops.profiler._record_function_enter_new}
        7    0.010    0.001    0.010    0.001 {built-in method torch._C._cuda_synchronize}
      128    0.009    0.000    0.011    0.000 rollout.py:204(add)
      240    0.009    0.000    0.009    0.000 {built-in method torch._C._group_tensors_by_device_and_dtype}
       80    0.009    0.000    0.084    0.001 runtime_wrappers.py:2083(forward)
        1    0.008    0.008    0.010    0.010 rollout.py:244(compute_returns_and_advantage)
      258    0.008    0.000    0.011    0.000 embeddings.py:771(forward)
       80    0.007    0.000    0.117    0.001 ppo.py:70(forward)
   240/80    0.007    0.000    3.000    0.038 clip_grad.py:41(_no_grad_wrapper)
     8160    0.007    0.000    0.013    0.000 cudagraph_trees.py:1432(check_refcount)
      289    0.007    0.000    0.015    0.000 graphs.py:139(replay)
     4795    0.007    0.000    0.007    0.000 {method 'to' of 'torch._C.TensorBase' objects}
      947    0.006    0.000    0.363    0.000 eval_frame.py:1039(_fn)




Results saved to /home/castellanoontiv/Batched_Env/kge_experiments/tests/profile_learn.txt
