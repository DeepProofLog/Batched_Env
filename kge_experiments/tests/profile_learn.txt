Profile  Learn Results
Date: 2026-01-07 01:11:06
Device: cuda
Dataset: family

Configuration:
  Total timesteps (profiled): 1
  Batch size env: 128
  N steps per rollout: 128
  N epochs: 5
  Minibatch size: 1024
  Compile mode: reduce-overhead
  Fullgraph: True


Setting up components...
[EnvOptimal] skip_unary_actions enabled - skipping torch.compile for compatibility
[PPO] Compiled ranking_step with mode=default
Initialization time: 6.68s

Running warmup (compilation + first rollout)...
[EnvOptimal] Compiled with mode=reduce-overhead, fullgraph=True
Warmup: Running learn() iteration to compile all graphs...
[PPO] Rollout collected in 117.38s. FPS: 139.58
Epoch 1/5. 
Losses: total 1.08649, value 3.05281, policy 0.00516, entropy -0.03128, approx_kl 0.01607 clip_fraction 0.02869. 
Epoch 2/5. 
Losses: total 0.80411, value 2.42887, policy 0.00433, entropy -0.03091, approx_kl 0.04946 clip_fraction 0.03851. 
Epoch 3/5. 
Losses: total 0.63061, value 2.04351, policy 0.00382, entropy -0.03116, approx_kl 0.07761 clip_fraction 0.04462. 
Epoch 4/5. 
Losses: total 0.45578, value 1.77427, policy 0.00308, entropy -0.03150, approx_kl 0.09760 clip_fraction 0.04903. 
Epoch 5/5. 
Losses: total 0.34882, value 1.57260, policy 0.00234, entropy -0.03195, approx_kl 0.11383 clip_fraction 0.05197. 
[PPO] Training completed in 14.27s
Warmup time: 184.42s

Profiling training for 1 timesteps...
[PPO] Rollout collected in 7.59s. FPS: 2157.44
Epoch 1/5. 
Losses: total 0.44232, value 0.93966, policy 0.00350, entropy -0.03224, approx_kl 0.00671 clip_fraction 0.02032. 
Epoch 2/5. 
Losses: total 0.35766, value 0.85287, policy 0.00123, entropy -0.03161, approx_kl 0.03007 clip_fraction 0.02924. 
Epoch 3/5. 
Losses: total 0.28657, value 0.77436, policy 0.00002, entropy -0.03184, approx_kl 0.04968 clip_fraction 0.03495. 
Epoch 4/5. 
Losses: total 0.20463, value 0.70611, policy -0.00122, entropy -0.03213, approx_kl 0.06695 clip_fraction 0.03917. 
Epoch 5/5. 
Losses: total 0.18721, value 0.64701, policy -0.00224, entropy -0.03276, approx_kl 0.08031 clip_fraction 0.04257. 
[PPO] Training completed in 11.56s

================================================================================
TIMING SUMMARY
================================================================================
Init time:         6.6824s
Warmup time:       184.4221s
Runtime:           19.2013s
Total time:        203.6234s
Steps/second:      853.3
Total timesteps:   32768 (Warmup: 16384, Profiled: 16384)

Target: Runtime ≤ 16s
Status: FAIL ✗

Last training metrics:
  policy_loss: -0.0022
  value_loss: 0.6470
  entropy: 0.0328
  clip_fraction: 0.0426
  approx_kl: 0.1338
  explained_var: -6.6744

================================================================================
PROFILING RESULTS - Top by Cumulative Time
================================================================================
         525075 function calls (503739 primitive calls) in 19.096 seconds

   Ordered by: cumulative time
   List reduced from 741 to 40 due to restriction <40>

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      128    6.887    0.054    6.887    0.054 {built-in method torch.nonzero}
       36    5.039    0.140    5.039    0.140 {method 'item' of 'torch._C.TensorBase' objects}
       80    0.000    0.000    3.335    0.042 __init__.py:243(backward)
       80    0.001    0.000    3.334    0.042 graph.py:832(_engine_run_backward)
       80    3.248    0.041    3.329    0.042 {method 'run_backward' of 'torch._C._EngineBase' objects}
   240/80    0.005    0.000    2.959    0.037 clip_grad.py:41(_no_grad_wrapper)
       80    0.003    0.000    2.957    0.037 clip_grad.py:185(clip_grad_norm_)
       80    0.003    0.000    2.908    0.036 clip_grad.py:49(_get_total_norm)
       80    2.890    0.036    2.890    0.036 {built-in method torch._foreach_norm}
      947    0.007    0.000    0.379    0.000 eval_frame.py:1039(_fn)
  369/289    0.006    0.000    0.307    0.001 utils.py:119(call_func_at_runtime_with_args)
 4159/596    0.007    0.000    0.285    0.000 module.py:1771(_wrapped_call_impl)
 4159/596    0.010    0.000    0.283    0.000 module.py:1779(_call_impl)
      289    0.004    0.000    0.274    0.001 output_code.py:590(__call__)
      209    0.001    0.000    0.267    0.001 aot_autograd.py:1126(forward)
      209    0.003    0.000    0.266    0.001 runtime_wrappers.py:310(runtime_wrapper)
      289    0.002    0.000    0.233    0.001 compile_fx.py:1767(run)
      289    0.001    0.000    0.230    0.001 cudagraph_trees.py:378(deferred_cudagraphify)
      289    0.002    0.000    0.230    0.001 utils.py:3013(run)
  496/289    0.005    0.000    0.225    0.001 cudagraph_trees.py:2008(run)
      209    0.001    0.000    0.223    0.001 runtime_wrappers.py:512(wrapper)
  496/289    0.002    0.000    0.217    0.001 cudagraph_trees.py:2073(_run)
      129    0.001    0.000    0.202    0.002 policy.py:276(predict_values)
      128    0.037    0.000    0.197    0.002 ppo.py:274(fused_step)
      129    0.001    0.000    0.180    0.001 runtime_wrappers.py:716(inner_fn)
      288    0.003    0.000    0.169    0.001 cudagraph_trees.py:2241(execute_node)
      288    0.002    0.000    0.132    0.000 cudagraph_trees.py:1105(run)
      128    0.002    0.000    0.130    0.001 cq7epo4ymchlirixaxq7mjgdyj64slkufwfkpet7uzz5qcg3j26g.py:36057(call)
      129    0.001    0.000    0.128    0.001 policy.py:184(forward_critic)
      129    0.000    0.000    0.111    0.001 policy.py:137(_get_shared_features)
      288    0.001    0.000    0.110    0.000 cudagraph_trees.py:1219(run_graph)
      129    0.015    0.000    0.110    0.001 policy.py:94(forward)
     1161    0.005    0.000    0.089    0.000 kernels.py:43(forward)
       80    0.008    0.000    0.082    0.001 ppo.py:62(forward)
       80    0.017    0.000    0.081    0.001 function.py:300(apply)
      289    0.007    0.000    0.076    0.000 cudagraph_trees.py:1057(_copy_inputs_and_remove_from_src)
      129    0.002    0.000    0.072    0.001 policy.py:54(forward)
      129    0.001    0.000    0.071    0.001 base.py:12480(clone)
      129    0.001    0.000    0.070    0.001 _td.py:3261(_clone)
      258    0.007    0.000    0.069    0.000 embeddings.py:1256(get_embeddings_batch)




================================================================================
PROFILING RESULTS - Top by Total Time
================================================================================
         525075 function calls (503739 primitive calls) in 19.096 seconds

   Ordered by: internal time
   List reduced from 741 to 40 due to restriction <40>

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      128    6.887    0.054    6.887    0.054 {built-in method torch.nonzero}
       36    5.039    0.140    5.039    0.140 {method 'item' of 'torch._C.TensorBase' objects}
       80    3.248    0.041    3.329    0.042 {method 'run_backward' of 'torch._C._EngineBase' objects}
       80    2.890    0.036    2.890    0.036 {built-in method torch._foreach_norm}
  290/289    0.066    0.000    0.066    0.000 {built-in method torch._foreach_copy_}
      508    0.066    0.000    0.066    0.000 {method 'cpu' of 'torch._C.TensorBase' objects}
     1419    0.052    0.000    0.052    0.000 {built-in method torch._C._nn.linear}
      128    0.037    0.000    0.197    0.002 ppo.py:274(fused_step)
      129    0.037    0.000    0.037    0.000 {built-in method torch._foreach_add}
      289    0.034    0.000    0.046    0.000 graphs.py:139(replay)
      516    0.026    0.000    0.026    0.000 {built-in method torch.embedding}
     1161    0.022    0.000    0.022    0.000 {built-in method torch.layer_norm}
     1172    0.021    0.000    0.021    0.000 {method 'clone' of 'torch._C.TensorBase' objects}
        7    0.021    0.003    0.021    0.003 {built-in method torch._C._cuda_synchronize}
       80    0.017    0.000    0.081    0.001 function.py:300(apply)
      129    0.015    0.000    0.110    0.001 policy.py:94(forward)
     1290    0.015    0.000    0.015    0.000 {built-in method torch.relu_}
      128    0.014    0.000    0.016    0.000 rollout.py:202(add)
      890    0.013    0.000    0.013    0.000 {method 'copy_' of 'torch._C.TensorBase' objects}
      258    0.012    0.000    0.016    0.000 embeddings.py:771(forward)
      288    0.012    0.000    0.016    0.000 cudagraph_trees.py:1126(reconstruct_outputs)
      640    0.012    0.000    0.012    0.000 {built-in method torch.index_select}
      368    0.011    0.000    0.011    0.000 {method 'mean' of 'torch._C.TensorBase' objects}
      450    0.011    0.000    0.011    0.000 {built-in method torch._ops.profiler._record_function_enter_new}
     8263    0.011    0.000    0.017    0.000 cudagraph_trees.py:534(expired)
       80    0.010    0.000    0.015    0.000 adam.py:138(_init_group)
 4159/596    0.010    0.000    0.283    0.000 module.py:1779(_call_impl)
        1    0.009    0.009    0.010    0.010 rollout.py:242(compute_returns_and_advantage)
63959/63839    0.008    0.000    0.010    0.000 {built-in method builtins.isinstance}
       80    0.008    0.000    0.082    0.001 ppo.py:62(forward)
    51585    0.007    0.000    0.007    0.000 {method 'append' of 'list' objects}
 4159/596    0.007    0.000    0.285    0.000 module.py:1771(_wrapped_call_impl)
      947    0.007    0.000    0.379    0.000 eval_frame.py:1039(_fn)
      289    0.007    0.000    0.076    0.000 cudagraph_trees.py:1057(_copy_inputs_and_remove_from_src)
      258    0.007    0.000    0.069    0.000 embeddings.py:1256(get_embeddings_batch)
      254    0.007    0.000    0.007    0.000 {method 'masked_fill_' of 'torch._C.TensorBase' objects}
        7    0.007    0.001    0.007    0.001 {method 'acquire' of '_thread.lock' objects}
       80    0.007    0.000    0.015    0.000 optimizer.py:997(zero_grad)
       80    0.006    0.000    0.056    0.001 runtime_wrappers.py:2083(forward)
  369/289    0.006    0.000    0.307    0.001 utils.py:119(call_func_at_runtime_with_args)




Results saved to /home/castellanoontiv/Batched_env/kge_experiments/tests/profile_learn.txt
