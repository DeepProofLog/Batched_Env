Profile  Learn Results
Date: 2026-01-05 21:55:25
Device: cuda
Dataset: family

Configuration:
  Total timesteps (profiled): 1
  Batch size env: 128
  N steps per rollout: 128
  N epochs: 5
  Minibatch size: 1024
  Compile mode: reduce-overhead
  Fullgraph: True


Setting up components...
[EnvOptimal] Compiled with mode=reduce-overhead, fullgraph=True
[PPO] Compiled ranking_step with mode=default
Initialization time: 4.07s

Running warmup (compilation + first rollout)...
[EnvOptimal] Compiled with mode=reduce-overhead, fullgraph=True
Warmup: Running learn() iteration to compile all graphs...
[PPO] Rollout collected in 5.04s. FPS: 3251.65
Epoch 1/5. 
Losses: total 1.05683, value 3.05266, policy 0.00555, entropy -0.03185, approx_kl 0.01769 clip_fraction 0.02863. 
Epoch 2/5. 
Losses: total 0.79462, value 2.43344, policy 0.00444, entropy -0.03150, approx_kl 0.05428 clip_fraction 0.03851. 
Epoch 3/5. 
Losses: total 0.63848, value 2.04825, policy 0.00379, entropy -0.03169, approx_kl 0.08560 clip_fraction 0.04543. 
Epoch 4/5. 
Losses: total 0.44477, value 1.77836, policy 0.00294, entropy -0.03207, approx_kl 0.10676 clip_fraction 0.05008. 
Epoch 5/5. 
Losses: total 0.35721, value 1.57637, policy 0.00204, entropy -0.03255, approx_kl 0.12331 clip_fraction 0.05327. 
[PPO] Training completed in 12.51s
Warmup time: 20.48s

Profiling training for 1 timesteps...
[PPO] Rollout collected in 2.70s. FPS: 6064.41
Epoch 1/5. 
Losses: total 0.44583, value 0.95933, policy 0.00368, entropy -0.03468, approx_kl 0.00912 clip_fraction 0.02258. 
Epoch 2/5. 
Losses: total 0.40024, value 0.87485, policy 0.00185, entropy -0.03403, approx_kl 0.03302 clip_fraction 0.03165. 
Epoch 3/5. 
Losses: total 0.29223, value 0.79751, policy 0.00010, entropy -0.03427, approx_kl 0.05245 clip_fraction 0.03713. 
Epoch 4/5. 
Losses: total 0.23269, value 0.72823, policy -0.00100, entropy -0.03488, approx_kl 0.06703 clip_fraction 0.04134. 
Epoch 5/5. 
Losses: total 0.19640, value 0.66829, policy -0.00197, entropy -0.03522, approx_kl 0.07917 clip_fraction 0.04458. 
[PPO] Training completed in 11.72s

================================================================================
TIMING SUMMARY
================================================================================
Init time:         4.0688s
Warmup time:       20.4828s
Runtime:           14.4386s
Total time:        34.9214s
Steps/second:      1134.7
Total timesteps:   32768 (Warmup: 16384, Profiled: 16384)

Target: Runtime ≤ 16s
Status: PASS ✓

Last training metrics:
  policy_loss: -0.0020
  value_loss: 0.6683
  entropy: 0.0352
  clip_fraction: 0.0446
  approx_kl: 0.1277
  explained_var: -6.9926

================================================================================
PROFILING RESULTS - Top by Cumulative Time
================================================================================
         520850 function calls (499519 primitive calls) in 14.366 seconds

   Ordered by: cumulative time
   List reduced from 739 to 40 due to restriction <40>

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
       36    5.100    0.142    5.100    0.142 {method 'item' of 'torch._C.TensorBase' objects}
       80    0.000    0.000    3.401    0.043 __init__.py:243(backward)
       80    0.001    0.000    3.400    0.043 graph.py:832(_engine_run_backward)
       80    3.322    0.042    3.395    0.042 {method 'run_backward' of 'torch._C._EngineBase' objects}
   240/80    0.006    0.000    3.009    0.038 clip_grad.py:41(_no_grad_wrapper)
       80    0.004    0.000    3.006    0.038 clip_grad.py:185(clip_grad_norm_)
       80    0.003    0.000    2.958    0.037 clip_grad.py:49(_get_total_norm)
       80    2.938    0.037    2.938    0.037 {built-in method torch._foreach_norm}
      128    2.071    0.016    2.071    0.016 {built-in method torch.nonzero}
      947    0.007    0.000    0.304    0.000 eval_frame.py:1039(_fn)
 4159/596    0.006    0.000    0.287    0.000 module.py:1771(_wrapped_call_impl)
 4159/596    0.009    0.000    0.286    0.000 module.py:1779(_call_impl)
  369/289    0.005    0.000    0.243    0.001 utils.py:119(call_func_at_runtime_with_args)
      289    0.003    0.000    0.214    0.001 output_code.py:590(__call__)
      129    0.001    0.000    0.214    0.002 policy.py:276(predict_values)
      209    0.001    0.000    0.201    0.001 aot_autograd.py:1126(forward)
      209    0.001    0.000    0.200    0.001 runtime_wrappers.py:310(runtime_wrapper)
      289    0.002    0.000    0.175    0.001 compile_fx.py:1767(run)
      289    0.000    0.000    0.173    0.001 cudagraph_trees.py:378(deferred_cudagraphify)
      289    0.001    0.000    0.172    0.001 utils.py:3013(run)
      209    0.001    0.000    0.172    0.001 runtime_wrappers.py:512(wrapper)
  496/289    0.004    0.000    0.167    0.001 cudagraph_trees.py:2008(run)
  496/289    0.001    0.000    0.161    0.001 cudagraph_trees.py:2073(_run)
      128    0.022    0.000    0.158    0.001 ppo.py:256(fused_step)
      129    0.001    0.000    0.143    0.001 policy.py:184(forward_critic)
      288    0.002    0.000    0.141    0.000 cudagraph_trees.py:2241(execute_node)
      129    0.000    0.000    0.124    0.001 policy.py:137(_get_shared_features)
      129    0.016    0.000    0.123    0.001 policy.py:94(forward)
      288    0.002    0.000    0.111    0.000 cudagraph_trees.py:1105(run)
      128    0.001    0.000    0.111    0.001 caim2z45tprjbboh6gixznogn2irsx25amuz67575rmg4d6z7pcj.py:13034(call)
     1161    0.006    0.000    0.101    0.000 kernels.py:43(forward)
      288    0.001    0.000    0.094    0.000 cudagraph_trees.py:1219(run_graph)
       80    0.017    0.000    0.073    0.001 function.py:300(apply)
       80    0.008    0.000    0.073    0.001 ppo.py:61(forward)
      289    0.006    0.000    0.072    0.000 cudagraph_trees.py:1057(_copy_inputs_and_remove_from_src)
      129    0.001    0.000    0.069    0.001 base.py:12480(clone)
      129    0.002    0.000    0.068    0.001 policy.py:54(forward)
      129    0.001    0.000    0.068    0.001 _td.py:3261(_clone)
      129    0.005    0.000    0.068    0.001 base.py:10716(_clone_recurse)
      258    0.006    0.000    0.066    0.000 embeddings.py:1256(get_embeddings_batch)




================================================================================
PROFILING RESULTS - Top by Total Time
================================================================================
         520850 function calls (499519 primitive calls) in 14.366 seconds

   Ordered by: internal time
   List reduced from 739 to 40 due to restriction <40>

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
       36    5.100    0.142    5.100    0.142 {method 'item' of 'torch._C.TensorBase' objects}
       80    3.322    0.042    3.395    0.042 {method 'run_backward' of 'torch._C._EngineBase' objects}
       80    2.938    0.037    2.938    0.037 {built-in method torch._foreach_norm}
      128    2.071    0.016    2.071    0.016 {built-in method torch.nonzero}
  290/289    0.063    0.000    0.063    0.000 {built-in method torch._foreach_copy_}
     1419    0.060    0.000    0.060    0.000 {built-in method torch._C._nn.linear}
      508    0.049    0.000    0.049    0.000 {method 'cpu' of 'torch._C.TensorBase' objects}
      129    0.039    0.000    0.039    0.000 {built-in method torch._foreach_add}
      516    0.026    0.000    0.026    0.000 {built-in method torch.embedding}
     1161    0.024    0.000    0.024    0.000 {built-in method torch.layer_norm}
     1172    0.022    0.000    0.022    0.000 {method 'clone' of 'torch._C.TensorBase' objects}
      289    0.022    0.000    0.027    0.000 graphs.py:139(replay)
      128    0.022    0.000    0.158    0.001 ppo.py:256(fused_step)
     1290    0.018    0.000    0.018    0.000 {built-in method torch.relu_}
       80    0.017    0.000    0.073    0.001 function.py:300(apply)
      129    0.016    0.000    0.123    0.001 policy.py:94(forward)
      128    0.016    0.000    0.018    0.000 rollout.py:202(add)
      258    0.013    0.000    0.016    0.000 embeddings.py:771(forward)
      890    0.012    0.000    0.012    0.000 {method 'copy_' of 'torch._C.TensorBase' objects}
      450    0.011    0.000    0.011    0.000 {built-in method torch._ops.profiler._record_function_enter_new}
      640    0.011    0.000    0.011    0.000 {built-in method torch.index_select}
      368    0.010    0.000    0.010    0.000 {method 'mean' of 'torch._C.TensorBase' objects}
       80    0.010    0.000    0.014    0.000 adam.py:138(_init_group)
 4159/596    0.009    0.000    0.286    0.000 module.py:1779(_call_impl)
      288    0.009    0.000    0.012    0.000 cudagraph_trees.py:1126(reconstruct_outputs)
        1    0.008    0.008    0.010    0.010 rollout.py:242(compute_returns_and_advantage)
63661/63541    0.008    0.000    0.009    0.000 {built-in method builtins.isinstance}
       80    0.008    0.000    0.073    0.001 ppo.py:61(forward)
       80    0.007    0.000    0.020    0.000 clip_grad.py:120(_clip_grads_with_norm_)
      947    0.007    0.000    0.304    0.000 eval_frame.py:1039(_fn)
      254    0.007    0.000    0.007    0.000 {method 'masked_fill_' of 'torch._C.TensorBase' objects}
     8257    0.007    0.000    0.012    0.000 cudagraph_trees.py:534(expired)
       82    0.007    0.000    0.007    0.000 {built-in method torch.stack}
 4159/596    0.006    0.000    0.287    0.000 module.py:1771(_wrapped_call_impl)
       80    0.006    0.000    0.015    0.000 optimizer.py:997(zero_grad)
      258    0.006    0.000    0.066    0.000 embeddings.py:1256(get_embeddings_batch)
       80    0.006    0.000    0.050    0.001 runtime_wrappers.py:2083(forward)
   240/80    0.006    0.000    3.009    0.038 clip_grad.py:41(_no_grad_wrapper)
      289    0.006    0.000    0.072    0.000 cudagraph_trees.py:1057(_copy_inputs_and_remove_from_src)
    51319    0.006    0.000    0.006    0.000 {method 'append' of 'list' objects}




Results saved to /home/castellanoontiv/Batched_env/kge_experiments/tests/profile_learn.txt
