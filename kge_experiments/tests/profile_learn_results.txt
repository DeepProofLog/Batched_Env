Profile Optimized Learn Results
Date: 2025-12-17 08:34:04
Device: cuda
Dataset: countries_s3

Configuration:
  Total timesteps (profiled): 1
  Batch size env: 128
  N steps per rollout: 128
  N epochs: 5
  Minibatch size: 1024
  Compile mode: reduce-overhead
  Fullgraph: True


Setting up components...
Queries loaded - Train: 111/111, Valid: 24, Test: 24
Using Automatic Mixed Precision (AMP) with dtype: torch.bfloat16
Compiling policy network and loss module for training...
Initialization time: 3.22s

Running warmup (compilation + first rollout)...
Compiling step_with_policy (mode='reduce-overhead', fullgraph=True)...
Warmup: Running learn() iteration to compile all graphs...

Collecting rollouts
Collecting rollouts: 0/128 steps
Collecting rollouts: 25/128 steps
Collecting rollouts: 50/128 steps
Collecting rollouts: 75/128 steps
Collecting rollouts: 100/128 steps
Collecting rollouts: 125/128 steps
Rollout collected in 8.21s. FPS: 1996.24


Training
Epoch 1/5
Epoch 2/5
Epoch 3/5
Epoch 4/5
Epoch 5/5
Training completed in 2.64s
Iteration 1, timesteps: 16384/128.  total loss: 0.1958, policy_loss: -0.0023, value_loss: 0.1981, entropy_loss: 0.0169, approx_kl: 0.2080, clip_fraction: 0.0451, explained_var: -6.0447

Warmup time: 10.91s

Profiling training for 1 timesteps...

Collecting rollouts
Collecting rollouts: 0/128 steps
Collecting rollouts: 25/128 steps
Collecting rollouts: 50/128 steps
Collecting rollouts: 75/128 steps
Collecting rollouts: 100/128 steps
Collecting rollouts: 125/128 steps
Rollout collected in 1.91s. FPS: 8584.50


Training
Epoch 1/5
Epoch 2/5
Epoch 3/5
Epoch 4/5
Epoch 5/5
Training completed in 1.84s
Iteration 1, timesteps: 32768/16385.  total loss: 0.0181, policy_loss: 0.0001, value_loss: 0.0179, entropy_loss: 0.0025, approx_kl: 0.2944, clip_fraction: 0.0236, explained_var: 0.5195


================================================================================
TIMING SUMMARY
================================================================================
Init time:         3.2191s
Warmup time:       10.9114s
Runtime:           3.7618s
Total time:        14.6732s
Steps/second:      4355.4
Total timesteps:   32768 (Warmup: 16384, Profiled: 16384)

Last training metrics:
  policy_loss: 0.0001
  value_loss: 0.0179
  entropy: 0.0025
  clip_fraction: 0.0236
  approx_kl: 0.2944
  explained_var: 0.5195

================================================================================
PROFILING RESULTS - Top by Cumulative Time
================================================================================
         618117 function calls (543190 primitive calls) in 2.500 seconds

   Ordered by: cumulative time
   List reduced from 743 to 40 due to restriction <40>

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
       80    0.000    0.000    1.314    0.016 __init__.py:243(backward)
       80    0.001    0.000    1.314    0.016 graph.py:832(_engine_run_backward)
       80    1.150    0.014    1.309    0.016 {method 'run_backward' of 'torch._C._EngineBase' objects}
16543/338    0.018    0.000    0.479    0.001 module.py:1771(_wrapped_call_impl)
16543/338    0.025    0.000    0.478    0.001 module.py:1779(_call_impl)
      129    0.001    0.000    0.409    0.003 model.py:730(predict_values)
      944    0.006    0.000    0.359    0.000 eval_frame.py:1039(_fn)
      129    0.001    0.000    0.331    0.003 model.py:432(forward)
      129    0.009    0.000    0.330    0.003 model.py:339(forward_joint)
  368/288    0.004    0.000    0.289    0.001 utils.py:119(call_func_at_runtime_with_args)
      288    0.003    0.000    0.263    0.001 output_code.py:590(__call__)
      258    0.001    0.000    0.262    0.001 model.py:270(_encode_with_shared_body)
      258    0.032    0.000    0.260    0.001 model.py:138(forward)
     2709    0.015    0.000    0.259    0.000 container.py:245(forward)
      288    0.001    0.000    0.230    0.001 compile_fx.py:1767(run)
      288    0.000    0.000    0.228    0.001 cudagraph_trees.py:378(deferred_cudagraphify)
      288    0.001    0.000    0.228    0.001 utils.py:3013(run)
  494/288    0.004    0.000    0.223    0.001 cudagraph_trees.py:2008(run)
  494/288    0.001    0.000    0.219    0.001 cudagraph_trees.py:2073(_run)
      287    0.002    0.000    0.193    0.001 cudagraph_trees.py:2241(execute_node)
        6    0.182    0.030    0.182    0.030 {method 'item' of 'torch._C.TensorBase' objects}
      287    0.002    0.000    0.165    0.001 cudagraph_trees.py:1105(run)
      208    0.001    0.000    0.162    0.001 aot_autograd.py:1126(forward)
       80    0.017    0.000    0.160    0.002 function.py:300(apply)
      208    0.001    0.000    0.156    0.001 runtime_wrappers.py:310(runtime_wrapper)
      287    0.001    0.000    0.149    0.001 cudagraph_trees.py:1219(run_graph)
       80    0.000    0.000    0.143    0.002 runtime_wrappers.py:2239(backward)
       80    0.002    0.000    0.143    0.002 runtime_wrappers.py:2288(impl_fn)
       80    0.000    0.000    0.134    0.002 runtime_wrappers.py:2330(_backward_impl)
      208    0.001    0.000    0.133    0.001 runtime_wrappers.py:512(wrapper)
       80    0.001    0.000    0.127    0.002 c2nq3fpwvq4n3mib57z65u5vh4mbhgzpnadeue3wffmnyqtvihfi.py:5966(call)
     3479    0.117    0.000    0.117    0.000 {method 'clone' of 'torch._C.TensorBase' objects}
      288    0.103    0.000    0.113    0.000 graphs.py:139(replay)
      127    0.016    0.000    0.108    0.001 env.py:890(_step_with_policy_impl)
     3096    0.003    0.000    0.099    0.000 linear.py:130(forward)
     3096    0.094    0.000    0.094    0.000 {built-in method torch._C._nn.linear}
      129    0.000    0.000    0.076    0.001 model.py:584(extract_features)
      129    0.002    0.000    0.075    0.001 model.py:66(forward)
   240/80    0.004    0.000    0.074    0.001 clip_grad.py:41(_no_grad_wrapper)
       80    0.002    0.000    0.072    0.001 clip_grad.py:185(clip_grad_norm_)




================================================================================
PROFILING RESULTS - Top by Total Time
================================================================================
         618117 function calls (543190 primitive calls) in 2.500 seconds

   Ordered by: internal time
   List reduced from 743 to 40 due to restriction <40>

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
       80    1.150    0.014    1.309    0.016 {method 'run_backward' of 'torch._C._EngineBase' objects}
        6    0.182    0.030    0.182    0.030 {method 'item' of 'torch._C.TensorBase' objects}
     3479    0.117    0.000    0.117    0.000 {method 'clone' of 'torch._C.TensorBase' objects}
      288    0.103    0.000    0.113    0.000 graphs.py:139(replay)
     3096    0.094    0.000    0.094    0.000 {built-in method torch._C._nn.linear}
     2322    0.043    0.000    0.043    0.000 {built-in method torch.layer_norm}
  289/288    0.039    0.000    0.039    0.000 {built-in method torch._foreach_copy_}
     2709    0.038    0.000    0.038    0.000 {built-in method torch.relu}
      258    0.032    0.000    0.260    0.001 model.py:138(forward)
16543/338    0.025    0.000    0.478    0.001 module.py:1779(_call_impl)
      516    0.023    0.000    0.023    0.000 {built-in method torch.embedding}
16543/338    0.018    0.000    0.479    0.001 module.py:1771(_wrapped_call_impl)
       80    0.017    0.000    0.160    0.002 function.py:300(apply)
      127    0.016    0.000    0.108    0.001 env.py:890(_step_with_policy_impl)
     2709    0.015    0.000    0.259    0.000 container.py:245(forward)
      258    0.014    0.000    0.017    0.000 embeddings.py:771(forward)
        1    0.012    0.012    0.014    0.014 rollout.py:244(compute_returns_and_advantage)
      128    0.012    0.000    0.014    0.000 rollout.py:204(add)
       80    0.012    0.000    0.012    0.000 {built-in method torch._foreach_norm}
      1/0    0.012    0.012    0.000          _tensor.py:570(backward)
44480/5840    0.011    0.000    0.013    0.000 module.py:2823(named_modules)
     5047    0.010    0.000    0.010    0.000 {method 'to' of 'torch._C.TensorBase' objects}
      117    0.010    0.000    0.010    0.000 {built-in method torch.where}
      640    0.010    0.000    0.010    0.000 {built-in method torch.index_select}
      449    0.009    0.000    0.009    0.000 {built-in method torch._ops.profiler._record_function_enter_new}
    16687    0.009    0.000    0.009    0.000 {built-in method torch._C._get_tracing_state}
      129    0.009    0.000    0.330    0.003 model.py:339(forward_joint)
      192    0.009    0.000    0.009    0.000 {method 'cpu' of 'torch._C.TensorBase' objects}
      760    0.009    0.000    0.009    0.000 {method 'copy_' of 'torch._C.TensorBase' objects}
      287    0.008    0.000    0.011    0.000 cudagraph_trees.py:1126(reconstruct_outputs)
       80    0.008    0.000    0.067    0.001 ppo.py:155(forward)
       80    0.008    0.000    0.012    0.000 adam.py:138(_init_group)
      343    0.008    0.000    0.008    0.000 {method 'mean' of 'torch._C.TensorBase' objects}
     2322    0.008    0.000    0.014    0.000 functional.py:1394(dropout)
     8518    0.007    0.000    0.013    0.000 cudagraph_trees.py:534(expired)
    15867    0.007    0.000    0.007    0.000 module.py:1951(__getattr__)
    57563    0.007    0.000    0.007    0.000 {method 'append' of 'list' objects}
60124/59832    0.006    0.000    0.007    0.000 {built-in method builtins.isinstance}
      201    0.006    0.000    0.006    0.000 {built-in method torch.zeros}
      129    0.006    0.000    0.006    0.000 {built-in method torch.matmul}




Results saved to /home/castellanoontiv/Batched_env/kge_experiments/tests/profile_learn_results.txt
