Profile Optimal Learn Results
Date: 2026-01-04 21:27:28
Device: cuda
Dataset: family

Configuration:
  Total timesteps (profiled): 1
  Batch size env: 128
  N steps per rollout: 128
  N epochs: 5
  Minibatch size: 1024
  Compile mode: reduce-overhead
  Fullgraph: True


Setting up components...
[EnvOptimal] Compiled with mode=reduce-overhead, fullgraph=True
[PPOOptimal] Fused rollout step compiled
[PPOOptimal] Compilation complete
[PPOOptimal] Fused eval step compiled
[PPOOptimal] Ranking loop step compiled
[PPOOptimal] Initialized with device=cuda, batch_size_env=128
Initialization time: 6.82s

Running warmup (compilation + first rollout)...
[EnvOptimal] Compiled with mode=reduce-overhead, fullgraph=True
Warmup: Running learn() iteration to compile all graphs...
[PPOOptimal] Training for 5 epochs...
Epoch 1/5. 
Losses: total 1.16763, value 3.09234, policy 0.00677, entropy -0.02701, approx_kl 0.02084 clip_fraction 0.02966. 
Epoch 2/5. 
Losses: total 0.84839, value 2.43537, policy 0.00679, entropy -0.02638, approx_kl 0.05246 clip_fraction 0.03964. 
Epoch 3/5. 
Losses: total 0.60306, value 2.04012, policy 0.00569, entropy -0.02600, approx_kl 0.07701 clip_fraction 0.04468. 
Epoch 4/5. 
Losses: total 0.46345, value 1.76861, policy 0.00461, entropy -0.02595, approx_kl 0.09801 clip_fraction 0.04799. 
Epoch 5/5. 
Losses: total 0.31352, value 1.56582, policy 0.00384, entropy -0.02613, approx_kl 0.11456 clip_fraction 0.05071. 
Warmup time: 23.69s

Profiling training for 1 timesteps...
[PPOOptimal] Training for 5 epochs...
Epoch 1/5. 
Losses: total 0.42537, value 0.97739, policy 0.00310, entropy -0.02812, approx_kl 0.00834 clip_fraction 0.02106. 
Epoch 2/5. 
Losses: total 0.36186, value 0.88847, policy 0.00092, entropy -0.02763, approx_kl 0.04501 clip_fraction 0.02856. 
Epoch 3/5. 
Losses: total 0.31606, value 0.80373, policy -0.00036, entropy -0.02798, approx_kl 0.06764 clip_fraction 0.03426. 
Epoch 4/5. 
Losses: total 0.20794, value 0.73017, policy -0.00124, entropy -0.02886, approx_kl 0.08570 clip_fraction 0.03935. 
Epoch 5/5. 
Losses: total 0.17773, value 0.66753, policy -0.00195, entropy -0.02972, approx_kl 0.10075 clip_fraction 0.04336. 

================================================================================
TIMING SUMMARY
================================================================================
Init time:         6.8220s
Warmup time:       23.6874s
Runtime:           13.7603s
Total time:        37.4478s
Steps/second:      1190.7
Total timesteps:   32768 (Warmup: 16384, Profiled: 16384)

Target: Runtime ≤ 16s
Status: PASS ✓

Last training metrics:
  policy_loss: -0.0019
  value_loss: 0.6675
  entropy: 0.0297
  clip_fraction: 0.0434
  approx_kl: 0.1609
  explained_var: -7.3109

================================================================================
PROFILING RESULTS - Top by Cumulative Time
================================================================================
         511125 function calls (489795 primitive calls) in 11.835 seconds

   Ordered by: cumulative time
   List reduced from 739 to 40 due to restriction <40>

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
       36    3.919    0.109    3.919    0.109 {method 'item' of 'torch._C.TensorBase' objects}
       80    0.000    0.000    3.116    0.039 __init__.py:243(backward)
       80    0.002    0.000    3.116    0.039 graph.py:832(_engine_run_backward)
       80    3.035    0.038    3.110    0.039 {method 'run_backward' of 'torch._C._EngineBase' objects}
   240/80    0.005    0.000    3.008    0.038 clip_grad.py:41(_no_grad_wrapper)
       80    0.003    0.000    3.006    0.038 clip_grad.py:185(clip_grad_norm_)
       80    0.003    0.000    2.962    0.037 clip_grad.py:49(_get_total_norm)
       80    2.945    0.037    2.945    0.037 {built-in method torch._foreach_norm}
        7    0.985    0.141    0.985    0.141 {method 'acquire' of '_thread.lock' objects}
      947    0.007    0.000    0.318    0.000 eval_frame.py:1039(_fn)
 4159/596    0.005    0.000    0.267    0.000 module.py:1771(_wrapped_call_impl)
 4159/596    0.007    0.000    0.266    0.000 module.py:1779(_call_impl)
  369/289    0.004    0.000    0.228    0.001 utils.py:119(call_func_at_runtime_with_args)
      209    0.002    0.000    0.217    0.001 aot_autograd.py:1126(forward)
      209    0.009    0.000    0.214    0.001 runtime_wrappers.py:310(runtime_wrapper)
      289    0.003    0.000    0.199    0.001 output_code.py:590(__call__)
      129    0.001    0.000    0.193    0.001 policy.py:331(predict_values)
      289    0.001    0.000    0.166    0.001 compile_fx.py:1767(run)
      289    0.000    0.000    0.164    0.001 cudagraph_trees.py:378(deferred_cudagraphify)
      289    0.001    0.000    0.164    0.001 utils.py:3013(run)
  496/289    0.004    0.000    0.160    0.001 cudagraph_trees.py:2008(run)
      209    0.001    0.000    0.155    0.001 runtime_wrappers.py:512(wrapper)
  496/289    0.001    0.000    0.155    0.001 cudagraph_trees.py:2073(_run)
      288    0.002    0.000    0.133    0.000 cudagraph_trees.py:2241(execute_node)
      129    0.001    0.000    0.131    0.001 policy.py:234(forward_critic)
      128    0.013    0.000    0.126    0.001 ppo.py:252(fused_step)
      129    0.000    0.000    0.112    0.001 policy.py:180(_get_shared_features)
      129    0.015    0.000    0.111    0.001 policy.py:113(forward)
      288    0.002    0.000    0.103    0.000 cudagraph_trees.py:1105(run)
      128    0.001    0.000    0.094    0.001 cdlhwhnkzkq6gggtl7ftj4ufrartrtuezfm7czwj7vd6ghl63tvv.py:12049(call)
     1161    0.005    0.000    0.092    0.000 kernels.py:43(forward)
      288    0.001    0.000    0.088    0.000 cudagraph_trees.py:1219(run_graph)
       80    0.018    0.000    0.075    0.001 function.py:300(apply)
       80    0.008    0.000    0.074    0.001 ppo.py:63(forward)
      289    0.006    0.000    0.068    0.000 cudagraph_trees.py:1057(_copy_inputs_and_remove_from_src)
  290/289    0.060    0.000    0.060    0.000 {built-in method torch._foreach_copy_}
      129    0.001    0.000    0.060    0.000 policy.py:54(forward)
       80    0.001    0.000    0.059    0.001 utils.py:102(g)
      129    0.000    0.000    0.059    0.000 base.py:12480(clone)
      129    0.000    0.000    0.058    0.000 _td.py:3261(_clone)




================================================================================
PROFILING RESULTS - Top by Total Time
================================================================================
         511125 function calls (489795 primitive calls) in 11.835 seconds

   Ordered by: internal time
   List reduced from 739 to 40 due to restriction <40>

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
       36    3.919    0.109    3.919    0.109 {method 'item' of 'torch._C.TensorBase' objects}
       80    3.035    0.038    3.110    0.039 {method 'run_backward' of 'torch._C._EngineBase' objects}
       80    2.945    0.037    2.945    0.037 {built-in method torch._foreach_norm}
        7    0.985    0.141    0.985    0.141 {method 'acquire' of '_thread.lock' objects}
  290/289    0.060    0.000    0.060    0.000 {built-in method torch._foreach_copy_}
     1419    0.056    0.000    0.056    0.000 {built-in method torch._C._nn.linear}
      508    0.046    0.000    0.046    0.000 {method 'cpu' of 'torch._C.TensorBase' objects}
      129    0.036    0.000    0.036    0.000 {built-in method torch._foreach_add}
     84/0    0.034    0.000    0.000          eval_frame.py:791(compile_wrapper)
     1161    0.024    0.000    0.024    0.000 {built-in method torch.layer_norm}
     1169    0.023    0.000    0.023    0.000 {method 'clone' of 'torch._C.TensorBase' objects}
      516    0.021    0.000    0.021    0.000 {built-in method torch.embedding}
      289    0.019    0.000    0.028    0.000 graphs.py:139(replay)
       80    0.018    0.000    0.075    0.001 function.py:300(apply)
      127    0.017    0.000    0.017    0.000 {method 'nonzero' of 'torch._C.TensorBase' objects}
     1290    0.016    0.000    0.016    0.000 {built-in method torch.relu_}
      129    0.015    0.000    0.111    0.001 policy.py:113(forward)
      128    0.013    0.000    0.126    0.001 ppo.py:252(fused_step)
      128    0.013    0.000    0.015    0.000 rollout.py:204(add)
        1    0.013    0.013    0.015    0.015 rollout.py:244(compute_returns_and_advantage)
      890    0.012    0.000    0.012    0.000 {method 'copy_' of 'torch._C.TensorBase' objects}
      258    0.011    0.000    0.014    0.000 embeddings.py:771(forward)
      368    0.011    0.000    0.011    0.000 {method 'mean' of 'torch._C.TensorBase' objects}
      640    0.011    0.000    0.011    0.000 {built-in method torch.index_select}
      450    0.010    0.000    0.010    0.000 {built-in method torch._ops.profiler._record_function_enter_new}
      209    0.009    0.000    0.214    0.001 runtime_wrappers.py:310(runtime_wrapper)
       80    0.009    0.000    0.013    0.000 adam.py:138(_init_group)
      288    0.008    0.000    0.011    0.000 cudagraph_trees.py:1126(reconstruct_outputs)
       80    0.008    0.000    0.074    0.001 ppo.py:63(forward)
     8247    0.008    0.000    0.013    0.000 cudagraph_trees.py:534(expired)
        1    0.007    0.007    0.025    0.025 env.py:689(_sample_negatives)
      508    0.007    0.000    0.007    0.000 {method 'numpy' of 'torch._C.TensorBase' objects}
 4159/596    0.007    0.000    0.266    0.000 module.py:1779(_call_impl)
62740/62620    0.007    0.000    0.008    0.000 {built-in method builtins.isinstance}
      947    0.007    0.000    0.318    0.000 eval_frame.py:1039(_fn)
       80    0.006    0.000    0.019    0.000 clip_grad.py:120(_clip_grads_with_norm_)
       82    0.006    0.000    0.006    0.000 {built-in method torch.stack}
       80    0.006    0.000    0.050    0.001 runtime_wrappers.py:2083(forward)
       80    0.006    0.000    0.015    0.000 optimizer.py:997(zero_grad)
      289    0.006    0.000    0.068    0.000 cudagraph_trees.py:1057(_copy_inputs_and_remove_from_src)




Results saved to /home/castellanoontiv/Batched_env/kge_experiments/tests/profile_learn_optimal_results.txt
