Profile Optimal Learn Results
Date: 2026-01-05 00:48:20
Device: cuda
Dataset: family

Configuration:
  Total timesteps (profiled): 1
  Batch size env: 128
  N steps per rollout: 128
  N epochs: 5
  Minibatch size: 1024
  Compile mode: reduce-overhead
  Fullgraph: True


Setting up components...
[EnvOptimal] Compiled with mode=reduce-overhead, fullgraph=True
[PPOOptimal] Fused rollout step compiled
[PPOOptimal] Compilation complete
[PPOOptimal] Fused eval step compiled
[PPOOptimal] Ranking loop step compiled
[PPOOptimal] Initialized with device=cuda, batch_size_env=128
Initialization time: 3.64s

Running warmup (compilation + first rollout)...
[EnvOptimal] Compiled with mode=reduce-overhead, fullgraph=True
Warmup: Running learn() iteration to compile all graphs...
[PPOOptimal] Training for 5 epochs...
Epoch 1/5. 
Losses: total 1.18234, value 3.08196, policy 0.00745, entropy -0.02673, approx_kl 0.02020 clip_fraction 0.02924. 
Epoch 2/5. 
Losses: total 0.81599, value 2.43272, policy 0.00601, entropy -0.02653, approx_kl 0.05217 clip_fraction 0.03900. 
Epoch 3/5. 
Losses: total 0.60883, value 2.03794, policy 0.00500, entropy -0.02622, approx_kl 0.07573 clip_fraction 0.04409. 
Epoch 4/5. 
Losses: total 0.45253, value 1.76585, policy 0.00406, entropy -0.02627, approx_kl 0.09520 clip_fraction 0.04762. 
Epoch 5/5. 
Losses: total 0.31558, value 1.56383, policy 0.00315, entropy -0.02646, approx_kl 0.11309 clip_fraction 0.05071. 
Warmup time: 19.35s

Profiling training for 1 timesteps...
[PPOOptimal] Training for 5 epochs...
Epoch 1/5. 
Losses: total 0.45626, value 0.97835, policy 0.00322, entropy -0.02798, approx_kl 0.01491 clip_fraction 0.02301. 
Epoch 2/5. 
Losses: total 0.42654, value 0.88619, policy 0.00267, entropy -0.02749, approx_kl 0.04081 clip_fraction 0.03113. 
Epoch 3/5. 
Losses: total 0.31475, value 0.80267, policy 0.00156, entropy -0.02760, approx_kl 0.06354 clip_fraction 0.03733. 
Epoch 4/5. 
Losses: total 0.20046, value 0.73024, policy 0.00050, entropy -0.02774, approx_kl 0.08376 clip_fraction 0.04170. 
Epoch 5/5. 
Losses: total 0.18293, value 0.66817, policy -0.00024, entropy -0.02841, approx_kl 0.09784 clip_fraction 0.04514. 

================================================================================
TIMING SUMMARY
================================================================================
Init time:         3.6352s
Warmup time:       19.3519s
Runtime:           13.8132s
Total time:        33.1651s
Steps/second:      1186.1
Total timesteps:   32768 (Warmup: 16384, Profiled: 16384)

Target: Runtime ≤ 16s
Status: PASS ✓

Last training metrics:
  policy_loss: -0.0002
  value_loss: 0.6682
  entropy: 0.0284
  clip_fraction: 0.0451
  approx_kl: 0.1541
  explained_var: -7.2600

================================================================================
PROFILING RESULTS - Top by Cumulative Time
================================================================================
         515447 function calls (494121 primitive calls) in 13.757 seconds

   Ordered by: cumulative time
   List reduced from 740 to 40 due to restriction <40>

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
       36    4.903    0.136    4.903    0.136 {method 'item' of 'torch._C.TensorBase' objects}
       80    0.000    0.000    3.103    0.039 __init__.py:243(backward)
       80    0.001    0.000    3.103    0.039 graph.py:832(_engine_run_backward)
       80    3.031    0.038    3.098    0.039 {method 'run_backward' of 'torch._C._EngineBase' objects}
   240/80    0.004    0.000    2.946    0.037 clip_grad.py:41(_no_grad_wrapper)
       80    0.002    0.000    2.944    0.037 clip_grad.py:185(clip_grad_norm_)
       80    0.002    0.000    2.905    0.036 clip_grad.py:49(_get_total_norm)
       80    2.890    0.036    2.890    0.036 {built-in method torch._foreach_norm}
      128    1.927    0.015    1.927    0.015 {built-in method torch.nonzero}
      947    0.007    0.000    0.298    0.000 eval_frame.py:1039(_fn)
 4159/596    0.007    0.000    0.283    0.000 module.py:1771(_wrapped_call_impl)
 4159/596    0.009    0.000    0.282    0.000 module.py:1779(_call_impl)
  369/289    0.004    0.000    0.242    0.001 utils.py:119(call_func_at_runtime_with_args)
      129    0.001    0.000    0.218    0.002 policy.py:331(predict_values)
      289    0.003    0.000    0.215    0.001 output_code.py:590(__call__)
      209    0.001    0.000    0.203    0.001 aot_autograd.py:1126(forward)
      209    0.001    0.000    0.201    0.001 runtime_wrappers.py:310(runtime_wrapper)
      289    0.002    0.000    0.175    0.001 compile_fx.py:1767(run)
      209    0.001    0.000    0.175    0.001 runtime_wrappers.py:512(wrapper)
      289    0.001    0.000    0.173    0.001 cudagraph_trees.py:378(deferred_cudagraphify)
      289    0.001    0.000    0.173    0.001 utils.py:3013(run)
  496/289    0.004    0.000    0.168    0.001 cudagraph_trees.py:2008(run)
      128    0.021    0.000    0.163    0.001 ppo.py:274(fused_step)
  496/289    0.001    0.000    0.162    0.001 cudagraph_trees.py:2073(_run)
      129    0.001    0.000    0.143    0.001 policy.py:234(forward_critic)
      288    0.002    0.000    0.142    0.000 cudagraph_trees.py:2241(execute_node)
      129    0.000    0.000    0.124    0.001 policy.py:180(_get_shared_features)
      129    0.016    0.000    0.123    0.001 policy.py:113(forward)
      128    0.002    0.000    0.116    0.001 cvg7szrnhyrgb5pjdatmghp26mgpemb3bdyavbwmtp6cy3elqtfw.py:12038(call)
      288    0.002    0.000    0.113    0.000 cudagraph_trees.py:1105(run)
     1161    0.006    0.000    0.100    0.000 kernels.py:43(forward)
      288    0.001    0.000    0.097    0.000 cudagraph_trees.py:1219(run_graph)
      289    0.006    0.000    0.076    0.000 cudagraph_trees.py:1057(_copy_inputs_and_remove_from_src)
      129    0.002    0.000    0.072    0.001 policy.py:54(forward)
        1    0.000    0.000    0.070    0.070 threading.py:637(wait)
        1    0.000    0.000    0.070    0.070 threading.py:323(wait)
        7    0.069    0.010    0.070    0.010 {method 'acquire' of '_thread.lock' objects}
      258    0.006    0.000    0.070    0.000 embeddings.py:1256(get_embeddings_batch)
      129    0.000    0.000    0.069    0.001 base.py:12480(clone)
       80    0.016    0.000    0.068    0.001 function.py:300(apply)




================================================================================
PROFILING RESULTS - Top by Total Time
================================================================================
         515447 function calls (494121 primitive calls) in 13.757 seconds

   Ordered by: internal time
   List reduced from 740 to 40 due to restriction <40>

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
       36    4.903    0.136    4.903    0.136 {method 'item' of 'torch._C.TensorBase' objects}
       80    3.031    0.038    3.098    0.039 {method 'run_backward' of 'torch._C._EngineBase' objects}
       80    2.890    0.036    2.890    0.036 {built-in method torch._foreach_norm}
      128    1.927    0.015    1.927    0.015 {built-in method torch.nonzero}
        7    0.069    0.010    0.070    0.010 {method 'acquire' of '_thread.lock' objects}
  290/289    0.066    0.000    0.067    0.000 {built-in method torch._foreach_copy_}
     1419    0.059    0.000    0.059    0.000 {built-in method torch._C._nn.linear}
      508    0.047    0.000    0.047    0.000 {method 'cpu' of 'torch._C.TensorBase' objects}
      129    0.039    0.000    0.039    0.000 {built-in method torch._foreach_add}
      516    0.027    0.000    0.027    0.000 {built-in method torch.embedding}
     1161    0.024    0.000    0.024    0.000 {built-in method torch.layer_norm}
     1172    0.024    0.000    0.024    0.000 {method 'clone' of 'torch._C.TensorBase' objects}
      289    0.021    0.000    0.027    0.000 graphs.py:139(replay)
      1/0    0.021    0.021    0.000          _tensor.py:570(backward)
      128    0.021    0.000    0.163    0.001 ppo.py:274(fused_step)
     1290    0.018    0.000    0.018    0.000 {built-in method torch.relu_}
      128    0.017    0.000    0.019    0.000 rollout.py:204(add)
      129    0.016    0.000    0.123    0.001 policy.py:113(forward)
       80    0.016    0.000    0.068    0.001 function.py:300(apply)
      258    0.013    0.000    0.017    0.000 embeddings.py:771(forward)
        1    0.013    0.013    0.016    0.016 rollout.py:244(compute_returns_and_advantage)
      890    0.012    0.000    0.012    0.000 {method 'copy_' of 'torch._C.TensorBase' objects}
      450    0.011    0.000    0.011    0.000 {built-in method torch._ops.profiler._record_function_enter_new}
      368    0.011    0.000    0.011    0.000 {method 'mean' of 'torch._C.TensorBase' objects}
      640    0.010    0.000    0.010    0.000 {built-in method torch.index_select}
 4159/596    0.009    0.000    0.282    0.000 module.py:1779(_call_impl)
      288    0.008    0.000    0.011    0.000 cudagraph_trees.py:1126(reconstruct_outputs)
       80    0.008    0.000    0.012    0.000 adam.py:138(_init_group)
      254    0.008    0.000    0.008    0.000 {method 'masked_fill_' of 'torch._C.TensorBase' objects}
63248/63128    0.007    0.000    0.009    0.000 {built-in method builtins.isinstance}
      947    0.007    0.000    0.298    0.000 eval_frame.py:1039(_fn)
 4159/596    0.007    0.000    0.283    0.000 module.py:1771(_wrapped_call_impl)
       80    0.007    0.000    0.066    0.001 ppo.py:63(forward)
     8247    0.007    0.000    0.012    0.000 cudagraph_trees.py:534(expired)
      258    0.006    0.000    0.070    0.000 embeddings.py:1256(get_embeddings_batch)
      289    0.006    0.000    0.076    0.000 cudagraph_trees.py:1057(_copy_inputs_and_remove_from_src)
       80    0.006    0.000    0.014    0.000 optimizer.py:997(zero_grad)
    50918    0.006    0.000    0.006    0.000 {method 'append' of 'list' objects}
      254    0.006    0.000    0.006    0.000 {method 'bool' of 'torch._C.TensorBase' objects}
     1161    0.006    0.000    0.100    0.000 kernels.py:43(forward)




Results saved to /home/castellanoontiv/Batched_env/kge_experiments/tests/profile_learn_optimal_results.txt
