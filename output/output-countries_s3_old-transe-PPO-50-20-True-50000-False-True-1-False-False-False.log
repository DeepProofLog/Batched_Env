Experiment number  0  out of  1  experiments.
Seed 0  in  [0]

Run vars: countries_s3_old-transe-PPO-50-20-True-50000-False-True-1-False-False-False 
 Namespace(train_neg_pos_ratio=1, limit_space=False, dynamic_neg=True, standard_corruptions=False, dataset_name='countries_s3_old', data_path='./data/', domain_file=None, janus_file='train.pl', train_file='train_label_corruptions.json', valid_file='valid_queries.txt', test_file='test_queries.txt', dynamic_consult=False, learn_embeddings=True, kge='transe', model_name='PPO', atom_embedding_size=50, constant_embedding_size=50, predicate_embedding_size=50, constant_emb_file='./data/countries_s3_old/constant_embeddings.pkl', predicate_emb_file='./data/countries_s3_old/predicate_embeddings.pkl', rule_depend_var=False, variable_no=500, device='cpu', seed=[0], restore_best_val_model=False, load_model=False, save_model=True, models_path='models/countries_s3_old', timesteps_train=50000, n_epochs=10, n_steps=2048, eval_freq=5000, batch_size=64, lr=0.0003, max_depth=20, run_signature='countries_s3_old-transe-PPO-50-20-True-50000-False-True-1-False-False-False', seed_run_i=0) 

ratio of positives in train 0.50
                      valid 0.29
                      test 0.30
Using cpu device
Wrapping the env with a `Monitor` wrapper
Wrapping the env in a DummyVecEnv.
Epoch 1 completed in 2.57 seconds.
Metric "train/loss" not found. Available: dict_keys([])
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 8.5      |
|    ep_rew_mean     | 0.08     |
| time/              |          |
|    fps             | 792      |
|    iterations      | 1        |
|    time_elapsed    | 2        |
|    total_timesteps | 2048     |
---------------------------------
Epoch 2 completed in 2.59 seconds.
Improved train/loss to 0.0032
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 9.35        |
|    ep_rew_mean          | 0.16        |
| time/                   |             |
|    fps                  | 629         |
|    iterations           | 2           |
|    time_elapsed         | 6           |
|    total_timesteps      | 4096        |
| train/                  |             |
|    approx_kl            | 0.014957954 |
|    clip_fraction        | 0.167       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.778      |
|    explained_variance   | -0.106      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00324     |
|    n_updates            | 10          |
|    policy_gradient_loss | -0.0167     |
|    value_loss           | 0.0717      |
-----------------------------------------
Eval num_timesteps=5000, episode_reward=0.01 +/- 0.11
Episode length: 6.93 +/- 1.91
New best mean reward!
Epoch 3 completed in 3.23 seconds.
Improved train/loss to 0.0005
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 9.58        |
|    ep_rew_mean          | 0.19        |
| time/                   |             |
|    fps                  | 560         |
|    iterations           | 3           |
|    time_elapsed         | 10          |
|    total_timesteps      | 6144        |
| train/                  |             |
|    approx_kl            | 0.017960927 |
|    clip_fraction        | 0.162       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.774      |
|    explained_variance   | 0.0696      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.000457    |
|    n_updates            | 20          |
|    policy_gradient_loss | -0.0159     |
|    value_loss           | 0.053       |
-----------------------------------------
Epoch 4 completed in 3.09 seconds.
Improved train/loss to -0.0088
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 9.25       |
|    ep_rew_mean          | 0.17       |
| time/                   |            |
|    fps                  | 508        |
|    iterations           | 4          |
|    time_elapsed         | 16         |
|    total_timesteps      | 8192       |
| train/                  |            |
|    approx_kl            | 0.01837487 |
|    clip_fraction        | 0.186      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.784     |
|    explained_variance   | 0.141      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00883   |
|    n_updates            | 30         |
|    policy_gradient_loss | -0.0197    |
|    value_loss           | 0.0563     |
----------------------------------------
Eval num_timesteps=10000, episode_reward=0.06 +/- 0.24
Episode length: 6.82 +/- 1.69
New best mean reward!
Epoch 5 completed in 3.56 seconds.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 8.99        |
|    ep_rew_mean          | 0.21        |
| time/                   |             |
|    fps                  | 484         |
|    iterations           | 5           |
|    time_elapsed         | 21          |
|    total_timesteps      | 10240       |
| train/                  |             |
|    approx_kl            | 0.013735748 |
|    clip_fraction        | 0.158       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.73       |
|    explained_variance   | 0.149       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.000884    |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.0137     |
|    value_loss           | 0.0592      |
-----------------------------------------
Epoch 6 completed in 3.60 seconds.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 8.38        |
|    ep_rew_mean          | 0.24        |
| time/                   |             |
|    fps                  | 474         |
|    iterations           | 6           |
|    time_elapsed         | 25          |
|    total_timesteps      | 12288       |
| train/                  |             |
|    approx_kl            | 0.015259623 |
|    clip_fraction        | 0.166       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.707      |
|    explained_variance   | 0.186       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00305     |
|    n_updates            | 50          |
|    policy_gradient_loss | -0.0162     |
|    value_loss           | 0.0592      |
-----------------------------------------
Epoch 7 completed in 3.20 seconds.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 8.55        |
|    ep_rew_mean          | 0.28        |
| time/                   |             |
|    fps                  | 470         |
|    iterations           | 7           |
|    time_elapsed         | 30          |
|    total_timesteps      | 14336       |
| train/                  |             |
|    approx_kl            | 0.011540157 |
|    clip_fraction        | 0.134       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.693      |
|    explained_variance   | 0.13        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0284      |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.0104     |
|    value_loss           | 0.0813      |
-----------------------------------------
Eval num_timesteps=15000, episode_reward=0.06 +/- 0.24
Episode length: 6.29 +/- 1.83
Epoch 8 completed in 4.03 seconds.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 7.69        |
|    ep_rew_mean          | 0.23        |
| time/                   |             |
|    fps                  | 456         |
|    iterations           | 8           |
|    time_elapsed         | 35          |
|    total_timesteps      | 16384       |
| train/                  |             |
|    approx_kl            | 0.013829514 |
|    clip_fraction        | 0.138       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.679      |
|    explained_variance   | 0.206       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0206      |
|    n_updates            | 70          |
|    policy_gradient_loss | -0.0129     |
|    value_loss           | 0.078       |
-----------------------------------------
Epoch 9 completed in 3.86 seconds.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 7.6        |
|    ep_rew_mean          | 0.28       |
| time/                   |            |
|    fps                  | 441        |
|    iterations           | 9          |
|    time_elapsed         | 41         |
|    total_timesteps      | 18432      |
| train/                  |            |
|    approx_kl            | 0.01141073 |
|    clip_fraction        | 0.125      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.61      |
|    explained_variance   | 0.216      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0373     |
|    n_updates            | 80         |
|    policy_gradient_loss | -0.0128    |
|    value_loss           | 0.0898     |
----------------------------------------
Eval num_timesteps=20000, episode_reward=0.06 +/- 0.24
Episode length: 6.39 +/- 2.06
Epoch 10 completed in 4.70 seconds.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 7.93        |
|    ep_rew_mean          | 0.27        |
| time/                   |             |
|    fps                  | 427         |
|    iterations           | 10          |
|    time_elapsed         | 47          |
|    total_timesteps      | 20480       |
| train/                  |             |
|    approx_kl            | 0.011455077 |
|    clip_fraction        | 0.119       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.617      |
|    explained_variance   | 0.244       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0125      |
|    n_updates            | 90          |
|    policy_gradient_loss | -0.0118     |
|    value_loss           | 0.0832      |
-----------------------------------------
Epoch 11 completed in 3.87 seconds.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 8.64        |
|    ep_rew_mean          | 0.26        |
| time/                   |             |
|    fps                  | 421         |
|    iterations           | 11          |
|    time_elapsed         | 53          |
|    total_timesteps      | 22528       |
| train/                  |             |
|    approx_kl            | 0.012711529 |
|    clip_fraction        | 0.119       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.579      |
|    explained_variance   | 0.306       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0493      |
|    n_updates            | 100         |
|    policy_gradient_loss | -0.011      |
|    value_loss           | 0.0819      |
-----------------------------------------
Epoch 12 completed in 3.73 seconds.
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 7.76      |
|    ep_rew_mean          | 0.28      |
| time/                   |           |
|    fps                  | 419       |
|    iterations           | 12        |
|    time_elapsed         | 58        |
|    total_timesteps      | 24576     |
| train/                  |           |
|    approx_kl            | 0.0125537 |
|    clip_fraction        | 0.124     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.577    |
|    explained_variance   | 0.275     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.0368    |
|    n_updates            | 110       |
|    policy_gradient_loss | -0.013    |
|    value_loss           | 0.0873    |
---------------------------------------
Eval num_timesteps=25000, episode_reward=0.05 +/- 0.21
Episode length: 6.93 +/- 1.85
Epoch 13 completed in 4.14 seconds.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 7.62        |
|    ep_rew_mean          | 0.29        |
| time/                   |             |
|    fps                  | 413         |
|    iterations           | 13          |
|    time_elapsed         | 64          |
|    total_timesteps      | 26624       |
| train/                  |             |
|    approx_kl            | 0.013255991 |
|    clip_fraction        | 0.124       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.541      |
|    explained_variance   | 0.308       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0206      |
|    n_updates            | 120         |
|    policy_gradient_loss | -0.011      |
|    value_loss           | 0.0859      |
-----------------------------------------
Epoch 14 completed in 4.06 seconds.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 8.67       |
|    ep_rew_mean          | 0.28       |
| time/                   |            |
|    fps                  | 409        |
|    iterations           | 14         |
|    time_elapsed         | 70         |
|    total_timesteps      | 28672      |
| train/                  |            |
|    approx_kl            | 0.01189239 |
|    clip_fraction        | 0.121      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.53      |
|    explained_variance   | 0.301      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0244     |
|    n_updates            | 130        |
|    policy_gradient_loss | -0.0133    |
|    value_loss           | 0.0821     |
----------------------------------------
Eval num_timesteps=30000, episode_reward=0.06 +/- 0.24
Episode length: 7.21 +/- 2.26
Epoch 15 completed in 4.63 seconds.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 8.42        |
|    ep_rew_mean          | 0.29        |
| time/                   |             |
|    fps                  | 399         |
|    iterations           | 15          |
|    time_elapsed         | 76          |
|    total_timesteps      | 30720       |
| train/                  |             |
|    approx_kl            | 0.010908112 |
|    clip_fraction        | 0.113       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.532      |
|    explained_variance   | 0.285       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0382      |
|    n_updates            | 140         |
|    policy_gradient_loss | -0.0108     |
|    value_loss           | 0.079       |
-----------------------------------------
Epoch 16 completed in 3.78 seconds.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 8.38        |
|    ep_rew_mean          | 0.31        |
| time/                   |             |
|    fps                  | 396         |
|    iterations           | 16          |
|    time_elapsed         | 82          |
|    total_timesteps      | 32768       |
| train/                  |             |
|    approx_kl            | 0.009215847 |
|    clip_fraction        | 0.1         |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.544      |
|    explained_variance   | 0.343       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0279      |
|    n_updates            | 150         |
|    policy_gradient_loss | -0.00705    |
|    value_loss           | 0.0706      |
-----------------------------------------
Epoch 17 completed in 4.23 seconds.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 7.87        |
|    ep_rew_mean          | 0.31        |
| time/                   |             |
|    fps                  | 394         |
|    iterations           | 17          |
|    time_elapsed         | 88          |
|    total_timesteps      | 34816       |
| train/                  |             |
|    approx_kl            | 0.010255065 |
|    clip_fraction        | 0.111       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.541      |
|    explained_variance   | 0.39        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0235      |
|    n_updates            | 160         |
|    policy_gradient_loss | -0.00955    |
|    value_loss           | 0.0719      |
-----------------------------------------
Eval num_timesteps=35000, episode_reward=0.06 +/- 0.24
Episode length: 7.21 +/- 2.48
Epoch 18 completed in 4.67 seconds.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 8.46        |
|    ep_rew_mean          | 0.33        |
| time/                   |             |
|    fps                  | 388         |
|    iterations           | 18          |
|    time_elapsed         | 94          |
|    total_timesteps      | 36864       |
| train/                  |             |
|    approx_kl            | 0.013131749 |
|    clip_fraction        | 0.105       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.519      |
|    explained_variance   | 0.445       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.02        |
|    n_updates            | 170         |
|    policy_gradient_loss | -0.0117     |
|    value_loss           | 0.0611      |
-----------------------------------------
Epoch 19 completed in 4.58 seconds.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 8.19        |
|    ep_rew_mean          | 0.37        |
| time/                   |             |
|    fps                  | 384         |
|    iterations           | 19          |
|    time_elapsed         | 101         |
|    total_timesteps      | 38912       |
| train/                  |             |
|    approx_kl            | 0.016286284 |
|    clip_fraction        | 0.151       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.545      |
|    explained_variance   | 0.486       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.000547   |
|    n_updates            | 180         |
|    policy_gradient_loss | -0.0154     |
|    value_loss           | 0.0623      |
-----------------------------------------
Eval num_timesteps=40000, episode_reward=0.06 +/- 0.24
Episode length: 7.00 +/- 2.12
Epoch 20 completed in 4.91 seconds.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 8.21        |
|    ep_rew_mean          | 0.34        |
| time/                   |             |
|    fps                  | 379         |
|    iterations           | 20          |
|    time_elapsed         | 107         |
|    total_timesteps      | 40960       |
| train/                  |             |
|    approx_kl            | 0.011002855 |
|    clip_fraction        | 0.102       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.52       |
|    explained_variance   | 0.541       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0268      |
|    n_updates            | 190         |
|    policy_gradient_loss | -0.0113     |
|    value_loss           | 0.0589      |
-----------------------------------------
Epoch 21 completed in 4.28 seconds.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 8.04        |
|    ep_rew_mean          | 0.33        |
| time/                   |             |
|    fps                  | 377         |
|    iterations           | 21          |
|    time_elapsed         | 113         |
|    total_timesteps      | 43008       |
| train/                  |             |
|    approx_kl            | 0.014143568 |
|    clip_fraction        | 0.102       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.54       |
|    explained_variance   | 0.564       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.000199   |
|    n_updates            | 200         |
|    policy_gradient_loss | -0.0102     |
|    value_loss           | 0.0505      |
-----------------------------------------
Eval num_timesteps=45000, episode_reward=0.06 +/- 0.24
Episode length: 6.61 +/- 2.21
Epoch 22 completed in 4.74 seconds.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 8.2         |
|    ep_rew_mean          | 0.33        |
| time/                   |             |
|    fps                  | 375         |
|    iterations           | 22          |
|    time_elapsed         | 119         |
|    total_timesteps      | 45056       |
| train/                  |             |
|    approx_kl            | 0.009775996 |
|    clip_fraction        | 0.1         |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.545      |
|    explained_variance   | 0.636       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00512    |
|    n_updates            | 210         |
|    policy_gradient_loss | -0.0107     |
|    value_loss           | 0.0512      |
-----------------------------------------
Epoch 23 completed in 4.25 seconds.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 8.04        |
|    ep_rew_mean          | 0.32        |
| time/                   |             |
|    fps                  | 374         |
|    iterations           | 23          |
|    time_elapsed         | 125         |
|    total_timesteps      | 47104       |
| train/                  |             |
|    approx_kl            | 0.011886697 |
|    clip_fraction        | 0.124       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.527      |
|    explained_variance   | 0.624       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00426     |
|    n_updates            | 220         |
|    policy_gradient_loss | -0.0139     |
|    value_loss           | 0.0512      |
-----------------------------------------
Epoch 24 completed in 4.60 seconds.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 7.7         |
|    ep_rew_mean          | 0.31        |
| time/                   |             |
|    fps                  | 372         |
|    iterations           | 24          |
|    time_elapsed         | 131         |
|    total_timesteps      | 49152       |
| train/                  |             |
|    approx_kl            | 0.008502195 |
|    clip_fraction        | 0.0957      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.545      |
|    explained_variance   | 0.684       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00975     |
|    n_updates            | 230         |
|    policy_gradient_loss | -0.0105     |
|    value_loss           | 0.0447      |
-----------------------------------------
Eval num_timesteps=50000, episode_reward=0.12 +/- 0.32
Episode length: 6.96 +/- 2.83
New best mean reward!
Epoch 25 completed in 5.37 seconds.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 7.96        |
|    ep_rew_mean          | 0.3         |
| time/                   |             |
|    fps                  | 367         |
|    iterations           | 25          |
|    time_elapsed         | 139         |
|    total_timesteps      | 51200       |
| train/                  |             |
|    approx_kl            | 0.011955019 |
|    clip_fraction        | 0.12        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.537      |
|    explained_variance   | 0.717       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00318     |
|    n_updates            | 240         |
|    policy_gradient_loss | -0.0117     |
|    value_loss           | 0.0395      |
-----------------------------------------

Training completed!
Total training time: 100.24 seconds.
Average epoch time: 4.01 seconds.

Testing train set...
pos_queries: 26
neg_queries: 72
ratio_pos_queries: 0.270
mrr_mean: 0.951
mrr_std: 0.163
rewards_pos_mean: 0.731
rewards_pos_std: 0.444
rewards_neg_mean: 0.000
rewards_neg_std: 0.000
rewards_mean: 0.194
rewards_std: 0.395
episode_len_pos_mean: 5.269
episode_len_pos_std: 2.067
episode_len_neg_mean: 7.625
episode_len_neg_std: 2.446
episode_len_mean: 7.000
episode_len_std: 2.571
log_probs_pos_mean: -0.737
log_probs_pos_std: 0.821
log_probs_neg_mean: -2.563
log_probs_neg_std: 1.298
log_probs_mean: -2.078
log_probs_std: 1.438
auc_pr: 0.903

Testing val set...
pos_queries: 24
neg_queries: 60
ratio_pos_queries: 0.290
mrr_mean: 0.638
mrr_std: 0.334
rewards_pos_mean: 0.333
rewards_pos_std: 0.471
rewards_neg_mean: 0.000
rewards_neg_std: 0.000
rewards_mean: 0.095
rewards_std: 0.294
episode_len_pos_mean: 6.375
episode_len_pos_std: 2.446
episode_len_neg_mean: 7.450
episode_len_neg_std: 2.729
episode_len_mean: 7.143
episode_len_std: 2.695
log_probs_pos_mean: -1.795
log_probs_pos_std: 1.444
log_probs_neg_mean: -2.479
log_probs_neg_std: 1.486
log_probs_mean: -2.284
log_probs_std: 1.506
auc_pr: 0.488

Testing test set...
pos_queries: 25
neg_queries: 57
ratio_pos_queries: 0.300
mrr_mean: 0.838
mrr_std: 0.276
rewards_pos_mean: 0.360
rewards_pos_std: 0.480
rewards_neg_mean: 0.000
rewards_neg_std: 0.000
rewards_mean: 0.110
rewards_std: 0.313
episode_len_pos_mean: 5.440
episode_len_pos_std: 1.722
episode_len_neg_mean: 7.789
episode_len_neg_std: 2.419
episode_len_mean: 7.073
episode_len_std: 2.478
log_probs_pos_mean: -1.308
log_probs_pos_std: 0.998
log_probs_neg_mean: -2.801
log_probs_neg_std: 1.418
log_probs_mean: -2.346
log_probs_std: 1.474
auc_pr: 0.740
Writing results to ./runs/averaged_runs/experiments.csv
