Experiment number  0  out of  1  experiments.
Seed 0  in  [0]

Run vars: countries_s2-transe-PPO-50-20-True-50000-False-True-1-True-False-False 
 Namespace(train_neg_pos_ratio=1, limit_space=True, dynamic_neg=True, standard_corruptions=False, dataset_name='countries_s2', data_path='./data/', domain_file=None, janus_file='train.pl', train_file='train_label_corruptions.json', valid_file='valid_queries.txt', test_file='test_queries.txt', dynamic_consult=False, learn_embeddings=True, kge='transe', model_name='PPO', atom_embedding_size=50, constant_embedding_size=50, predicate_embedding_size=50, constant_emb_file='./data/countries_s2/constant_embeddings.pkl', predicate_emb_file='./data/countries_s2/predicate_embeddings.pkl', rule_depend_var=False, variable_no=500, device='cpu', seed=[0], restore_best_val_model=False, load_model=False, save_model=False, models_path='models/countries_s2', timesteps_train=50000, n_epochs=10, n_steps=2048, eval_freq=5000, batch_size=64, lr=0.0003, max_depth=20, run_signature='countries_s2-transe-PPO-50-20-True-50000-False-True-1-True-False-False', seed_run_i=0) 

ratio of positives in train 0.50
                      valid 0.30
                      test 0.30
Using cpu device
Wrapping the env with a `Monitor` wrapper
Wrapping the env in a DummyVecEnv.
Epoch 1 completed in 1.53 seconds.
Metric "train/loss" not found. Available: dict_keys([])
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 9.53     |
|    ep_rew_mean     | 0.49     |
| time/              |          |
|    fps             | 1321     |
|    iterations      | 1        |
|    time_elapsed    | 1        |
|    total_timesteps | 2048     |
---------------------------------
Epoch 2 completed in 2.80 seconds.
Improved train/loss to 0.0323
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 9.68        |
|    ep_rew_mean          | 0.49        |
| time/                   |             |
|    fps                  | 700         |
|    iterations           | 2           |
|    time_elapsed         | 5           |
|    total_timesteps      | 4096        |
| train/                  |             |
|    approx_kl            | 0.014502136 |
|    clip_fraction        | 0.138       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.474      |
|    explained_variance   | -0.124      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0323      |
|    n_updates            | 10          |
|    policy_gradient_loss | -0.014      |
|    value_loss           | 0.0972      |
-----------------------------------------
Eval num_timesteps=5000, episode_reward=0.30 +/- 0.46
Episode length: 12.14 +/- 7.58
New best mean reward!
Epoch 3 completed in 4.01 seconds.
Improved train/loss to 0.0211
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 9.59        |
|    ep_rew_mean          | 0.48        |
| time/                   |             |
|    fps                  | 525         |
|    iterations           | 3           |
|    time_elapsed         | 11          |
|    total_timesteps      | 6144        |
| train/                  |             |
|    approx_kl            | 0.014141865 |
|    clip_fraction        | 0.13        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.466      |
|    explained_variance   | 0.218       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0211      |
|    n_updates            | 20          |
|    policy_gradient_loss | -0.0146     |
|    value_loss           | 0.0769      |
-----------------------------------------
Epoch 4 completed in 2.91 seconds.
Improved train/loss to 0.0154
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 10.6        |
|    ep_rew_mean          | 0.5         |
| time/                   |             |
|    fps                  | 514         |
|    iterations           | 4           |
|    time_elapsed         | 15          |
|    total_timesteps      | 8192        |
| train/                  |             |
|    approx_kl            | 0.012720575 |
|    clip_fraction        | 0.125       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.46       |
|    explained_variance   | 0.242       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0154      |
|    n_updates            | 30          |
|    policy_gradient_loss | -0.0116     |
|    value_loss           | 0.0876      |
-----------------------------------------
Eval num_timesteps=10000, episode_reward=0.30 +/- 0.46
Episode length: 12.64 +/- 7.81
Epoch 5 completed in 3.89 seconds.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 10.9        |
|    ep_rew_mean          | 0.5         |
| time/                   |             |
|    fps                  | 488         |
|    iterations           | 5           |
|    time_elapsed         | 20          |
|    total_timesteps      | 10240       |
| train/                  |             |
|    approx_kl            | 0.013955838 |
|    clip_fraction        | 0.14        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.462      |
|    explained_variance   | 0.251       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0306      |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.0128     |
|    value_loss           | 0.0832      |
-----------------------------------------
Epoch 6 completed in 3.22 seconds.
Improved train/loss to 0.0137
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 10.9        |
|    ep_rew_mean          | 0.48        |
| time/                   |             |
|    fps                  | 480         |
|    iterations           | 6           |
|    time_elapsed         | 25          |
|    total_timesteps      | 12288       |
| train/                  |             |
|    approx_kl            | 0.013887211 |
|    clip_fraction        | 0.143       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.449      |
|    explained_variance   | 0.243       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0137      |
|    n_updates            | 50          |
|    policy_gradient_loss | -0.0135     |
|    value_loss           | 0.0831      |
-----------------------------------------
Epoch 7 completed in 2.98 seconds.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 10          |
|    ep_rew_mean          | 0.49        |
| time/                   |             |
|    fps                  | 482         |
|    iterations           | 7           |
|    time_elapsed         | 29          |
|    total_timesteps      | 14336       |
| train/                  |             |
|    approx_kl            | 0.017257404 |
|    clip_fraction        | 0.123       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.439      |
|    explained_variance   | 0.257       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0324      |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.0129     |
|    value_loss           | 0.0802      |
-----------------------------------------
Eval num_timesteps=15000, episode_reward=0.30 +/- 0.46
Episode length: 12.47 +/- 7.56
Epoch 8 completed in 2.77 seconds.
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 10.1         |
|    ep_rew_mean          | 0.49         |
| time/                   |              |
|    fps                  | 480          |
|    iterations           | 8            |
|    time_elapsed         | 34           |
|    total_timesteps      | 16384        |
| train/                  |              |
|    approx_kl            | 0.0135182645 |
|    clip_fraction        | 0.145        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.413       |
|    explained_variance   | 0.24         |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0149       |
|    n_updates            | 70           |
|    policy_gradient_loss | -0.0143      |
|    value_loss           | 0.0859       |
------------------------------------------
Epoch 9 completed in 3.24 seconds.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 10.2        |
|    ep_rew_mean          | 0.5         |
| time/                   |             |
|    fps                  | 466         |
|    iterations           | 9           |
|    time_elapsed         | 39          |
|    total_timesteps      | 18432       |
| train/                  |             |
|    approx_kl            | 0.013274568 |
|    clip_fraction        | 0.123       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.38       |
|    explained_variance   | 0.264       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0272      |
|    n_updates            | 80          |
|    policy_gradient_loss | -0.0126     |
|    value_loss           | 0.0884      |
-----------------------------------------
Eval num_timesteps=20000, episode_reward=0.30 +/- 0.46
Episode length: 12.54 +/- 7.83
Epoch 10 completed in 4.19 seconds.
Improved train/loss to 0.0057
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 11          |
|    ep_rew_mean          | 0.49        |
| time/                   |             |
|    fps                  | 450         |
|    iterations           | 10          |
|    time_elapsed         | 45          |
|    total_timesteps      | 20480       |
| train/                  |             |
|    approx_kl            | 0.017531423 |
|    clip_fraction        | 0.122       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.359      |
|    explained_variance   | 0.225       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00573     |
|    n_updates            | 90          |
|    policy_gradient_loss | -0.0125     |
|    value_loss           | 0.0879      |
-----------------------------------------
Epoch 11 completed in 3.67 seconds.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 10.8       |
|    ep_rew_mean          | 0.5        |
| time/                   |            |
|    fps                  | 440        |
|    iterations           | 11         |
|    time_elapsed         | 51         |
|    total_timesteps      | 22528      |
| train/                  |            |
|    approx_kl            | 0.01653299 |
|    clip_fraction        | 0.131      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.354     |
|    explained_variance   | 0.366      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0128     |
|    n_updates            | 100        |
|    policy_gradient_loss | -0.013     |
|    value_loss           | 0.0719     |
----------------------------------------
Epoch 12 completed in 3.38 seconds.
Improved train/loss to 0.0033
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 10.3        |
|    ep_rew_mean          | 0.5         |
| time/                   |             |
|    fps                  | 437         |
|    iterations           | 12          |
|    time_elapsed         | 56          |
|    total_timesteps      | 24576       |
| train/                  |             |
|    approx_kl            | 0.014994811 |
|    clip_fraction        | 0.127       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.335      |
|    explained_variance   | 0.35        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00333     |
|    n_updates            | 110         |
|    policy_gradient_loss | -0.0146     |
|    value_loss           | 0.0789      |
-----------------------------------------
Eval num_timesteps=25000, episode_reward=0.30 +/- 0.46
Episode length: 12.21 +/- 7.55
Epoch 13 completed in 4.26 seconds.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 10.2        |
|    ep_rew_mean          | 0.5         |
| time/                   |             |
|    fps                  | 428         |
|    iterations           | 13          |
|    time_elapsed         | 62          |
|    total_timesteps      | 26624       |
| train/                  |             |
|    approx_kl            | 0.014883151 |
|    clip_fraction        | 0.115       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.311      |
|    explained_variance   | 0.347       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0191      |
|    n_updates            | 120         |
|    policy_gradient_loss | -0.0116     |
|    value_loss           | 0.074       |
-----------------------------------------
Epoch 14 completed in 3.48 seconds.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 10          |
|    ep_rew_mean          | 0.5         |
| time/                   |             |
|    fps                  | 434         |
|    iterations           | 14          |
|    time_elapsed         | 66          |
|    total_timesteps      | 28672       |
| train/                  |             |
|    approx_kl            | 0.014050748 |
|    clip_fraction        | 0.111       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.298      |
|    explained_variance   | 0.384       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0284      |
|    n_updates            | 130         |
|    policy_gradient_loss | -0.00866    |
|    value_loss           | 0.0664      |
-----------------------------------------
Eval num_timesteps=30000, episode_reward=0.30 +/- 0.46
Episode length: 12.40 +/- 7.32
Epoch 15 completed in 4.19 seconds.
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 10.8         |
|    ep_rew_mean          | 0.5          |
| time/                   |              |
|    fps                  | 427          |
|    iterations           | 15           |
|    time_elapsed         | 71           |
|    total_timesteps      | 30720        |
| train/                  |              |
|    approx_kl            | 0.0143540185 |
|    clip_fraction        | 0.105        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.28        |
|    explained_variance   | 0.419        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00871      |
|    n_updates            | 140          |
|    policy_gradient_loss | -0.0106      |
|    value_loss           | 0.0624       |
------------------------------------------
Epoch 16 completed in 3.53 seconds.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 10.9        |
|    ep_rew_mean          | 0.47        |
| time/                   |             |
|    fps                  | 422         |
|    iterations           | 16          |
|    time_elapsed         | 77          |
|    total_timesteps      | 32768       |
| train/                  |             |
|    approx_kl            | 0.016848158 |
|    clip_fraction        | 0.117       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.294      |
|    explained_variance   | 0.514       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00628     |
|    n_updates            | 150         |
|    policy_gradient_loss | -0.00982    |
|    value_loss           | 0.0522      |
-----------------------------------------
Epoch 17 completed in 3.73 seconds.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 10.5        |
|    ep_rew_mean          | 0.49        |
| time/                   |             |
|    fps                  | 421         |
|    iterations           | 17          |
|    time_elapsed         | 82          |
|    total_timesteps      | 34816       |
| train/                  |             |
|    approx_kl            | 0.017417239 |
|    clip_fraction        | 0.114       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.279      |
|    explained_variance   | 0.655       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0107      |
|    n_updates            | 160         |
|    policy_gradient_loss | -0.013      |
|    value_loss           | 0.0365      |
-----------------------------------------
Eval num_timesteps=35000, episode_reward=0.30 +/- 0.46
Episode length: 13.02 +/- 8.06
Epoch 18 completed in 4.55 seconds.
Improved train/loss to 0.0011
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 10.2        |
|    ep_rew_mean          | 0.5         |
| time/                   |             |
|    fps                  | 417         |
|    iterations           | 18          |
|    time_elapsed         | 88          |
|    total_timesteps      | 36864       |
| train/                  |             |
|    approx_kl            | 0.009875307 |
|    clip_fraction        | 0.094       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.264      |
|    explained_variance   | 0.649       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00109     |
|    n_updates            | 170         |
|    policy_gradient_loss | -0.00756    |
|    value_loss           | 0.038       |
-----------------------------------------
Epoch 19 completed in 3.64 seconds.
Improved train/loss to -0.0122
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 10.1        |
|    ep_rew_mean          | 0.5         |
| time/                   |             |
|    fps                  | 414         |
|    iterations           | 19          |
|    time_elapsed         | 93          |
|    total_timesteps      | 38912       |
| train/                  |             |
|    approx_kl            | 0.011765957 |
|    clip_fraction        | 0.0883      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.251      |
|    explained_variance   | 0.791       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0122     |
|    n_updates            | 180         |
|    policy_gradient_loss | -0.00706    |
|    value_loss           | 0.021       |
-----------------------------------------
Eval num_timesteps=40000, episode_reward=0.30 +/- 0.46
Episode length: 13.57 +/- 7.73
Epoch 20 completed in 4.68 seconds.
Improved train/loss to -0.0241
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 10.3         |
|    ep_rew_mean          | 0.49         |
| time/                   |              |
|    fps                  | 416          |
|    iterations           | 20           |
|    time_elapsed         | 98           |
|    total_timesteps      | 40960        |
| train/                  |              |
|    approx_kl            | 0.0128256595 |
|    clip_fraction        | 0.104        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.252       |
|    explained_variance   | 0.883        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0241      |
|    n_updates            | 190          |
|    policy_gradient_loss | -0.0101      |
|    value_loss           | 0.013        |
------------------------------------------
Epoch 21 completed in 3.79 seconds.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 9.64        |
|    ep_rew_mean          | 0.5         |
| time/                   |             |
|    fps                  | 416         |
|    iterations           | 21          |
|    time_elapsed         | 103         |
|    total_timesteps      | 43008       |
| train/                  |             |
|    approx_kl            | 0.014434725 |
|    clip_fraction        | 0.11        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.23       |
|    explained_variance   | 0.855       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00284    |
|    n_updates            | 200         |
|    policy_gradient_loss | -0.00983    |
|    value_loss           | 0.0145      |
-----------------------------------------
Eval num_timesteps=45000, episode_reward=0.30 +/- 0.46
Episode length: 12.81 +/- 7.59
Epoch 22 completed in 4.80 seconds.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 10.3        |
|    ep_rew_mean          | 0.5         |
| time/                   |             |
|    fps                  | 409         |
|    iterations           | 22          |
|    time_elapsed         | 109         |
|    total_timesteps      | 45056       |
| train/                  |             |
|    approx_kl            | 0.011891453 |
|    clip_fraction        | 0.0949      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.218      |
|    explained_variance   | 0.907       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0124     |
|    n_updates            | 210         |
|    policy_gradient_loss | -0.00772    |
|    value_loss           | 0.0101      |
-----------------------------------------
Epoch 23 completed in 4.07 seconds.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 9.82        |
|    ep_rew_mean          | 0.5         |
| time/                   |             |
|    fps                  | 406         |
|    iterations           | 23          |
|    time_elapsed         | 115         |
|    total_timesteps      | 47104       |
| train/                  |             |
|    approx_kl            | 0.011069942 |
|    clip_fraction        | 0.0751      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.207      |
|    explained_variance   | 0.927       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00814    |
|    n_updates            | 220         |
|    policy_gradient_loss | -0.00511    |
|    value_loss           | 0.00886     |
-----------------------------------------
Epoch 24 completed in 3.88 seconds.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 10.3        |
|    ep_rew_mean          | 0.5         |
| time/                   |             |
|    fps                  | 405         |
|    iterations           | 24          |
|    time_elapsed         | 121         |
|    total_timesteps      | 49152       |
| train/                  |             |
|    approx_kl            | 0.014488796 |
|    clip_fraction        | 0.113       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.235      |
|    explained_variance   | 0.947       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00582    |
|    n_updates            | 230         |
|    policy_gradient_loss | -0.00859    |
|    value_loss           | 0.00569     |
-----------------------------------------
Eval num_timesteps=50000, episode_reward=0.30 +/- 0.46
Episode length: 13.95 +/- 7.96
Epoch 25 completed in 3.50 seconds.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 10.3        |
|    ep_rew_mean          | 0.5         |
| time/                   |             |
|    fps                  | 403         |
|    iterations           | 25          |
|    time_elapsed         | 126         |
|    total_timesteps      | 51200       |
| train/                  |             |
|    approx_kl            | 0.014403864 |
|    clip_fraction        | 0.0922      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.253      |
|    explained_variance   | 0.934       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0116     |
|    n_updates            | 240         |
|    policy_gradient_loss | -0.00536    |
|    value_loss           | 0.00759     |
-----------------------------------------

Training completed!
Total training time: 90.71 seconds.
Average epoch time: 3.63 seconds.

Testing train set...
pos_queries: 116
neg_queries: 288
ratio_pos_queries: 0.290
mrr_mean: 0.995
mrr_std: 0.051
rewards_pos_mean: 0.991
rewards_pos_std: 0.092
rewards_neg_mean: 0.000
rewards_neg_std: 0.000
rewards_mean: 0.285
rewards_std: 0.451
episode_len_pos_mean: 3.802
episode_len_pos_std: 2.014
episode_len_neg_mean: 17.681
episode_len_neg_std: 4.032
episode_len_mean: 13.696
episode_len_std: 7.224
log_probs_pos_mean: -0.250
log_probs_pos_std: 0.394
log_probs_neg_mean: -2.677
log_probs_neg_std: 1.339
log_probs_mean: -1.980
log_probs_std: 1.590
auc_pr: 0.943

Testing val set...
pos_queries: 24
neg_queries: 57
ratio_pos_queries: 0.300
mrr_mean: 1.000
mrr_std: 0.000
rewards_pos_mean: 1.000
rewards_pos_std: 0.000
rewards_neg_mean: 0.000
rewards_neg_std: 0.000
rewards_mean: 0.296
rewards_std: 0.457
episode_len_pos_mean: 2.333
episode_len_pos_std: 1.599
episode_len_neg_mean: 17.772
episode_len_neg_std: 3.574
episode_len_mean: 13.198
episode_len_std: 7.710
log_probs_pos_mean: -0.109
log_probs_pos_std: 0.187
log_probs_neg_mean: -2.626
log_probs_neg_std: 1.225
log_probs_mean: -1.880
log_probs_std: 1.545
auc_pr: 0.992

Testing test set...
pos_queries: 24
neg_queries: 57
ratio_pos_queries: 0.300
mrr_mean: 0.925
mrr_std: 0.218
rewards_pos_mean: 0.875
rewards_pos_std: 0.331
rewards_neg_mean: 0.000
rewards_neg_std: 0.000
rewards_mean: 0.259
rewards_std: 0.438
episode_len_pos_mean: 4.292
episode_len_pos_std: 3.409
episode_len_neg_mean: 15.561
episode_len_neg_std: 5.719
episode_len_mean: 12.222
episode_len_std: 7.276
log_probs_pos_mean: -0.337
log_probs_pos_std: 0.418
log_probs_neg_mean: -2.423
log_probs_neg_std: 1.697
log_probs_mean: -1.805
log_probs_std: 1.728
auc_pr: 0.816
