eval/mean_reward:0.9166666666666666;eval/std_reward:0.27638539919628335;eval/mean_ep_length:2.6666666666666665;eval/std_ep_length:1.699673171197595;eval/num_timesteps:16384
rollout/ep_rew_mean:0.15;rollout/ep_len_mean:2.11
eval/mean_reward:1.0;eval/std_reward:0.0;eval/mean_ep_length:2.8333333333333335;eval/std_ep_length:2.4094720491334933;eval/num_timesteps:32640

All data;dataset_name:countries_s3;model_name:PPO;learn_embeddings:True;atom_embedder:transe;state_embedder:mean;atom_embedding_size:64;seed:[0, 1, 2];max_depth:20;timesteps_train:150000;restore_best_val_model:True;memory_pruning:True;rule_depend_var:False;dynamic_consult:True;corruption_mode:dynamic;train_neg_pos_ratio:1;false_rules:False;end_proof_action:False;skip_unary_actions:True;ent_coef:0.1;clip_range:0.2;engine:python;train_depth:None;valid_depth:None;test_depth:3;truncate_atoms:True;truncate_states:True;padding_atoms:3;padding_states:10;non_provable_queries:True;non_provable_corruptions:True;corruption_scheme:['tail'];janus_file:None;data_path:./data/;train_file:train.txt;valid_file:valid.txt;test_file:test_depths.txt;rules_file:rules.txt;facts_file:train.txt;state_embedding_size:64;constant_embedding_size:64;predicate_embedding_size:64;variable_no:500;device:cuda;load_model:False;save_model:True;models_path:models/countries_s3;n_eval_queries:24;n_test_queries:3;valid_negatives:None;test_negatives:None;eval_freq:16384;n_envs:128;n_eval_envs:1;n_callback_envs:1;n_steps:128;n_epochs:10;batch_size:128;lr:0.0003;run_signature:countries_s3-transe-mean-64-3-10-dynamic-True-True-1-True-False-False-True-True-True-True-False-20-True-0.1-0.2-python-1;seed_run_i:2
train;pos_queries:0;neg_queries:0;ratio_pos_queries:0;mrr_mean:0;mrr_std:0;rewards_pos_mean:0;rewards_pos_std:0;rewards_neg_mean:0;rewards_neg_std:0;rewards_mean:0;rewards_std:0;episode_len_pos_mean:0;episode_len_pos_std:0;episode_len_neg_mean:0;episode_len_neg_std:0;episode_len_mean:0;episode_len_std:0;log_probs_pos_mean:0;log_probs_pos_std:0;log_probs_neg_mean:0;log_probs_neg_std:0;log_probs_mean:0;log_probs_std:0;auc_pr:0;hits1_mean:0;hits1_std:0;hits3_mean:0;hits3_std:0;hits10_mean:0;hits10_std:0
valid;pos_queries:0;neg_queries:0;ratio_pos_queries:0;mrr_mean:0;mrr_std:0;rewards_pos_mean:0;rewards_pos_std:0;rewards_neg_mean:0;rewards_neg_std:0;rewards_mean:0;rewards_std:0;episode_len_pos_mean:0;episode_len_pos_std:0;episode_len_neg_mean:0;episode_len_neg_std:0;episode_len_mean:0;episode_len_std:0;log_probs_pos_mean:0;log_probs_pos_std:0;log_probs_neg_mean:0;log_probs_neg_std:0;log_probs_mean:0;log_probs_std:0;auc_pr:0;hits1_mean:0;hits1_std:0;hits3_mean:0;hits3_std:0;hits10_mean:0;hits10_std:0
test;pos_queries:3;neg_queries:12;ratio_pos_queries:0.2;mrr_mean:1.0;mrr_std:0.0;rewards_pos_mean:1.0;rewards_pos_std:0.0;rewards_neg_mean:0.0;rewards_neg_std:0.0;rewards_mean:0.2;rewards_std:0.4000000000000001;episode_len_pos_mean:5.0;episode_len_pos_std:3.559026084010437;episode_len_neg_mean:12.333333333333334;episode_len_neg_std:5.557777333511022;episode_len_mean:10.866666666666667;episode_len_std:5.987394165151388;log_probs_pos_mean:-0.1079421838124593;log_probs_pos_std:0.07770810347814916;log_probs_neg_mean:-100.41532748828952;log_probs_neg_std:0.5961646009100648;log_probs_mean:-80.35385042739411;log_probs_std:40.12651224507686;auc_pr:1.0;hits1_mean:1.0;hits1_std:0.0;hits3_mean:1.0;hits3_std:0.0;hits10_mean:1.0;hits10_std:0.0
