Device: cuda
Total timesteps: 90
Training time: 110.17s

================================================================================
Top by Cumulative Time
================================================================================
         19672655 function calls (18418256 primitive calls) in 105.466 seconds

   Ordered by: cumulative time
   List reduced from 9217 to 30 due to restriction <30>

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     5553   14.446    0.003   14.487    0.003 {method 'clone' of 'torch._C.TensorBase' objects}
     1445    8.349    0.006    8.349    0.006 {built-in method torch.ones_like}
      161    0.006    0.000    8.333    0.052 __init__.py:89(_make_grads)
      160    0.003    0.000    7.712    0.048 model.py:641(evaluate_actions)
      128    0.254    0.002    6.828    0.053 env.py:734(step_and_maybe_reset)
      257    0.199    0.001    5.297    0.021 env.py:801(_compute_derived_states)
        3    0.000    0.000    4.263    1.421 graph.py:2256(codegen)
      160    0.000    0.000    4.103    0.026 fast_distributions.py:123(entropy)
      160    3.820    0.024    4.102    0.026 fast_distributions.py:81(entropy)
      128    0.002    0.000    4.056    0.032 common.py:2056(step)
      128    0.733    0.006    4.035    0.032 env.py:593(_step)
      257    0.258    0.001    3.879    0.015 unification.py:1827(get_derived_states)
      129    0.002    0.000    2.649    0.021 common.py:2822(reset)
        3    0.000    0.000    2.604    0.868 scheduler.py:5194(codegen)
        3    0.000    0.000    2.603    0.868 scheduler.py:5318(_codegen_partitions)
        3    0.000    0.000    2.496    0.832 scheduler.py:5202(_codegen_partition_wrapper)
      129    0.039    0.000    2.400    0.019 env.py:344(_reset)
        3    0.002    0.001    2.368    0.789 scheduler.py:5351(_codegen)
       49    0.000    0.000    2.335    0.048 cuda_combined_scheduling.py:126(codegen_node)
       49    0.001    0.000    2.335    0.048 simd.py:1384(codegen_node)
       49    0.004    0.000    2.147    0.044 simd.py:1445(codegen_node_schedule)
      161    0.002    0.000    1.945    0.012 model.py:423(forward)
      161    0.018    0.000    1.943    0.012 model.py:333(forward_joint)
       49    0.004    0.000    1.690    0.034 simd.py:1534(codegen_node_schedule_with_kernel)
      515    0.003    0.000    1.683    0.003 graph.py:1180(call_function)
  965/477    0.016    0.000    1.672    0.004 lowering.py:463(wrapped)
     3381    0.030    0.000    1.639    0.000 container.py:245(forward)
        3    0.000    0.000    1.633    0.544 graph.py:2245(_update_scheduler)
        3    0.000    0.000    1.631    0.544 scheduler.py:2224(__init__)
        3    0.000    0.000    1.626    0.542 scheduler.py:2228(_init)




================================================================================
Top by Total Time
================================================================================
         19672655 function calls (18418256 primitive calls) in 105.466 seconds

   Ordered by: internal time
   List reduced from 9217 to 30 due to restriction <30>

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
    158/0   37.573    0.238    0.000          {method 'run_backward' of 'torch._C._EngineBase' objects}
     5553   14.446    0.003   14.487    0.003 {method 'clone' of 'torch._C.TensorBase' objects}
    158/0   11.176    0.071    0.000          function.py:300(apply)
     1445    8.349    0.006    8.349    0.006 {built-in method torch.ones_like}
      160    3.820    0.024    4.102    0.026 fast_distributions.py:81(entropy)
3033/2254    0.974    0.000    0.840    0.000 {method 'read' of '_io.BufferedReader' objects}
        1    0.832    0.832    0.833    0.833 ppo.py:39(explained_variance)
      322    0.736    0.002    0.745    0.002 embeddings.py:771(forward)
      128    0.733    0.006    4.035    0.032 env.py:593(_step)
  3905/24    0.700    0.000    0.163    0.007 {built-in method torch._C._nn.linear}
    60/46    0.669    0.011    0.927    0.020 {method 'acquire' of '_thread.lock' objects}
     28/8    0.585    0.021    0.570    0.071 operator_schemas.py:96(_torchscript_schema_to_signature_impl)
  499/496    0.485    0.001    0.495    0.001 {method 'mean' of 'torch._C.TensorBase' objects}
      656    0.471    0.001    0.484    0.001 {built-in method torch.embedding}
      170    0.466    0.003    0.583    0.003 rollout.py:246(get)
     2952    0.462    0.000    0.716    0.000 {built-in method torch.layer_norm}
2753850/2720413    0.442    0.000    0.665    0.000 {built-in method builtins.isinstance}
       80    0.435    0.005    0.435    0.005 {built-in method torch._C._cuda_synchronize}
      257    0.364    0.001    0.851    0.003 unification.py:925(unify_with_rules)
      257    0.334    0.001    0.645    0.003 unification.py:1266(standardize_derived_states)
     3444    0.313    0.000    0.372    0.000 {built-in method torch.relu}
      160    0.308    0.002    0.308    0.002 {method 'std' of 'torch._C.TensorBase' objects}
      257    0.306    0.001    0.792    0.003 unification.py:796(unify_with_facts)
    10356    0.291    0.000    0.291    0.000 {method 'update' of '_hashlib.HASH' objects}
      257    0.281    0.001    0.903    0.004 env.py:1292(_postprocess)
34406/12913    0.259    0.000    0.607    0.000 _pytree.py:1272(helper)
      257    0.258    0.001    3.879    0.015 unification.py:1827(get_derived_states)
      128    0.254    0.002    6.828    0.053 env.py:734(step_and_maybe_reset)
      257    0.242    0.001    0.383    0.001 unification.py:1169(prune_and_collapse)
 1138/271    0.230    0.000    0.109    0.000 functional_tensor.py:356(__torch_dispatch__)


